<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>jidenn.data.JIDENNDataset API documentation</title>
<meta name="description" content="Module containing the `JIDENNDataset` dataclass that is a wrapper for a TensorFlow dataset that allows for easy adding and processing of dataset â€¦" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS_CHTML" integrity="sha256-kZafAc6mZvK3W3v1pHOcUix30OHQN6pU/NO2oFkqZVw=" crossorigin></script>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
<link rel="canonical" href="http://jansam.wieno.sk/JIDENN/jidenn/data/JIDENNDataset.html">
<link rel="icon" href="images/q_g_tagging.jpeg">
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>jidenn.data.JIDENNDataset</code></h1>
</header>
<section id="section-intro">
<p>Module containing the <code><a title="jidenn.data.JIDENNDataset.JIDENNDataset" href="#jidenn.data.JIDENNDataset.JIDENNDataset">JIDENNDataset</a></code> dataclass that is a wrapper for a TensorFlow dataset that allows for easy adding and processing of dataset files.
It contains all the necessary tools to perform a preprocessing of the jet dataset for training.</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;
Module containing the `JIDENNDataset` dataclass that is a wrapper for a TensorFlow dataset that allows for easy adding and processing of dataset files.
It contains all the necessary tools to perform a preprocessing of the jet dataset for training. 
&#34;&#34;&#34;
from __future__ import annotations
import tensorflow as tf
import pandas as pd
from dataclasses import dataclass
from typing import Union, Literal, Callable, Dict, Tuple, List, Optional, Any
import os
import pickle
#
import jidenn.config.config as config
from jidenn.data.string_conversions import Cut, Expression
from jidenn.evaluation.plotter import plot_data_distributions


ROOTVariables = Dict[str, Union[tf.RaggedTensor, tf.Tensor]]
&#34;&#34;&#34;Type alias for a dictionary of ROOT variables. The keys are the variable  names and the values are the corresponding 
Tensorflow `tf.RaggedTensor` or `tf.Tensor`.

Example:
```python
variables = {
    &#39;jets_pt&#39;: tf.RaggedTensor([[1, 2, 3, 4, 5], [2, 3]], dtype=tf.float32),
    &#39;eventNumber&#39;: tf.Tensor([1, 2], dtype=tf.int32),
    ...
}
```
&#34;&#34;&#34;


@tf.function
def dict_to_stacked_array(data: Union[ROOTVariables, Tuple[ROOTVariables, ROOTVariables]], label: int, weight: Optional[float] = None) -&gt; Tuple[Union[tf.Tensor, Tuple[tf.Tensor, tf.Tensor]], int, Union[float, None]]:
    &#34;&#34;&#34;Converts a `ROOTVariables` to a input for training a neural network, i.e. a tuple `(input, label, weight)`.
    The `input` is construsted by **stacking all the variables**  in `data` `ROOTVariables` dictionary into a single `tf.Tensor`.

    Optionally, the input data can be a tuple of two ROOTVariables. The output has the form `((input1, input2), label, weight)`.
    The `input2` is constructed by **stacking all the variables** in the second `ROOTVariables` dictionary into a single `tf.Tensor`.

    Args:
        data (ROOTVariables or tuple[ROOTVariables, ROOTVariables]): The input data.
        label (int): The label.
        weight (float, optional): The weight. Defaults to `None`.

    Returns:
        A tuple `(input, label, weight)` where `data` is a  `tf.Tensor` or a tuple `((input1, input2), label, weight)`
        in case `data` is a tuple of two ROOTVariables where `input1` and `input2` are `tf.Tensor`s.
    &#34;&#34;&#34;
    if isinstance(data, tuple):
        interaction = tf.stack([data[1][var] for var in data[1]], axis=-1)
        interaction = tf.where(tf.math.logical_or(tf.math.is_inf(interaction), tf.math.is_nan(interaction)),
                               tf.zeros_like(interaction), interaction)
        if weight is None:
            return (tf.stack([data[0][var] for var in data[0]], axis=-1), interaction), label
        return (tf.stack([data[0][var] for var in data[0]], axis=-1), interaction), label, weight
    else:
        if weight is None:
            return tf.stack([data[var] for var in data.keys()], axis=-1), label
        return tf.stack([data[var] for var in data.keys()], axis=-1), label, weight


@dataclass
class JIDENNDataset:
    &#34;&#34;&#34;The JIDENNDataset dataclass is a wrapper for a TensorFlow dataset that allows for easy loading and processing of dataset files 
    for jet identifiation using deep neural networks (**JIDENN**). The `tf.data.Dataset` is constructed from a `tf.data.Dataset` 
    consisting of `ROOTVariables` dictionaries. 

    The dataset can be loaded from a file using the `load_dataset` method or set manually using the `set_dataset` method.
    Both methods require the `element_spec` either in a pickled file in the case of loading, or as dictionary of `tf.TensorSpec` 
    or `tf.RaggedTensorSpec`  object in the case of setting the dataset manually.

    Example:
    Typical usage of the `JIDENNDataset` dataclass is as follows:
    ```python
    import tensorflow as tf
    from jidenn.config.config_subclasses import Variables
    from .utils.Cut import Cut

    @tf.function 
    def count_PFO(sample: ROOTVariables) -&gt; ROOTVariables:
        sample = sample.copy()
        sample[&#39;jets_PFO_n&#39;] = tf.reduce_sum(tf.ones_like(sample[&#39;jets_PFO_pt&#39;]))
        return sample

    @tf.function 
    def train_input(sample: ROOTVariables) -&gt; ROOTVariables:
        output = {
            &#39;N_PFO&#39;: sample[&#39;jets_PFO_n&#39;],
            &#39;pt&#39;: sample[&#39;jets_pt&#39;],
            &#39;width&#39;: sample[&#39;jets_Width&#39;],
            &#39;EMFrac&#39;: sample[&#39;jets_EMFrac&#39;],
            &#39;mu&#39;: sample[&#39;corrected_averageInteractionsPerCrossing[0]&#39;]
        }
        return output

    variables = [&#39;corrected_averageInteractionsPerCrossing[0]&#39;, &#39;jets_pt&#39;, &#39;jets_Width&#39;, &#39;jets_EMFrac&#39;,&#39;jets_PFO_pt&#39;]

    jidenn_dataset = JIDENNDataset(variables=variables,
                                   target=&#39;jets_TruthLabelID&#39;,
                                   weight=None)
    jidenn_dataset = jidenn_dataset.load_dataset(&#39;path/to/dataset&#39;)

    jidenn_dataset = jidenn_dataset.create_variables(cut=Cut(&#39;jets_pt &gt; 10_000&#39;), map_dataset=count_PFO)
    jidenn_dataset = jidenn_dataset.resample_dataset(lambda data, label: tf.cast(tf.greater(label, 0), tf.int32), [0.5, 0.5])
    jidenn_dataset = jidenn_dataset.remap_labels(lambda data, label: tf.cast(tf.greater(label, 0), tf.int32))
    jidenn_dataset = jidenn_dataset.create_train_input(train_input)
    dataset = jidenn_dataset.get_prepared_dataset(batch_size=128, 
                                                  shuffle_buffer_size=1000, 
                                                  take=100_000,
                                                  assert_length=True)
    model.fit(dataset, epochs=10)
    ```

    Args:
        variables (List[str]): The list of variables to be used in the dataset.
        target (str, optional): The name of the target variable. Defaults to `None`.
        weight (str, optional): The name of the weight variable. Defaults to `None`.


    &#34;&#34;&#34;
    variables: Optional[List[str]] = None
    &#34;&#34;&#34;The configuration dataclass of the variables to be used in the dataset. 
        If `None`, the variables are set automatically during loading with JIDENNDataset.load().&#34;&#34;&#34;
    target: Optional[str] = None
    &#34;&#34;&#34;The name of the target variable. `None` if no target variable is used.&#34;&#34;&#34;
    weight: Optional[str] = None
    &#34;&#34;&#34;The name of the weight variable. `None` if no weight variable is used.&#34;&#34;&#34;

    def __post_init__(self):
        self._dataset = None
        self._element_spec = None

    def load_dataset(self, file: str) -&gt; JIDENNDataset:
        &#34;&#34;&#34;Loads a dataset from a file. The dataset is stored in the `tf.data.Dataset` format.
        The `element_spec` is loaded from the `element_spec` file inside the dataset directory.    
        Alternatively, the `element_spec` can be loaded manually using the `load_element_spec` method.

        Args:
            file (str): The path to the dataset directory.

        Returns:
            JIDENNDataset: The JIDENNDataset object with set dataset and `element_spec`.

        &#34;&#34;&#34;
        if self.element_spec is None:
            element_spec_file = os.path.join(file, &#39;element_spec&#39;)
            jidenn_dataset = self.load_element_spec(element_spec_file)
        else:
            jidenn_dataset = self
        dataset = tf.data.Dataset.load(
            file, compression=&#39;GZIP&#39;, element_spec=jidenn_dataset.element_spec)
        return jidenn_dataset._set_dataset(dataset)

    @staticmethod
    def load(path: str, element_spec_path: Optional[str] = None) -&gt; JIDENNDataset:
        &#34;&#34;&#34;Loads a dataset from a file. The dataset is stored in the `tf.data.Dataset` format.
        The assumed dataset elements are `ROOTVariables` dictionaries or a tuple of `ROOTVariables`, `label` and `weight`.

        Args:
            path (str): The path to the dataset directory.
            element_spec_path (str, optional): The path to the `element_spec` file. Defaults to `None`. 
                If `None`, the `element_spec` is loaded from the `element_spec` file inside the dataset directory.

        Raises:
            ValueError: If the `element_spec` is not a dictionary or a tuple whose first element is a dictionary.

        Returns:
            JIDENNDataset: The JIDENNDataset object with set dataset and `element_spec`.
        &#34;&#34;&#34;

        if element_spec_path is None:
            element_spec_path = os.path.join(path, &#39;element_spec&#39;)
        with open(element_spec_path, &#39;rb&#39;) as f:
            element_spec = pickle.load(f)

        if isinstance(element_spec, dict):
            variables = list(element_spec.keys())

        elif isinstance(element_spec[0], dict):
            variables = list(element_spec[0].keys())

        else:
            raise ValueError(&#39;Element spec is not a dictionary.&#39;)

        return JIDENNDataset(variables=variables).load_dataset(path)

    def save_dataset(self, file: str, num_shards: Optional[int] = None) -&gt; None:
        &#34;&#34;&#34;Saves the dataset to a file. The dataset is stored in the `tf.data.Dataset` format.
        The `element_spec` is stored in the `element_spec` file inside the dataset directory.
        Tensorflow saves the `element_spec.pb` automatically, but manual save is required 
        for further processing of the dataset.  Ternsorflow file has the `.pb` extension.

        Args:
            file (str): The path to the dataset directory.
            num_shards (int, optional): The number of shards to split the dataset into. Defaults to `None`. The sharding is done uniformly into `num_shards` files.

        Raises:
            ValueError: If the dataset is not loaded yet.

        Returns:
            None
        &#34;&#34;&#34;

        if self.dataset is None:
            raise ValueError(&#39;Dataset not loaded yet.&#39;)

        @tf.function
        def random_shards(_) -&gt; tf.Tensor:
            return tf.random.uniform(shape=[], minval=0, maxval=num_shards, dtype=tf.int64)

        self.dataset.save(file, compression=&#39;GZIP&#39;,
                          shard_func=random_shards if num_shards is not None else None)
        with open(os.path.join(file, &#39;element_spec&#39;), &#39;wb&#39;) as f:
            pickle.dump(self.dataset.element_spec, f)

    def load_element_spec(self, file: str) -&gt; JIDENNDataset:
        &#34;&#34;&#34;Loads the `element_spec` from a file. The `element_spec` is a pickled dictionary of `tf.TensorSpec` or `tf.RaggedTensorSpec` objects.

        Args:
            file (str): The path to the `element_spec` file.
        Returns:
            JIDENNDataset: The JIDENNDataset object with the `element_spec` set.
        &#34;&#34;&#34;
        with open(file, &#39;rb&#39;) as f:
            element_spec = pickle.load(f)
        return self._set_element_spec(element_spec)

    def create_variables(self, cut: Optional[Cut] = None, map_dataset: Optional[Callable[[ROOTVariables], ROOTVariables]] = None) -&gt; JIDENNDataset:
        &#34;&#34;&#34;Creates a &#39;tf.data.Dataset&#39; from selected variables and creates labels and weights.
        The variables are selected according to the `variables` loaded from config.
        the `target` and `weight` class variables are used to create labels and weights from the `ROOTVariables`.

        Optionally, a `Cut` can be applied to the dataset. It is done **before** the variables are selected.
        The `map_dataset` function can be used to apply a function to the dataset before the variables are selected.
        It could be used to create new variables from the existing ones.

        Args:
            cut (jidenn.data.utils.Cut.Cut, optional): The `Cut` object to be applied to the dataset. Defaults to `None`. 
            map_dataset (Callable[[ROOTVariables], ROOTVariables], optional): The function to be applied to the dataset using `tf.data.Dataset.map`. Defaults to `None`.

        Raises:
            ValueError: If the dataset is not loaded yet.

        Returns:
            JIDENNDataset: The JIDENNDataset object with the signature of `(ROOTVariables, label, weight)`.
        &#34;&#34;&#34;
        if self.dataset is None:
            raise ValueError(&#39;Dataset not loaded yet.&#39;)
        if map_dataset is not None:
            dataset = self.dataset.map(map_dataset)
        else:
            dataset = self.dataset

        dataset = dataset.filter(cut) if cut is not None else dataset
        dataset = dataset.map(self._var_picker)
        return self._set_dataset(dataset)

    def remap_labels(self, label_mapping: Callable[[int], int]) -&gt; JIDENNDataset:
        &#34;&#34;&#34;Remaps the labels in the dataset using the `label_mapping` function.
        Should be used after the `create_variables` method. 

        Args:
            label_mapping (Callable[[int], int]): The function that maps the labels.

        Raises:
            ValueError: If the dataset is not loaded yet.
            ValueError: If the `target` is not set.

        Returns:
            JIDENNDataset: The JIDENNDataset object where the `label` is remapped.
        &#34;&#34;&#34;
        if self.dataset is None:
            raise ValueError(&#39;Dataset not loaded yet.&#39;)
        if self.target is None:
            raise ValueError(&#39;Target not set yet.&#39;)

        if self.weight is not None:
            @tf.function
            def remap_label(x, y, w):
                return x, label_mapping(y), w
        else:
            @tf.function
            def remap_label(x, y):
                return x, label_mapping(y)

        dataset = self.dataset.map(remap_label)
        return self._set_dataset(dataset)

    @property
    def dataset(self) -&gt; Union[tf.data.Dataset, None]:
        &#34;&#34;&#34;The `tf.data.Dataset` object or `None` if the dataset is not set yet.&#34;&#34;&#34;
        return self._dataset

    @property
    def element_spec(self) -&gt; Union[Dict[str, Union[tf.TensorSpec, tf.RaggedTensorSpec]], None]:
        &#34;&#34;&#34;The `element_spec` of the dataset or `None` if the dataset is not set yet.&#34;&#34;&#34;
        return self._element_spec

    def _set_element_spec(self, element_spec: Dict[str, Union[tf.TensorSpec, tf.RaggedTensorSpec]]) -&gt; JIDENNDataset:
        jidenn_dataset = JIDENNDataset(variables=self.variables,
                                       target=self.target,
                                       weight=self.weight)
        self._element_spec = element_spec
        self._dataset = self.dataset
        return jidenn_dataset

    def _set_dataset(self, dataset: Union[tf.data.Dataset, None]) -&gt; JIDENNDataset:
        jidenn_dataset = JIDENNDataset(variables=self.variables,
                                       target=self.target,
                                       weight=self.weight)
        jidenn_dataset._dataset = dataset
        jidenn_dataset._element_spec = dataset.element_spec
        return jidenn_dataset

    def set_dataset(self, dataset: tf.data.Dataset, element_spec: Dict[str, Union[tf.TensorSpec, tf.RaggedTensorSpec]]) -&gt; JIDENNDataset:
        &#34;&#34;&#34;Sets the `tf.data.Dataset` object and the `element_spec` of the dataset.

        Args:
            dataset (tf.data.Dataset): The `tf.data.Dataset` object consisting of `ROOTVariables`.
            element_spec (Dict[str, Union[tf.TensorSpec, tf.RaggedTensorSpec]]): The `element_spec` of the dataset.

        Returns:
            JIDENNDataset: The JIDENNDataset object with the `dataset` and `element_spec` set.
        &#34;&#34;&#34;
        jidenn_dataset = JIDENNDataset(variables=self.variables,
                                       target=self.target,
                                       weight=self.weight)
        jidenn_dataset._dataset = dataset
        jidenn_dataset._element_spec = element_spec
        return jidenn_dataset

    @property
    def _var_picker(self):
        @tf.function
        def _pick_variables(sample: ROOTVariables) -&gt; Union[Tuple[ROOTVariables, tf.RaggedTensor, tf.RaggedTensor], ROOTVariables, Tuple[ROOTVariables, tf.RaggedTensor]]:

            new_sample = {var: Expression(var)(sample)
                          for var in self.variables}

            if self.target is None:
                return new_sample
            if self.weight is None:
                return new_sample, Expression(self.target)(sample)
            else:
                return new_sample, Expression(self.target)(sample), Expression(self.weight)(sample)
        return _pick_variables

    def resample_dataset(self, resampling_func: Callable[[ROOTVariables, Any], int], target_dist: List[float]):
        &#34;&#34;&#34;Resamples the dataset using the `resampling_func` function. The function computes the bin index for each sample in the dataset. 
        The dataset is then resampled to match the `target_dist` distribution. Be careful that this may **slow down the training process**,
        if the target distribution is very different from the original one as the dataset is resampled on the fly and is waiting 
        for the appropriate sample to be drawn.

        Args:
            resampling_func (Callable[[ROOTVariables, Any], int]): Function that bins the data. It must return an integer between 0 and `len(target_dist) - 1`.
            target_dist (List[float]): The target distribution of the resampled dataset.

        Raises:
            ValueError: If the dataset is not loaded yet.

        Returns:
            JIDENNDataset: The JIDENNDataset object where the dataset is resampled.
        &#34;&#34;&#34;
        if self.dataset is None:
            raise ValueError(&#39;Dataset not loaded yet.&#39;)

        @tf.function
        def _data_only(x, data):
            return data
        dataset = self.dataset.rejection_resample(
            resampling_func, target_dist=target_dist).map(_data_only)
        return self._set_dataset(dataset)

    @staticmethod
    def combine(datasets: List[JIDENNDataset], weights: List[float]) -&gt; JIDENNDataset:
        &#34;&#34;&#34;Combines multiple datasets into one dataset. The samples are interleaved and the weights are used to sample from the datasets.

        Args:
            datasets (List[JIDENNDataset]): List of datasets to combined. All `JIDENNDataset.dataset`s must be set and have the same `element_spec`.
            weights (List[float]): List of weights for each dataset. The weights are used to sample from the datasets.

        Returns:
            JIDENNDataset: Combined `JIDENNDataset` object.
        &#34;&#34;&#34;
        dataset = tf.data.Dataset.sample_from_datasets(
            [dataset.dataset for dataset in datasets], weights=weights)
        jidenn_dataset = JIDENNDataset(
            datasets[0].variables, datasets[0].target, datasets[0].weight)
        return jidenn_dataset._set_dataset(dataset)

    def apply(self, func: Callable[[tf.data.Dataset], tf.data.Dataset]) -&gt; JIDENNDataset:
        &#34;&#34;&#34;Applies a function to the dataset.

        Args:
            func (Callable[[tf.data.Dataset], tf.data.Dataset]): Function to apply to the dataset.

        Returns:
            JIDENNDataset: The JIDENNDataset object with the dataset modified by the function.

        &#34;&#34;&#34;
        if self.dataset is None:
            raise ValueError(&#39;Dataset not loaded yet.&#39;)
        dataset = func(self.dataset)
        return self._set_dataset(dataset)

    def create_train_input(self, func: Callable[[ROOTVariables], Union[ROOTVariables, Tuple[ROOTVariables, ROOTVariables]]]) -&gt; JIDENNDataset:
        &#34;&#34;&#34;Creates a training input from the dataset using the `func` function. The function must take a `ROOTVariables` object and return a `ROOTVariables` object.
        The output of the function is of the form Dict[str, tf.Tensor] or Tuple[Dict[str, tf.Tensor], Dict[str, tf.Tensor]] (optionally aslo tf.RaggedTensor).


        Args:
            func (Callable[[ROOTVariables], Union[ROOTVariables, Tuple[ROOTVariables, ROOTVariables]]]): Function to apply to the data to create the training input.

        Raises:
            ValueError: If the dataset is not loaded yet.

        Returns:
            JIDENNDataset: The JIDENNDataset object  with signature `((ROOTVariables, ROOTVariables), ...)` or `(ROOTVariables, ...)`.
        &#34;&#34;&#34;
        if self.dataset is None:
            raise ValueError(&#39;Dataset not loaded yet.&#39;)

        @tf.function
        def input_wrapper(data, label, w=None):
            return func(data), label
        dataset = self.dataset.map(input_wrapper)
        return self._set_dataset(dataset)

    def to_pandas(self, variables: Optional[List[str]] = None) -&gt; pd.DataFrame:
        &#34;&#34;&#34;Converts the dataset to a pandas DataFrame. The dataset must be loaded before calling this function.
        The function uses `tensorflow_datasets.as_dataframe` to convert the dataset to a pandas DataFrame, so 
        the `tensorflow_datasets` package must be installed.

        Be careful that this function may take a **long time to run**, depending on the size of the dataset.
        Consider taking only a subset of the dataset before converting it to a pandas DataFrame.
        ```python
        jidenn_dataset = JIDENNDataset(...) 
        ...
        jidenn_dataset = jidenn_dataset.apply(lambda dataset: dataset.take(1_000))
        df = jidenn_dataset.to_pandas()
        ```

        If the dataset contains nested tuples consider using `jidenn.data.data_info.explode_nested_variables` 
        on the tuple columns of the convereted dataframe.

        Args:
            variables (Optional[List[str]], optional): List of variables to convert to a pandas DataFrame. If `None`, all variables are converted. Defaults to `None`.

        Raises:
            ImportError: If `tensorflow_datasets` is not installed.
            ValueError: If the dataset is not loaded yet.

        Returns:
            pd.DataFrame: The `tf.data.Dataset` converted to a pandas `pd.DataFrame`.
        &#34;&#34;&#34;

        try:
            import tensorflow_datasets as tfds
        except ImportError:
            raise ImportError(
                &#39;Please install tensorflow_datasets to use this function. Use `pip install tensorflow_datasets`.&#39;)
        if self.dataset is None:
            raise ValueError(&#39;Dataset not loaded yet.&#39;)

        if isinstance(self.element_spec, tuple) and variables is None:
            @tf.function
            def tuple_to_dict(data, label, weight=None):
                if isinstance(data, tuple):
                    data = {**data[0], **data[1]}
                data = {**data, &#39;label&#39;: label, &#39;weight&#39;: weight}
                return data

        elif isinstance(self.element_spec, tuple) and variables is not None:
            @tf.function
            def tuple_to_dict(data, label, weight=None):
                if isinstance(data, tuple):
                    data = {**data[0], **data[1]}
                data = {**data, &#39;label&#39;: label, &#39;weight&#39;: weight}
                return {k: data[k] for k in variables + [&#39;label&#39;, &#39;weight&#39;]}

        elif isinstance(self.element_spec, dict) and variables is not None:
            @tf.function
            def tuple_to_dict(data):
                return {k: data[k] for k in variables}

        elif isinstance(self.element_spec, dict) and variables is None:
            @tf.function
            def tuple_to_dict(data):
                return data

        else:
            raise ValueError(&#39;The dataset must be a tuple or a dict.&#39;)

        dataset = self.dataset.map(tuple_to_dict)
        df = tfds.as_dataframe(dataset)
        df = df.rename(lambda x: x.replace(&#39;/&#39;, &#39;.&#39;), axis=&#39;columns&#39;)
        return df

    def filter(self, filter: Callable[[ROOTVariables], bool]) -&gt; JIDENNDataset:
        &#34;&#34;&#34;Filters the dataset using the `filter` function. 

        Args:
            filter (Callable[[ROOTVariables], bool]): Function to apply to the data.

        Raises:
            ValueError: If the dataset is not loaded yet.

        Returns:
            JIDENNDataset: The JIDENNDataset object with the dataset filtered.
        &#34;&#34;&#34;
        if self.dataset is None:
            raise ValueError(&#39;Dataset not loaded yet.&#39;)
        dataset = self.dataset.filter(filter)
        return self._set_dataset(dataset)

    def get_prepared_dataset(self,
                             batch_size: int,
                             assert_length: bool = False,
                             shuffle_buffer_size: Optional[int] = None,
                             take: Optional[int] = None,
                             map_func: Optional[Callable[[Union[ROOTVariables, Tuple[ROOTVariables, ROOTVariables]], Any], Tuple[Union[ROOTVariables, Tuple[ROOTVariables, ROOTVariables]], Any]]] = None) -&gt; tf.data.Dataset:
        &#34;&#34;&#34;Returns a prepared dataset for training. The dataset is prepared by stacking the arrays in the `ROOTVariables` in the dataset using `dict_to_stacked_array`.
        The dataset is also batched, shuffled, shortend (using `take`) and mapped using the `map_func` function. The function is applied before the input is stacked.

        **Train input must be created with `JIDENNDataset.create_train_input` before calling this method.**  

        The assertion allows displaying the estimated epoch time during training. The assertion is only performed if `take` is set.

        Args:
            batch_size (int): Batch size of the dataset.
            assert_length (bool, optional): If `True`, the dataset is asserted to have the `take` length. It is only used if &#39;take&#39; is set. Defaults to False.
            shuffle_buffer_size (int, optional): Size of the shuffle buffer. If `None`, the dataset is not shuffled. Defaults to None.
            take (int, optional): Number of elements to take from the dataset. If `None`, the dataset is not taken. Defaults to None.
            map_func (Callable[[Union[ROOTVariables, Tuple[ROOTVariables, ROOTVariables]], Any], Tuple[Union[ROOTVariables, Tuple[ROOTVariables, ROOTVariables]], Any]], optional): Function to apply to the dataset. Defaults to None.

        Raises:
            ValueError: If the dataset is not loaded yet.

        Returns:
            tf.data.Dataset: The prepared dataset.
        &#34;&#34;&#34;

        if self.dataset is None:
            raise ValueError(&#39;Dataset not loaded yet.&#39;)
        if map_func is not None:
            dataset = self.dataset.map(map_func)
        else:
            dataset = self.dataset.map(dict_to_stacked_array)
        dataset = dataset.shuffle(
            shuffle_buffer_size) if shuffle_buffer_size is not None else dataset
        if take is not None:
            dataset = dataset.take(take)
            dataset = dataset.apply(tf.data.experimental.assert_cardinality(
                take)) if assert_length else dataset
        dataset = dataset.apply(
            tf.data.experimental.dense_to_ragged_batch(batch_size))
        # dataset = dataset.ragged_batch(batch_size)
        dataset = dataset.prefetch(tf.data.AUTOTUNE)
        return dataset

    def plot_data_distributions(self,
                                folder: str,
                                variables: Optional[List[str]] = None,
                                hue_variable: Optional[str] = None,
                                named_labels: Optional[Dict[int, str]] = None,
                                xlabel_mapper: Optional[Dict[str, str]] = None) -&gt; None:
        &#34;&#34;&#34;Plots the data distributions of the dataset. The dataset must be loaded before calling this function.
        The function uses `jidenn.evaluation.plotter.plot_data_distributions` to plot the data distributions.

        Args:
            folder (str): The path to the directory where the plots are saved.
            variables (Optional[List[str]], optional): List of variables to plot. If `None`, all variables are plotted. Defaults to `None`.
            named_labels (Dict[int, str], optional): Dictionary mapping truth values to custom labels.
                If not provided, the truth values will be used as labels. 

        Raises:
            ValueError: If the dataset is not loaded yet.

        Returns:
            None
        &#34;&#34;&#34;
        if self.dataset is None:
            raise ValueError(&#39;Dataset not loaded yet.&#39;)
        df = self.to_pandas(variables)
        plot_data_distributions(df, folder=folder, named_labels=named_labels,
                                xlabel_mapper=xlabel_mapper, hue_variable=hue_variable)</code></pre>
</details>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-variables">Global variables</h2>
<dl>
<dt id="jidenn.data.JIDENNDataset.ROOTVariables"><code class="name">var <span class="ident">ROOTVariables</span></code></dt>
<dd>
<div class="desc"><p>Type alias for a dictionary of ROOT variables. The keys are the variable
names and the values are the corresponding
Tensorflow <code>tf.RaggedTensor</code> or <code>tf.Tensor</code>.</p>
<p>Example:</p>
<pre><code class="language-python">variables = {
    'jets_pt': tf.RaggedTensor([[1, 2, 3, 4, 5], [2, 3]], dtype=tf.float32),
    'eventNumber': tf.Tensor([1, 2], dtype=tf.int32),
    ...
}
</code></pre></div>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="jidenn.data.JIDENNDataset.dict_to_stacked_array"><code class="name flex">
<span>def <span class="ident">dict_to_stacked_array</span></span>(<span>data:Â Union[<a title="jidenn.data.JIDENNDataset.ROOTVariables" href="#jidenn.data.JIDENNDataset.ROOTVariables">ROOTVariables</a>,Â Tuple[<a title="jidenn.data.JIDENNDataset.ROOTVariables" href="#jidenn.data.JIDENNDataset.ROOTVariables">ROOTVariables</a>,Â <a title="jidenn.data.JIDENNDataset.ROOTVariables" href="#jidenn.data.JIDENNDataset.ROOTVariables">ROOTVariables</a>]], label:Â int, weight:Â Optional[float]Â =Â None) â€‘>Â Tuple[Union[tensorflow.python.framework.ops.Tensor,Â Tuple[tensorflow.python.framework.ops.Tensor,Â tensorflow.python.framework.ops.Tensor]],Â int,Â Optional[float]]</span>
</code></dt>
<dd>
<div class="desc"><p>Converts a <code><a title="jidenn.data.JIDENNDataset.ROOTVariables" href="#jidenn.data.JIDENNDataset.ROOTVariables">ROOTVariables</a></code> to a input for training a neural network, i.e. a tuple <code>(input, label, weight)</code>.
The <code>input</code> is construsted by <strong>stacking all the variables</strong>
in <code>data</code> <code><a title="jidenn.data.JIDENNDataset.ROOTVariables" href="#jidenn.data.JIDENNDataset.ROOTVariables">ROOTVariables</a></code> dictionary into a single <code>tf.Tensor</code>.</p>
<p>Optionally, the input data can be a tuple of two ROOTVariables. The output has the form <code>((input1, input2), label, weight)</code>.
The <code>input2</code> is constructed by <strong>stacking all the variables</strong> in the second <code><a title="jidenn.data.JIDENNDataset.ROOTVariables" href="#jidenn.data.JIDENNDataset.ROOTVariables">ROOTVariables</a></code> dictionary into a single <code>tf.Tensor</code>.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>data</code></strong> :&ensp;<code><a title="jidenn.data.JIDENNDataset.ROOTVariables" href="#jidenn.data.JIDENNDataset.ROOTVariables">ROOTVariables</a></code> or <code>tuple[<a title="jidenn.data.JIDENNDataset.ROOTVariables" href="#jidenn.data.JIDENNDataset.ROOTVariables">ROOTVariables</a>, <a title="jidenn.data.JIDENNDataset.ROOTVariables" href="#jidenn.data.JIDENNDataset.ROOTVariables">ROOTVariables</a>]</code></dt>
<dd>The input data.</dd>
<dt><strong><code>label</code></strong> :&ensp;<code>int</code></dt>
<dd>The label.</dd>
<dt><strong><code>weight</code></strong> :&ensp;<code>float</code>, optional</dt>
<dd>The weight. Defaults to <code>None</code>.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>A tuple <code>(input, label, weight)</code> where <code>data</code> is a
<code>tf.Tensor</code> or a tuple <code>((input1, input2), label, weight)</code>
in case <code>data</code> is a tuple of two ROOTVariables where <code>input1</code> and <code>input2</code> are <code>tf.Tensor</code>s.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@tf.function
def dict_to_stacked_array(data: Union[ROOTVariables, Tuple[ROOTVariables, ROOTVariables]], label: int, weight: Optional[float] = None) -&gt; Tuple[Union[tf.Tensor, Tuple[tf.Tensor, tf.Tensor]], int, Union[float, None]]:
    &#34;&#34;&#34;Converts a `ROOTVariables` to a input for training a neural network, i.e. a tuple `(input, label, weight)`.
    The `input` is construsted by **stacking all the variables**  in `data` `ROOTVariables` dictionary into a single `tf.Tensor`.

    Optionally, the input data can be a tuple of two ROOTVariables. The output has the form `((input1, input2), label, weight)`.
    The `input2` is constructed by **stacking all the variables** in the second `ROOTVariables` dictionary into a single `tf.Tensor`.

    Args:
        data (ROOTVariables or tuple[ROOTVariables, ROOTVariables]): The input data.
        label (int): The label.
        weight (float, optional): The weight. Defaults to `None`.

    Returns:
        A tuple `(input, label, weight)` where `data` is a  `tf.Tensor` or a tuple `((input1, input2), label, weight)`
        in case `data` is a tuple of two ROOTVariables where `input1` and `input2` are `tf.Tensor`s.
    &#34;&#34;&#34;
    if isinstance(data, tuple):
        interaction = tf.stack([data[1][var] for var in data[1]], axis=-1)
        interaction = tf.where(tf.math.logical_or(tf.math.is_inf(interaction), tf.math.is_nan(interaction)),
                               tf.zeros_like(interaction), interaction)
        if weight is None:
            return (tf.stack([data[0][var] for var in data[0]], axis=-1), interaction), label
        return (tf.stack([data[0][var] for var in data[0]], axis=-1), interaction), label, weight
    else:
        if weight is None:
            return tf.stack([data[var] for var in data.keys()], axis=-1), label
        return tf.stack([data[var] for var in data.keys()], axis=-1), label, weight</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="jidenn.data.JIDENNDataset.JIDENNDataset"><code class="flex name class">
<span>class <span class="ident">JIDENNDataset</span></span>
<span>(</span><span>variables:Â Optional[List[str]]Â =Â None, target:Â Optional[str]Â =Â None, weight:Â Optional[str]Â =Â None)</span>
</code></dt>
<dd>
<div class="desc"><p>The JIDENNDataset dataclass is a wrapper for a TensorFlow dataset that allows for easy loading and processing of dataset files
for jet identifiation using deep neural networks (<strong>JIDENN</strong>). The <code>tf.data.Dataset</code> is constructed from a <code>tf.data.Dataset</code>
consisting of <code><a title="jidenn.data.JIDENNDataset.ROOTVariables" href="#jidenn.data.JIDENNDataset.ROOTVariables">ROOTVariables</a></code> dictionaries. </p>
<p>The dataset can be loaded from a file using the <code>load_dataset</code> method or set manually using the <code>set_dataset</code> method.
Both methods require the <code>element_spec</code> either in a pickled file in the case of loading, or as dictionary of <code>tf.TensorSpec</code>
or <code>tf.RaggedTensorSpec</code>
object in the case of setting the dataset manually.</p>
<p>Example:
Typical usage of the <code><a title="jidenn.data.JIDENNDataset.JIDENNDataset" href="#jidenn.data.JIDENNDataset.JIDENNDataset">JIDENNDataset</a></code> dataclass is as follows:</p>
<pre><code class="language-python">import tensorflow as tf
from jidenn.config.config_subclasses import Variables
from .utils.Cut import Cut

@tf.function 
def count_PFO(sample: ROOTVariables) -&gt; ROOTVariables:
    sample = sample.copy()
    sample['jets_PFO_n'] = tf.reduce_sum(tf.ones_like(sample['jets_PFO_pt']))
    return sample

@tf.function 
def train_input(sample: ROOTVariables) -&gt; ROOTVariables:
    output = {
        'N_PFO': sample['jets_PFO_n'],
        'pt': sample['jets_pt'],
        'width': sample['jets_Width'],
        'EMFrac': sample['jets_EMFrac'],
        'mu': sample['corrected_averageInteractionsPerCrossing[0]']
    }
    return output

variables = ['corrected_averageInteractionsPerCrossing[0]', 'jets_pt', 'jets_Width', 'jets_EMFrac','jets_PFO_pt']

jidenn_dataset = JIDENNDataset(variables=variables,
                               target='jets_TruthLabelID',
                               weight=None)
jidenn_dataset = jidenn_dataset.load_dataset('path/to/dataset')

jidenn_dataset = jidenn_dataset.create_variables(cut=Cut('jets_pt &gt; 10_000'), map_dataset=count_PFO)
jidenn_dataset = jidenn_dataset.resample_dataset(lambda data, label: tf.cast(tf.greater(label, 0), tf.int32), [0.5, 0.5])
jidenn_dataset = jidenn_dataset.remap_labels(lambda data, label: tf.cast(tf.greater(label, 0), tf.int32))
jidenn_dataset = jidenn_dataset.create_train_input(train_input)
dataset = jidenn_dataset.get_prepared_dataset(batch_size=128, 
                                              shuffle_buffer_size=1000, 
                                              take=100_000,
                                              assert_length=True)
model.fit(dataset, epochs=10)
</code></pre>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>variables</code></strong> :&ensp;<code>List[str]</code></dt>
<dd>The list of variables to be used in the dataset.</dd>
<dt><strong><code>target</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>The name of the target variable. Defaults to <code>None</code>.</dd>
<dt><strong><code>weight</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>The name of the weight variable. Defaults to <code>None</code>.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@dataclass
class JIDENNDataset:
    &#34;&#34;&#34;The JIDENNDataset dataclass is a wrapper for a TensorFlow dataset that allows for easy loading and processing of dataset files 
    for jet identifiation using deep neural networks (**JIDENN**). The `tf.data.Dataset` is constructed from a `tf.data.Dataset` 
    consisting of `ROOTVariables` dictionaries. 

    The dataset can be loaded from a file using the `load_dataset` method or set manually using the `set_dataset` method.
    Both methods require the `element_spec` either in a pickled file in the case of loading, or as dictionary of `tf.TensorSpec` 
    or `tf.RaggedTensorSpec`  object in the case of setting the dataset manually.

    Example:
    Typical usage of the `JIDENNDataset` dataclass is as follows:
    ```python
    import tensorflow as tf
    from jidenn.config.config_subclasses import Variables
    from .utils.Cut import Cut

    @tf.function 
    def count_PFO(sample: ROOTVariables) -&gt; ROOTVariables:
        sample = sample.copy()
        sample[&#39;jets_PFO_n&#39;] = tf.reduce_sum(tf.ones_like(sample[&#39;jets_PFO_pt&#39;]))
        return sample

    @tf.function 
    def train_input(sample: ROOTVariables) -&gt; ROOTVariables:
        output = {
            &#39;N_PFO&#39;: sample[&#39;jets_PFO_n&#39;],
            &#39;pt&#39;: sample[&#39;jets_pt&#39;],
            &#39;width&#39;: sample[&#39;jets_Width&#39;],
            &#39;EMFrac&#39;: sample[&#39;jets_EMFrac&#39;],
            &#39;mu&#39;: sample[&#39;corrected_averageInteractionsPerCrossing[0]&#39;]
        }
        return output

    variables = [&#39;corrected_averageInteractionsPerCrossing[0]&#39;, &#39;jets_pt&#39;, &#39;jets_Width&#39;, &#39;jets_EMFrac&#39;,&#39;jets_PFO_pt&#39;]

    jidenn_dataset = JIDENNDataset(variables=variables,
                                   target=&#39;jets_TruthLabelID&#39;,
                                   weight=None)
    jidenn_dataset = jidenn_dataset.load_dataset(&#39;path/to/dataset&#39;)

    jidenn_dataset = jidenn_dataset.create_variables(cut=Cut(&#39;jets_pt &gt; 10_000&#39;), map_dataset=count_PFO)
    jidenn_dataset = jidenn_dataset.resample_dataset(lambda data, label: tf.cast(tf.greater(label, 0), tf.int32), [0.5, 0.5])
    jidenn_dataset = jidenn_dataset.remap_labels(lambda data, label: tf.cast(tf.greater(label, 0), tf.int32))
    jidenn_dataset = jidenn_dataset.create_train_input(train_input)
    dataset = jidenn_dataset.get_prepared_dataset(batch_size=128, 
                                                  shuffle_buffer_size=1000, 
                                                  take=100_000,
                                                  assert_length=True)
    model.fit(dataset, epochs=10)
    ```

    Args:
        variables (List[str]): The list of variables to be used in the dataset.
        target (str, optional): The name of the target variable. Defaults to `None`.
        weight (str, optional): The name of the weight variable. Defaults to `None`.


    &#34;&#34;&#34;
    variables: Optional[List[str]] = None
    &#34;&#34;&#34;The configuration dataclass of the variables to be used in the dataset. 
        If `None`, the variables are set automatically during loading with JIDENNDataset.load().&#34;&#34;&#34;
    target: Optional[str] = None
    &#34;&#34;&#34;The name of the target variable. `None` if no target variable is used.&#34;&#34;&#34;
    weight: Optional[str] = None
    &#34;&#34;&#34;The name of the weight variable. `None` if no weight variable is used.&#34;&#34;&#34;

    def __post_init__(self):
        self._dataset = None
        self._element_spec = None

    def load_dataset(self, file: str) -&gt; JIDENNDataset:
        &#34;&#34;&#34;Loads a dataset from a file. The dataset is stored in the `tf.data.Dataset` format.
        The `element_spec` is loaded from the `element_spec` file inside the dataset directory.    
        Alternatively, the `element_spec` can be loaded manually using the `load_element_spec` method.

        Args:
            file (str): The path to the dataset directory.

        Returns:
            JIDENNDataset: The JIDENNDataset object with set dataset and `element_spec`.

        &#34;&#34;&#34;
        if self.element_spec is None:
            element_spec_file = os.path.join(file, &#39;element_spec&#39;)
            jidenn_dataset = self.load_element_spec(element_spec_file)
        else:
            jidenn_dataset = self
        dataset = tf.data.Dataset.load(
            file, compression=&#39;GZIP&#39;, element_spec=jidenn_dataset.element_spec)
        return jidenn_dataset._set_dataset(dataset)

    @staticmethod
    def load(path: str, element_spec_path: Optional[str] = None) -&gt; JIDENNDataset:
        &#34;&#34;&#34;Loads a dataset from a file. The dataset is stored in the `tf.data.Dataset` format.
        The assumed dataset elements are `ROOTVariables` dictionaries or a tuple of `ROOTVariables`, `label` and `weight`.

        Args:
            path (str): The path to the dataset directory.
            element_spec_path (str, optional): The path to the `element_spec` file. Defaults to `None`. 
                If `None`, the `element_spec` is loaded from the `element_spec` file inside the dataset directory.

        Raises:
            ValueError: If the `element_spec` is not a dictionary or a tuple whose first element is a dictionary.

        Returns:
            JIDENNDataset: The JIDENNDataset object with set dataset and `element_spec`.
        &#34;&#34;&#34;

        if element_spec_path is None:
            element_spec_path = os.path.join(path, &#39;element_spec&#39;)
        with open(element_spec_path, &#39;rb&#39;) as f:
            element_spec = pickle.load(f)

        if isinstance(element_spec, dict):
            variables = list(element_spec.keys())

        elif isinstance(element_spec[0], dict):
            variables = list(element_spec[0].keys())

        else:
            raise ValueError(&#39;Element spec is not a dictionary.&#39;)

        return JIDENNDataset(variables=variables).load_dataset(path)

    def save_dataset(self, file: str, num_shards: Optional[int] = None) -&gt; None:
        &#34;&#34;&#34;Saves the dataset to a file. The dataset is stored in the `tf.data.Dataset` format.
        The `element_spec` is stored in the `element_spec` file inside the dataset directory.
        Tensorflow saves the `element_spec.pb` automatically, but manual save is required 
        for further processing of the dataset.  Ternsorflow file has the `.pb` extension.

        Args:
            file (str): The path to the dataset directory.
            num_shards (int, optional): The number of shards to split the dataset into. Defaults to `None`. The sharding is done uniformly into `num_shards` files.

        Raises:
            ValueError: If the dataset is not loaded yet.

        Returns:
            None
        &#34;&#34;&#34;

        if self.dataset is None:
            raise ValueError(&#39;Dataset not loaded yet.&#39;)

        @tf.function
        def random_shards(_) -&gt; tf.Tensor:
            return tf.random.uniform(shape=[], minval=0, maxval=num_shards, dtype=tf.int64)

        self.dataset.save(file, compression=&#39;GZIP&#39;,
                          shard_func=random_shards if num_shards is not None else None)
        with open(os.path.join(file, &#39;element_spec&#39;), &#39;wb&#39;) as f:
            pickle.dump(self.dataset.element_spec, f)

    def load_element_spec(self, file: str) -&gt; JIDENNDataset:
        &#34;&#34;&#34;Loads the `element_spec` from a file. The `element_spec` is a pickled dictionary of `tf.TensorSpec` or `tf.RaggedTensorSpec` objects.

        Args:
            file (str): The path to the `element_spec` file.
        Returns:
            JIDENNDataset: The JIDENNDataset object with the `element_spec` set.
        &#34;&#34;&#34;
        with open(file, &#39;rb&#39;) as f:
            element_spec = pickle.load(f)
        return self._set_element_spec(element_spec)

    def create_variables(self, cut: Optional[Cut] = None, map_dataset: Optional[Callable[[ROOTVariables], ROOTVariables]] = None) -&gt; JIDENNDataset:
        &#34;&#34;&#34;Creates a &#39;tf.data.Dataset&#39; from selected variables and creates labels and weights.
        The variables are selected according to the `variables` loaded from config.
        the `target` and `weight` class variables are used to create labels and weights from the `ROOTVariables`.

        Optionally, a `Cut` can be applied to the dataset. It is done **before** the variables are selected.
        The `map_dataset` function can be used to apply a function to the dataset before the variables are selected.
        It could be used to create new variables from the existing ones.

        Args:
            cut (jidenn.data.utils.Cut.Cut, optional): The `Cut` object to be applied to the dataset. Defaults to `None`. 
            map_dataset (Callable[[ROOTVariables], ROOTVariables], optional): The function to be applied to the dataset using `tf.data.Dataset.map`. Defaults to `None`.

        Raises:
            ValueError: If the dataset is not loaded yet.

        Returns:
            JIDENNDataset: The JIDENNDataset object with the signature of `(ROOTVariables, label, weight)`.
        &#34;&#34;&#34;
        if self.dataset is None:
            raise ValueError(&#39;Dataset not loaded yet.&#39;)
        if map_dataset is not None:
            dataset = self.dataset.map(map_dataset)
        else:
            dataset = self.dataset

        dataset = dataset.filter(cut) if cut is not None else dataset
        dataset = dataset.map(self._var_picker)
        return self._set_dataset(dataset)

    def remap_labels(self, label_mapping: Callable[[int], int]) -&gt; JIDENNDataset:
        &#34;&#34;&#34;Remaps the labels in the dataset using the `label_mapping` function.
        Should be used after the `create_variables` method. 

        Args:
            label_mapping (Callable[[int], int]): The function that maps the labels.

        Raises:
            ValueError: If the dataset is not loaded yet.
            ValueError: If the `target` is not set.

        Returns:
            JIDENNDataset: The JIDENNDataset object where the `label` is remapped.
        &#34;&#34;&#34;
        if self.dataset is None:
            raise ValueError(&#39;Dataset not loaded yet.&#39;)
        if self.target is None:
            raise ValueError(&#39;Target not set yet.&#39;)

        if self.weight is not None:
            @tf.function
            def remap_label(x, y, w):
                return x, label_mapping(y), w
        else:
            @tf.function
            def remap_label(x, y):
                return x, label_mapping(y)

        dataset = self.dataset.map(remap_label)
        return self._set_dataset(dataset)

    @property
    def dataset(self) -&gt; Union[tf.data.Dataset, None]:
        &#34;&#34;&#34;The `tf.data.Dataset` object or `None` if the dataset is not set yet.&#34;&#34;&#34;
        return self._dataset

    @property
    def element_spec(self) -&gt; Union[Dict[str, Union[tf.TensorSpec, tf.RaggedTensorSpec]], None]:
        &#34;&#34;&#34;The `element_spec` of the dataset or `None` if the dataset is not set yet.&#34;&#34;&#34;
        return self._element_spec

    def _set_element_spec(self, element_spec: Dict[str, Union[tf.TensorSpec, tf.RaggedTensorSpec]]) -&gt; JIDENNDataset:
        jidenn_dataset = JIDENNDataset(variables=self.variables,
                                       target=self.target,
                                       weight=self.weight)
        self._element_spec = element_spec
        self._dataset = self.dataset
        return jidenn_dataset

    def _set_dataset(self, dataset: Union[tf.data.Dataset, None]) -&gt; JIDENNDataset:
        jidenn_dataset = JIDENNDataset(variables=self.variables,
                                       target=self.target,
                                       weight=self.weight)
        jidenn_dataset._dataset = dataset
        jidenn_dataset._element_spec = dataset.element_spec
        return jidenn_dataset

    def set_dataset(self, dataset: tf.data.Dataset, element_spec: Dict[str, Union[tf.TensorSpec, tf.RaggedTensorSpec]]) -&gt; JIDENNDataset:
        &#34;&#34;&#34;Sets the `tf.data.Dataset` object and the `element_spec` of the dataset.

        Args:
            dataset (tf.data.Dataset): The `tf.data.Dataset` object consisting of `ROOTVariables`.
            element_spec (Dict[str, Union[tf.TensorSpec, tf.RaggedTensorSpec]]): The `element_spec` of the dataset.

        Returns:
            JIDENNDataset: The JIDENNDataset object with the `dataset` and `element_spec` set.
        &#34;&#34;&#34;
        jidenn_dataset = JIDENNDataset(variables=self.variables,
                                       target=self.target,
                                       weight=self.weight)
        jidenn_dataset._dataset = dataset
        jidenn_dataset._element_spec = element_spec
        return jidenn_dataset

    @property
    def _var_picker(self):
        @tf.function
        def _pick_variables(sample: ROOTVariables) -&gt; Union[Tuple[ROOTVariables, tf.RaggedTensor, tf.RaggedTensor], ROOTVariables, Tuple[ROOTVariables, tf.RaggedTensor]]:

            new_sample = {var: Expression(var)(sample)
                          for var in self.variables}

            if self.target is None:
                return new_sample
            if self.weight is None:
                return new_sample, Expression(self.target)(sample)
            else:
                return new_sample, Expression(self.target)(sample), Expression(self.weight)(sample)
        return _pick_variables

    def resample_dataset(self, resampling_func: Callable[[ROOTVariables, Any], int], target_dist: List[float]):
        &#34;&#34;&#34;Resamples the dataset using the `resampling_func` function. The function computes the bin index for each sample in the dataset. 
        The dataset is then resampled to match the `target_dist` distribution. Be careful that this may **slow down the training process**,
        if the target distribution is very different from the original one as the dataset is resampled on the fly and is waiting 
        for the appropriate sample to be drawn.

        Args:
            resampling_func (Callable[[ROOTVariables, Any], int]): Function that bins the data. It must return an integer between 0 and `len(target_dist) - 1`.
            target_dist (List[float]): The target distribution of the resampled dataset.

        Raises:
            ValueError: If the dataset is not loaded yet.

        Returns:
            JIDENNDataset: The JIDENNDataset object where the dataset is resampled.
        &#34;&#34;&#34;
        if self.dataset is None:
            raise ValueError(&#39;Dataset not loaded yet.&#39;)

        @tf.function
        def _data_only(x, data):
            return data
        dataset = self.dataset.rejection_resample(
            resampling_func, target_dist=target_dist).map(_data_only)
        return self._set_dataset(dataset)

    @staticmethod
    def combine(datasets: List[JIDENNDataset], weights: List[float]) -&gt; JIDENNDataset:
        &#34;&#34;&#34;Combines multiple datasets into one dataset. The samples are interleaved and the weights are used to sample from the datasets.

        Args:
            datasets (List[JIDENNDataset]): List of datasets to combined. All `JIDENNDataset.dataset`s must be set and have the same `element_spec`.
            weights (List[float]): List of weights for each dataset. The weights are used to sample from the datasets.

        Returns:
            JIDENNDataset: Combined `JIDENNDataset` object.
        &#34;&#34;&#34;
        dataset = tf.data.Dataset.sample_from_datasets(
            [dataset.dataset for dataset in datasets], weights=weights)
        jidenn_dataset = JIDENNDataset(
            datasets[0].variables, datasets[0].target, datasets[0].weight)
        return jidenn_dataset._set_dataset(dataset)

    def apply(self, func: Callable[[tf.data.Dataset], tf.data.Dataset]) -&gt; JIDENNDataset:
        &#34;&#34;&#34;Applies a function to the dataset.

        Args:
            func (Callable[[tf.data.Dataset], tf.data.Dataset]): Function to apply to the dataset.

        Returns:
            JIDENNDataset: The JIDENNDataset object with the dataset modified by the function.

        &#34;&#34;&#34;
        if self.dataset is None:
            raise ValueError(&#39;Dataset not loaded yet.&#39;)
        dataset = func(self.dataset)
        return self._set_dataset(dataset)

    def create_train_input(self, func: Callable[[ROOTVariables], Union[ROOTVariables, Tuple[ROOTVariables, ROOTVariables]]]) -&gt; JIDENNDataset:
        &#34;&#34;&#34;Creates a training input from the dataset using the `func` function. The function must take a `ROOTVariables` object and return a `ROOTVariables` object.
        The output of the function is of the form Dict[str, tf.Tensor] or Tuple[Dict[str, tf.Tensor], Dict[str, tf.Tensor]] (optionally aslo tf.RaggedTensor).


        Args:
            func (Callable[[ROOTVariables], Union[ROOTVariables, Tuple[ROOTVariables, ROOTVariables]]]): Function to apply to the data to create the training input.

        Raises:
            ValueError: If the dataset is not loaded yet.

        Returns:
            JIDENNDataset: The JIDENNDataset object  with signature `((ROOTVariables, ROOTVariables), ...)` or `(ROOTVariables, ...)`.
        &#34;&#34;&#34;
        if self.dataset is None:
            raise ValueError(&#39;Dataset not loaded yet.&#39;)

        @tf.function
        def input_wrapper(data, label, w=None):
            return func(data), label
        dataset = self.dataset.map(input_wrapper)
        return self._set_dataset(dataset)

    def to_pandas(self, variables: Optional[List[str]] = None) -&gt; pd.DataFrame:
        &#34;&#34;&#34;Converts the dataset to a pandas DataFrame. The dataset must be loaded before calling this function.
        The function uses `tensorflow_datasets.as_dataframe` to convert the dataset to a pandas DataFrame, so 
        the `tensorflow_datasets` package must be installed.

        Be careful that this function may take a **long time to run**, depending on the size of the dataset.
        Consider taking only a subset of the dataset before converting it to a pandas DataFrame.
        ```python
        jidenn_dataset = JIDENNDataset(...) 
        ...
        jidenn_dataset = jidenn_dataset.apply(lambda dataset: dataset.take(1_000))
        df = jidenn_dataset.to_pandas()
        ```

        If the dataset contains nested tuples consider using `jidenn.data.data_info.explode_nested_variables` 
        on the tuple columns of the convereted dataframe.

        Args:
            variables (Optional[List[str]], optional): List of variables to convert to a pandas DataFrame. If `None`, all variables are converted. Defaults to `None`.

        Raises:
            ImportError: If `tensorflow_datasets` is not installed.
            ValueError: If the dataset is not loaded yet.

        Returns:
            pd.DataFrame: The `tf.data.Dataset` converted to a pandas `pd.DataFrame`.
        &#34;&#34;&#34;

        try:
            import tensorflow_datasets as tfds
        except ImportError:
            raise ImportError(
                &#39;Please install tensorflow_datasets to use this function. Use `pip install tensorflow_datasets`.&#39;)
        if self.dataset is None:
            raise ValueError(&#39;Dataset not loaded yet.&#39;)

        if isinstance(self.element_spec, tuple) and variables is None:
            @tf.function
            def tuple_to_dict(data, label, weight=None):
                if isinstance(data, tuple):
                    data = {**data[0], **data[1]}
                data = {**data, &#39;label&#39;: label, &#39;weight&#39;: weight}
                return data

        elif isinstance(self.element_spec, tuple) and variables is not None:
            @tf.function
            def tuple_to_dict(data, label, weight=None):
                if isinstance(data, tuple):
                    data = {**data[0], **data[1]}
                data = {**data, &#39;label&#39;: label, &#39;weight&#39;: weight}
                return {k: data[k] for k in variables + [&#39;label&#39;, &#39;weight&#39;]}

        elif isinstance(self.element_spec, dict) and variables is not None:
            @tf.function
            def tuple_to_dict(data):
                return {k: data[k] for k in variables}

        elif isinstance(self.element_spec, dict) and variables is None:
            @tf.function
            def tuple_to_dict(data):
                return data

        else:
            raise ValueError(&#39;The dataset must be a tuple or a dict.&#39;)

        dataset = self.dataset.map(tuple_to_dict)
        df = tfds.as_dataframe(dataset)
        df = df.rename(lambda x: x.replace(&#39;/&#39;, &#39;.&#39;), axis=&#39;columns&#39;)
        return df

    def filter(self, filter: Callable[[ROOTVariables], bool]) -&gt; JIDENNDataset:
        &#34;&#34;&#34;Filters the dataset using the `filter` function. 

        Args:
            filter (Callable[[ROOTVariables], bool]): Function to apply to the data.

        Raises:
            ValueError: If the dataset is not loaded yet.

        Returns:
            JIDENNDataset: The JIDENNDataset object with the dataset filtered.
        &#34;&#34;&#34;
        if self.dataset is None:
            raise ValueError(&#39;Dataset not loaded yet.&#39;)
        dataset = self.dataset.filter(filter)
        return self._set_dataset(dataset)

    def get_prepared_dataset(self,
                             batch_size: int,
                             assert_length: bool = False,
                             shuffle_buffer_size: Optional[int] = None,
                             take: Optional[int] = None,
                             map_func: Optional[Callable[[Union[ROOTVariables, Tuple[ROOTVariables, ROOTVariables]], Any], Tuple[Union[ROOTVariables, Tuple[ROOTVariables, ROOTVariables]], Any]]] = None) -&gt; tf.data.Dataset:
        &#34;&#34;&#34;Returns a prepared dataset for training. The dataset is prepared by stacking the arrays in the `ROOTVariables` in the dataset using `dict_to_stacked_array`.
        The dataset is also batched, shuffled, shortend (using `take`) and mapped using the `map_func` function. The function is applied before the input is stacked.

        **Train input must be created with `JIDENNDataset.create_train_input` before calling this method.**  

        The assertion allows displaying the estimated epoch time during training. The assertion is only performed if `take` is set.

        Args:
            batch_size (int): Batch size of the dataset.
            assert_length (bool, optional): If `True`, the dataset is asserted to have the `take` length. It is only used if &#39;take&#39; is set. Defaults to False.
            shuffle_buffer_size (int, optional): Size of the shuffle buffer. If `None`, the dataset is not shuffled. Defaults to None.
            take (int, optional): Number of elements to take from the dataset. If `None`, the dataset is not taken. Defaults to None.
            map_func (Callable[[Union[ROOTVariables, Tuple[ROOTVariables, ROOTVariables]], Any], Tuple[Union[ROOTVariables, Tuple[ROOTVariables, ROOTVariables]], Any]], optional): Function to apply to the dataset. Defaults to None.

        Raises:
            ValueError: If the dataset is not loaded yet.

        Returns:
            tf.data.Dataset: The prepared dataset.
        &#34;&#34;&#34;

        if self.dataset is None:
            raise ValueError(&#39;Dataset not loaded yet.&#39;)
        if map_func is not None:
            dataset = self.dataset.map(map_func)
        else:
            dataset = self.dataset.map(dict_to_stacked_array)
        dataset = dataset.shuffle(
            shuffle_buffer_size) if shuffle_buffer_size is not None else dataset
        if take is not None:
            dataset = dataset.take(take)
            dataset = dataset.apply(tf.data.experimental.assert_cardinality(
                take)) if assert_length else dataset
        dataset = dataset.apply(
            tf.data.experimental.dense_to_ragged_batch(batch_size))
        # dataset = dataset.ragged_batch(batch_size)
        dataset = dataset.prefetch(tf.data.AUTOTUNE)
        return dataset

    def plot_data_distributions(self,
                                folder: str,
                                variables: Optional[List[str]] = None,
                                hue_variable: Optional[str] = None,
                                named_labels: Optional[Dict[int, str]] = None,
                                xlabel_mapper: Optional[Dict[str, str]] = None) -&gt; None:
        &#34;&#34;&#34;Plots the data distributions of the dataset. The dataset must be loaded before calling this function.
        The function uses `jidenn.evaluation.plotter.plot_data_distributions` to plot the data distributions.

        Args:
            folder (str): The path to the directory where the plots are saved.
            variables (Optional[List[str]], optional): List of variables to plot. If `None`, all variables are plotted. Defaults to `None`.
            named_labels (Dict[int, str], optional): Dictionary mapping truth values to custom labels.
                If not provided, the truth values will be used as labels. 

        Raises:
            ValueError: If the dataset is not loaded yet.

        Returns:
            None
        &#34;&#34;&#34;
        if self.dataset is None:
            raise ValueError(&#39;Dataset not loaded yet.&#39;)
        df = self.to_pandas(variables)
        plot_data_distributions(df, folder=folder, named_labels=named_labels,
                                xlabel_mapper=xlabel_mapper, hue_variable=hue_variable)</code></pre>
</details>
<h3>Class variables</h3>
<dl>
<dt id="jidenn.data.JIDENNDataset.JIDENNDataset.target"><code class="name">var <span class="ident">target</span> :Â Optional[str]</code></dt>
<dd>
<div class="desc"><p>The name of the target variable. <code>None</code> if no target variable is used.</p></div>
</dd>
<dt id="jidenn.data.JIDENNDataset.JIDENNDataset.variables"><code class="name">var <span class="ident">variables</span> :Â Optional[List[str]]</code></dt>
<dd>
<div class="desc"><p>The configuration dataclass of the variables to be used in the dataset.
If <code>None</code>, the variables are set automatically during loading with JIDENNDataset.load().</p></div>
</dd>
<dt id="jidenn.data.JIDENNDataset.JIDENNDataset.weight"><code class="name">var <span class="ident">weight</span> :Â Optional[str]</code></dt>
<dd>
<div class="desc"><p>The name of the weight variable. <code>None</code> if no weight variable is used.</p></div>
</dd>
</dl>
<h3>Static methods</h3>
<dl>
<dt id="jidenn.data.JIDENNDataset.JIDENNDataset.combine"><code class="name flex">
<span>def <span class="ident">combine</span></span>(<span>datasets:Â List[<a title="jidenn.data.JIDENNDataset.JIDENNDataset" href="#jidenn.data.JIDENNDataset.JIDENNDataset">JIDENNDataset</a>], weights:Â List[float]) â€‘>Â <a title="jidenn.data.JIDENNDataset.JIDENNDataset" href="#jidenn.data.JIDENNDataset.JIDENNDataset">JIDENNDataset</a></span>
</code></dt>
<dd>
<div class="desc"><p>Combines multiple datasets into one dataset. The samples are interleaved and the weights are used to sample from the datasets.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>datasets</code></strong> :&ensp;<code>List[<a title="jidenn.data.JIDENNDataset.JIDENNDataset" href="#jidenn.data.JIDENNDataset.JIDENNDataset">JIDENNDataset</a>]</code></dt>
<dd>List of datasets to combined. All <code><a title="jidenn.data.JIDENNDataset.JIDENNDataset.dataset" href="#jidenn.data.JIDENNDataset.JIDENNDataset.dataset">JIDENNDataset.dataset</a></code>s must be set and have the same <code>element_spec</code>.</dd>
<dt><strong><code>weights</code></strong> :&ensp;<code>List[float]</code></dt>
<dd>List of weights for each dataset. The weights are used to sample from the datasets.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="jidenn.data.JIDENNDataset.JIDENNDataset" href="#jidenn.data.JIDENNDataset.JIDENNDataset">JIDENNDataset</a></code></dt>
<dd>Combined <code><a title="jidenn.data.JIDENNDataset.JIDENNDataset" href="#jidenn.data.JIDENNDataset.JIDENNDataset">JIDENNDataset</a></code> object.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def combine(datasets: List[JIDENNDataset], weights: List[float]) -&gt; JIDENNDataset:
    &#34;&#34;&#34;Combines multiple datasets into one dataset. The samples are interleaved and the weights are used to sample from the datasets.

    Args:
        datasets (List[JIDENNDataset]): List of datasets to combined. All `JIDENNDataset.dataset`s must be set and have the same `element_spec`.
        weights (List[float]): List of weights for each dataset. The weights are used to sample from the datasets.

    Returns:
        JIDENNDataset: Combined `JIDENNDataset` object.
    &#34;&#34;&#34;
    dataset = tf.data.Dataset.sample_from_datasets(
        [dataset.dataset for dataset in datasets], weights=weights)
    jidenn_dataset = JIDENNDataset(
        datasets[0].variables, datasets[0].target, datasets[0].weight)
    return jidenn_dataset._set_dataset(dataset)</code></pre>
</details>
</dd>
<dt id="jidenn.data.JIDENNDataset.JIDENNDataset.load"><code class="name flex">
<span>def <span class="ident">load</span></span>(<span>path:Â str, element_spec_path:Â Optional[str]Â =Â None) â€‘>Â <a title="jidenn.data.JIDENNDataset.JIDENNDataset" href="#jidenn.data.JIDENNDataset.JIDENNDataset">JIDENNDataset</a></span>
</code></dt>
<dd>
<div class="desc"><p>Loads a dataset from a file. The dataset is stored in the <code>tf.data.Dataset</code> format.
The assumed dataset elements are <code><a title="jidenn.data.JIDENNDataset.ROOTVariables" href="#jidenn.data.JIDENNDataset.ROOTVariables">ROOTVariables</a></code> dictionaries or a tuple of <code><a title="jidenn.data.JIDENNDataset.ROOTVariables" href="#jidenn.data.JIDENNDataset.ROOTVariables">ROOTVariables</a></code>, <code>label</code> and <code>weight</code>.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>path</code></strong> :&ensp;<code>str</code></dt>
<dd>The path to the dataset directory.</dd>
<dt><strong><code>element_spec_path</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>The path to the <code>element_spec</code> file. Defaults to <code>None</code>.
If <code>None</code>, the <code>element_spec</code> is loaded from the <code>element_spec</code> file inside the dataset directory.</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>ValueError</code></dt>
<dd>If the <code>element_spec</code> is not a dictionary or a tuple whose first element is a dictionary.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="jidenn.data.JIDENNDataset.JIDENNDataset" href="#jidenn.data.JIDENNDataset.JIDENNDataset">JIDENNDataset</a></code></dt>
<dd>The JIDENNDataset object with set dataset and <code>element_spec</code>.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@staticmethod
def load(path: str, element_spec_path: Optional[str] = None) -&gt; JIDENNDataset:
    &#34;&#34;&#34;Loads a dataset from a file. The dataset is stored in the `tf.data.Dataset` format.
    The assumed dataset elements are `ROOTVariables` dictionaries or a tuple of `ROOTVariables`, `label` and `weight`.

    Args:
        path (str): The path to the dataset directory.
        element_spec_path (str, optional): The path to the `element_spec` file. Defaults to `None`. 
            If `None`, the `element_spec` is loaded from the `element_spec` file inside the dataset directory.

    Raises:
        ValueError: If the `element_spec` is not a dictionary or a tuple whose first element is a dictionary.

    Returns:
        JIDENNDataset: The JIDENNDataset object with set dataset and `element_spec`.
    &#34;&#34;&#34;

    if element_spec_path is None:
        element_spec_path = os.path.join(path, &#39;element_spec&#39;)
    with open(element_spec_path, &#39;rb&#39;) as f:
        element_spec = pickle.load(f)

    if isinstance(element_spec, dict):
        variables = list(element_spec.keys())

    elif isinstance(element_spec[0], dict):
        variables = list(element_spec[0].keys())

    else:
        raise ValueError(&#39;Element spec is not a dictionary.&#39;)

    return JIDENNDataset(variables=variables).load_dataset(path)</code></pre>
</details>
</dd>
</dl>
<h3>Instance variables</h3>
<dl>
<dt id="jidenn.data.JIDENNDataset.JIDENNDataset.dataset"><code class="name">var <span class="ident">dataset</span> :Â Optional[tensorflow.python.data.ops.dataset_ops.DatasetV2]</code></dt>
<dd>
<div class="desc"><p>The <code>tf.data.Dataset</code> object or <code>None</code> if the dataset is not set yet.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def dataset(self) -&gt; Union[tf.data.Dataset, None]:
    &#34;&#34;&#34;The `tf.data.Dataset` object or `None` if the dataset is not set yet.&#34;&#34;&#34;
    return self._dataset</code></pre>
</details>
</dd>
<dt id="jidenn.data.JIDENNDataset.JIDENNDataset.element_spec"><code class="name">var <span class="ident">element_spec</span> :Â Optional[Dict[str,Â Union[tensorflow.python.framework.tensor_spec.TensorSpec,Â tensorflow.python.ops.ragged.ragged_tensor.RaggedTensorSpec]]]</code></dt>
<dd>
<div class="desc"><p>The <code>element_spec</code> of the dataset or <code>None</code> if the dataset is not set yet.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def element_spec(self) -&gt; Union[Dict[str, Union[tf.TensorSpec, tf.RaggedTensorSpec]], None]:
    &#34;&#34;&#34;The `element_spec` of the dataset or `None` if the dataset is not set yet.&#34;&#34;&#34;
    return self._element_spec</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="jidenn.data.JIDENNDataset.JIDENNDataset.apply"><code class="name flex">
<span>def <span class="ident">apply</span></span>(<span>self, func:Â Callable[[tf.data.Dataset],Â tf.data.Dataset]) â€‘>Â <a title="jidenn.data.JIDENNDataset.JIDENNDataset" href="#jidenn.data.JIDENNDataset.JIDENNDataset">JIDENNDataset</a></span>
</code></dt>
<dd>
<div class="desc"><p>Applies a function to the dataset.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>func</code></strong> :&ensp;<code>Callable[[tf.data.Dataset], tf.data.Dataset]</code></dt>
<dd>Function to apply to the dataset.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="jidenn.data.JIDENNDataset.JIDENNDataset" href="#jidenn.data.JIDENNDataset.JIDENNDataset">JIDENNDataset</a></code></dt>
<dd>The JIDENNDataset object with the dataset modified by the function.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def apply(self, func: Callable[[tf.data.Dataset], tf.data.Dataset]) -&gt; JIDENNDataset:
    &#34;&#34;&#34;Applies a function to the dataset.

    Args:
        func (Callable[[tf.data.Dataset], tf.data.Dataset]): Function to apply to the dataset.

    Returns:
        JIDENNDataset: The JIDENNDataset object with the dataset modified by the function.

    &#34;&#34;&#34;
    if self.dataset is None:
        raise ValueError(&#39;Dataset not loaded yet.&#39;)
    dataset = func(self.dataset)
    return self._set_dataset(dataset)</code></pre>
</details>
</dd>
<dt id="jidenn.data.JIDENNDataset.JIDENNDataset.create_train_input"><code class="name flex">
<span>def <span class="ident">create_train_input</span></span>(<span>self, func:Â Callable[[<a title="jidenn.data.JIDENNDataset.ROOTVariables" href="#jidenn.data.JIDENNDataset.ROOTVariables">ROOTVariables</a>],Â Union[<a title="jidenn.data.JIDENNDataset.ROOTVariables" href="#jidenn.data.JIDENNDataset.ROOTVariables">ROOTVariables</a>,Â Tuple[<a title="jidenn.data.JIDENNDataset.ROOTVariables" href="#jidenn.data.JIDENNDataset.ROOTVariables">ROOTVariables</a>,Â <a title="jidenn.data.JIDENNDataset.ROOTVariables" href="#jidenn.data.JIDENNDataset.ROOTVariables">ROOTVariables</a>]]]) â€‘>Â <a title="jidenn.data.JIDENNDataset.JIDENNDataset" href="#jidenn.data.JIDENNDataset.JIDENNDataset">JIDENNDataset</a></span>
</code></dt>
<dd>
<div class="desc"><p>Creates a training input from the dataset using the <code>func</code> function. The function must take a <code><a title="jidenn.data.JIDENNDataset.ROOTVariables" href="#jidenn.data.JIDENNDataset.ROOTVariables">ROOTVariables</a></code> object and return a <code><a title="jidenn.data.JIDENNDataset.ROOTVariables" href="#jidenn.data.JIDENNDataset.ROOTVariables">ROOTVariables</a></code> object.
The output of the function is of the form Dict[str, tf.Tensor] or Tuple[Dict[str, tf.Tensor], Dict[str, tf.Tensor]] (optionally aslo tf.RaggedTensor).</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>func</code></strong> :&ensp;<code>Callable[[<a title="jidenn.data.JIDENNDataset.ROOTVariables" href="#jidenn.data.JIDENNDataset.ROOTVariables">ROOTVariables</a>], Union[<a title="jidenn.data.JIDENNDataset.ROOTVariables" href="#jidenn.data.JIDENNDataset.ROOTVariables">ROOTVariables</a>, Tuple[<a title="jidenn.data.JIDENNDataset.ROOTVariables" href="#jidenn.data.JIDENNDataset.ROOTVariables">ROOTVariables</a>, <a title="jidenn.data.JIDENNDataset.ROOTVariables" href="#jidenn.data.JIDENNDataset.ROOTVariables">ROOTVariables</a>]]]</code></dt>
<dd>Function to apply to the data to create the training input.</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>ValueError</code></dt>
<dd>If the dataset is not loaded yet.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="jidenn.data.JIDENNDataset.JIDENNDataset" href="#jidenn.data.JIDENNDataset.JIDENNDataset">JIDENNDataset</a></code></dt>
<dd>The JIDENNDataset object
with signature <code>((<a title="jidenn.data.JIDENNDataset.ROOTVariables" href="#jidenn.data.JIDENNDataset.ROOTVariables">ROOTVariables</a>, <a title="jidenn.data.JIDENNDataset.ROOTVariables" href="#jidenn.data.JIDENNDataset.ROOTVariables">ROOTVariables</a>), &hellip;)</code> or <code>(<a title="jidenn.data.JIDENNDataset.ROOTVariables" href="#jidenn.data.JIDENNDataset.ROOTVariables">ROOTVariables</a>, &hellip;)</code>.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def create_train_input(self, func: Callable[[ROOTVariables], Union[ROOTVariables, Tuple[ROOTVariables, ROOTVariables]]]) -&gt; JIDENNDataset:
    &#34;&#34;&#34;Creates a training input from the dataset using the `func` function. The function must take a `ROOTVariables` object and return a `ROOTVariables` object.
    The output of the function is of the form Dict[str, tf.Tensor] or Tuple[Dict[str, tf.Tensor], Dict[str, tf.Tensor]] (optionally aslo tf.RaggedTensor).


    Args:
        func (Callable[[ROOTVariables], Union[ROOTVariables, Tuple[ROOTVariables, ROOTVariables]]]): Function to apply to the data to create the training input.

    Raises:
        ValueError: If the dataset is not loaded yet.

    Returns:
        JIDENNDataset: The JIDENNDataset object  with signature `((ROOTVariables, ROOTVariables), ...)` or `(ROOTVariables, ...)`.
    &#34;&#34;&#34;
    if self.dataset is None:
        raise ValueError(&#39;Dataset not loaded yet.&#39;)

    @tf.function
    def input_wrapper(data, label, w=None):
        return func(data), label
    dataset = self.dataset.map(input_wrapper)
    return self._set_dataset(dataset)</code></pre>
</details>
</dd>
<dt id="jidenn.data.JIDENNDataset.JIDENNDataset.create_variables"><code class="name flex">
<span>def <span class="ident">create_variables</span></span>(<span>self, cut:Â Optional[Cut]Â =Â None, map_dataset:Â Optional[Callable[[<a title="jidenn.data.JIDENNDataset.ROOTVariables" href="#jidenn.data.JIDENNDataset.ROOTVariables">ROOTVariables</a>],Â <a title="jidenn.data.JIDENNDataset.ROOTVariables" href="#jidenn.data.JIDENNDataset.ROOTVariables">ROOTVariables</a>]]Â =Â None) â€‘>Â <a title="jidenn.data.JIDENNDataset.JIDENNDataset" href="#jidenn.data.JIDENNDataset.JIDENNDataset">JIDENNDataset</a></span>
</code></dt>
<dd>
<div class="desc"><p>Creates a 'tf.data.Dataset' from selected variables and creates labels and weights.
The variables are selected according to the <code>variables</code> loaded from config.
the <code>target</code> and <code>weight</code> class variables are used to create labels and weights from the <code><a title="jidenn.data.JIDENNDataset.ROOTVariables" href="#jidenn.data.JIDENNDataset.ROOTVariables">ROOTVariables</a></code>.</p>
<p>Optionally, a <code>Cut</code> can be applied to the dataset. It is done <strong>before</strong> the variables are selected.
The <code>map_dataset</code> function can be used to apply a function to the dataset before the variables are selected.
It could be used to create new variables from the existing ones.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>cut</code></strong> :&ensp;<code>jidenn.data.utils.Cut.Cut</code>, optional</dt>
<dd>The <code>Cut</code> object to be applied to the dataset. Defaults to <code>None</code>. </dd>
<dt><strong><code>map_dataset</code></strong> :&ensp;<code>Callable[[<a title="jidenn.data.JIDENNDataset.ROOTVariables" href="#jidenn.data.JIDENNDataset.ROOTVariables">ROOTVariables</a>], <a title="jidenn.data.JIDENNDataset.ROOTVariables" href="#jidenn.data.JIDENNDataset.ROOTVariables">ROOTVariables</a>]</code>, optional</dt>
<dd>The function to be applied to the dataset using <code>tf.data.Dataset.map</code>. Defaults to <code>None</code>.</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>ValueError</code></dt>
<dd>If the dataset is not loaded yet.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="jidenn.data.JIDENNDataset.JIDENNDataset" href="#jidenn.data.JIDENNDataset.JIDENNDataset">JIDENNDataset</a></code></dt>
<dd>The JIDENNDataset object with the signature of <code>(<a title="jidenn.data.JIDENNDataset.ROOTVariables" href="#jidenn.data.JIDENNDataset.ROOTVariables">ROOTVariables</a>, label, weight)</code>.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def create_variables(self, cut: Optional[Cut] = None, map_dataset: Optional[Callable[[ROOTVariables], ROOTVariables]] = None) -&gt; JIDENNDataset:
    &#34;&#34;&#34;Creates a &#39;tf.data.Dataset&#39; from selected variables and creates labels and weights.
    The variables are selected according to the `variables` loaded from config.
    the `target` and `weight` class variables are used to create labels and weights from the `ROOTVariables`.

    Optionally, a `Cut` can be applied to the dataset. It is done **before** the variables are selected.
    The `map_dataset` function can be used to apply a function to the dataset before the variables are selected.
    It could be used to create new variables from the existing ones.

    Args:
        cut (jidenn.data.utils.Cut.Cut, optional): The `Cut` object to be applied to the dataset. Defaults to `None`. 
        map_dataset (Callable[[ROOTVariables], ROOTVariables], optional): The function to be applied to the dataset using `tf.data.Dataset.map`. Defaults to `None`.

    Raises:
        ValueError: If the dataset is not loaded yet.

    Returns:
        JIDENNDataset: The JIDENNDataset object with the signature of `(ROOTVariables, label, weight)`.
    &#34;&#34;&#34;
    if self.dataset is None:
        raise ValueError(&#39;Dataset not loaded yet.&#39;)
    if map_dataset is not None:
        dataset = self.dataset.map(map_dataset)
    else:
        dataset = self.dataset

    dataset = dataset.filter(cut) if cut is not None else dataset
    dataset = dataset.map(self._var_picker)
    return self._set_dataset(dataset)</code></pre>
</details>
</dd>
<dt id="jidenn.data.JIDENNDataset.JIDENNDataset.filter"><code class="name flex">
<span>def <span class="ident">filter</span></span>(<span>self, filter:Â Callable[[<a title="jidenn.data.JIDENNDataset.ROOTVariables" href="#jidenn.data.JIDENNDataset.ROOTVariables">ROOTVariables</a>],Â bool]) â€‘>Â <a title="jidenn.data.JIDENNDataset.JIDENNDataset" href="#jidenn.data.JIDENNDataset.JIDENNDataset">JIDENNDataset</a></span>
</code></dt>
<dd>
<div class="desc"><p>Filters the dataset using the <code>filter</code> function. </p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>filter</code></strong> :&ensp;<code>Callable[[<a title="jidenn.data.JIDENNDataset.ROOTVariables" href="#jidenn.data.JIDENNDataset.ROOTVariables">ROOTVariables</a>], bool]</code></dt>
<dd>Function to apply to the data.</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>ValueError</code></dt>
<dd>If the dataset is not loaded yet.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="jidenn.data.JIDENNDataset.JIDENNDataset" href="#jidenn.data.JIDENNDataset.JIDENNDataset">JIDENNDataset</a></code></dt>
<dd>The JIDENNDataset object with the dataset filtered.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def filter(self, filter: Callable[[ROOTVariables], bool]) -&gt; JIDENNDataset:
    &#34;&#34;&#34;Filters the dataset using the `filter` function. 

    Args:
        filter (Callable[[ROOTVariables], bool]): Function to apply to the data.

    Raises:
        ValueError: If the dataset is not loaded yet.

    Returns:
        JIDENNDataset: The JIDENNDataset object with the dataset filtered.
    &#34;&#34;&#34;
    if self.dataset is None:
        raise ValueError(&#39;Dataset not loaded yet.&#39;)
    dataset = self.dataset.filter(filter)
    return self._set_dataset(dataset)</code></pre>
</details>
</dd>
<dt id="jidenn.data.JIDENNDataset.JIDENNDataset.get_prepared_dataset"><code class="name flex">
<span>def <span class="ident">get_prepared_dataset</span></span>(<span>self, batch_size:Â int, assert_length:Â boolÂ =Â False, shuffle_buffer_size:Â Optional[int]Â =Â None, take:Â Optional[int]Â =Â None, map_func:Â Optional[Callable[[Union[<a title="jidenn.data.JIDENNDataset.ROOTVariables" href="#jidenn.data.JIDENNDataset.ROOTVariables">ROOTVariables</a>,Â Tuple[<a title="jidenn.data.JIDENNDataset.ROOTVariables" href="#jidenn.data.JIDENNDataset.ROOTVariables">ROOTVariables</a>,Â <a title="jidenn.data.JIDENNDataset.ROOTVariables" href="#jidenn.data.JIDENNDataset.ROOTVariables">ROOTVariables</a>]],Â Any],Â Tuple[Union[<a title="jidenn.data.JIDENNDataset.ROOTVariables" href="#jidenn.data.JIDENNDataset.ROOTVariables">ROOTVariables</a>,Â Tuple[<a title="jidenn.data.JIDENNDataset.ROOTVariables" href="#jidenn.data.JIDENNDataset.ROOTVariables">ROOTVariables</a>,Â <a title="jidenn.data.JIDENNDataset.ROOTVariables" href="#jidenn.data.JIDENNDataset.ROOTVariables">ROOTVariables</a>]],Â Any]]]Â =Â None) â€‘>Â tensorflow.python.data.ops.dataset_ops.DatasetV2</span>
</code></dt>
<dd>
<div class="desc"><p>Returns a prepared dataset for training. The dataset is prepared by stacking the arrays in the <code><a title="jidenn.data.JIDENNDataset.ROOTVariables" href="#jidenn.data.JIDENNDataset.ROOTVariables">ROOTVariables</a></code> in the dataset using <code><a title="jidenn.data.JIDENNDataset.dict_to_stacked_array" href="#jidenn.data.JIDENNDataset.dict_to_stacked_array">dict_to_stacked_array()</a></code>.
The dataset is also batched, shuffled, shortend (using <code>take</code>) and mapped using the <code>map_func</code> function. The function is applied before the input is stacked.</p>
<p><strong>Train input must be created with <code><a title="jidenn.data.JIDENNDataset.JIDENNDataset.create_train_input" href="#jidenn.data.JIDENNDataset.JIDENNDataset.create_train_input">JIDENNDataset.create_train_input()</a></code> before calling this method.</strong>
</p>
<p>The assertion allows displaying the estimated epoch time during training. The assertion is only performed if <code>take</code> is set.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>batch_size</code></strong> :&ensp;<code>int</code></dt>
<dd>Batch size of the dataset.</dd>
<dt><strong><code>assert_length</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>If <code>True</code>, the dataset is asserted to have the <code>take</code> length. It is only used if 'take' is set. Defaults to False.</dd>
<dt><strong><code>shuffle_buffer_size</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Size of the shuffle buffer. If <code>None</code>, the dataset is not shuffled. Defaults to None.</dd>
<dt><strong><code>take</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Number of elements to take from the dataset. If <code>None</code>, the dataset is not taken. Defaults to None.</dd>
<dt><strong><code>map_func</code></strong> :&ensp;<code>Callable[[Union[<a title="jidenn.data.JIDENNDataset.ROOTVariables" href="#jidenn.data.JIDENNDataset.ROOTVariables">ROOTVariables</a>, Tuple[<a title="jidenn.data.JIDENNDataset.ROOTVariables" href="#jidenn.data.JIDENNDataset.ROOTVariables">ROOTVariables</a>, <a title="jidenn.data.JIDENNDataset.ROOTVariables" href="#jidenn.data.JIDENNDataset.ROOTVariables">ROOTVariables</a>]], Any], Tuple[Union[<a title="jidenn.data.JIDENNDataset.ROOTVariables" href="#jidenn.data.JIDENNDataset.ROOTVariables">ROOTVariables</a>, Tuple[<a title="jidenn.data.JIDENNDataset.ROOTVariables" href="#jidenn.data.JIDENNDataset.ROOTVariables">ROOTVariables</a>, <a title="jidenn.data.JIDENNDataset.ROOTVariables" href="#jidenn.data.JIDENNDataset.ROOTVariables">ROOTVariables</a>]], Any]]</code>, optional</dt>
<dd>Function to apply to the dataset. Defaults to None.</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>ValueError</code></dt>
<dd>If the dataset is not loaded yet.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>tf.data.Dataset</code></dt>
<dd>The prepared dataset.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_prepared_dataset(self,
                         batch_size: int,
                         assert_length: bool = False,
                         shuffle_buffer_size: Optional[int] = None,
                         take: Optional[int] = None,
                         map_func: Optional[Callable[[Union[ROOTVariables, Tuple[ROOTVariables, ROOTVariables]], Any], Tuple[Union[ROOTVariables, Tuple[ROOTVariables, ROOTVariables]], Any]]] = None) -&gt; tf.data.Dataset:
    &#34;&#34;&#34;Returns a prepared dataset for training. The dataset is prepared by stacking the arrays in the `ROOTVariables` in the dataset using `dict_to_stacked_array`.
    The dataset is also batched, shuffled, shortend (using `take`) and mapped using the `map_func` function. The function is applied before the input is stacked.

    **Train input must be created with `JIDENNDataset.create_train_input` before calling this method.**  

    The assertion allows displaying the estimated epoch time during training. The assertion is only performed if `take` is set.

    Args:
        batch_size (int): Batch size of the dataset.
        assert_length (bool, optional): If `True`, the dataset is asserted to have the `take` length. It is only used if &#39;take&#39; is set. Defaults to False.
        shuffle_buffer_size (int, optional): Size of the shuffle buffer. If `None`, the dataset is not shuffled. Defaults to None.
        take (int, optional): Number of elements to take from the dataset. If `None`, the dataset is not taken. Defaults to None.
        map_func (Callable[[Union[ROOTVariables, Tuple[ROOTVariables, ROOTVariables]], Any], Tuple[Union[ROOTVariables, Tuple[ROOTVariables, ROOTVariables]], Any]], optional): Function to apply to the dataset. Defaults to None.

    Raises:
        ValueError: If the dataset is not loaded yet.

    Returns:
        tf.data.Dataset: The prepared dataset.
    &#34;&#34;&#34;

    if self.dataset is None:
        raise ValueError(&#39;Dataset not loaded yet.&#39;)
    if map_func is not None:
        dataset = self.dataset.map(map_func)
    else:
        dataset = self.dataset.map(dict_to_stacked_array)
    dataset = dataset.shuffle(
        shuffle_buffer_size) if shuffle_buffer_size is not None else dataset
    if take is not None:
        dataset = dataset.take(take)
        dataset = dataset.apply(tf.data.experimental.assert_cardinality(
            take)) if assert_length else dataset
    dataset = dataset.apply(
        tf.data.experimental.dense_to_ragged_batch(batch_size))
    # dataset = dataset.ragged_batch(batch_size)
    dataset = dataset.prefetch(tf.data.AUTOTUNE)
    return dataset</code></pre>
</details>
</dd>
<dt id="jidenn.data.JIDENNDataset.JIDENNDataset.load_dataset"><code class="name flex">
<span>def <span class="ident">load_dataset</span></span>(<span>self, file:Â str) â€‘>Â <a title="jidenn.data.JIDENNDataset.JIDENNDataset" href="#jidenn.data.JIDENNDataset.JIDENNDataset">JIDENNDataset</a></span>
</code></dt>
<dd>
<div class="desc"><p>Loads a dataset from a file. The dataset is stored in the <code>tf.data.Dataset</code> format.
The <code>element_spec</code> is loaded from the <code>element_spec</code> file inside the dataset directory.
<br>
Alternatively, the <code>element_spec</code> can be loaded manually using the <code>load_element_spec</code> method.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>file</code></strong> :&ensp;<code>str</code></dt>
<dd>The path to the dataset directory.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="jidenn.data.JIDENNDataset.JIDENNDataset" href="#jidenn.data.JIDENNDataset.JIDENNDataset">JIDENNDataset</a></code></dt>
<dd>The JIDENNDataset object with set dataset and <code>element_spec</code>.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_dataset(self, file: str) -&gt; JIDENNDataset:
    &#34;&#34;&#34;Loads a dataset from a file. The dataset is stored in the `tf.data.Dataset` format.
    The `element_spec` is loaded from the `element_spec` file inside the dataset directory.    
    Alternatively, the `element_spec` can be loaded manually using the `load_element_spec` method.

    Args:
        file (str): The path to the dataset directory.

    Returns:
        JIDENNDataset: The JIDENNDataset object with set dataset and `element_spec`.

    &#34;&#34;&#34;
    if self.element_spec is None:
        element_spec_file = os.path.join(file, &#39;element_spec&#39;)
        jidenn_dataset = self.load_element_spec(element_spec_file)
    else:
        jidenn_dataset = self
    dataset = tf.data.Dataset.load(
        file, compression=&#39;GZIP&#39;, element_spec=jidenn_dataset.element_spec)
    return jidenn_dataset._set_dataset(dataset)</code></pre>
</details>
</dd>
<dt id="jidenn.data.JIDENNDataset.JIDENNDataset.load_element_spec"><code class="name flex">
<span>def <span class="ident">load_element_spec</span></span>(<span>self, file:Â str) â€‘>Â <a title="jidenn.data.JIDENNDataset.JIDENNDataset" href="#jidenn.data.JIDENNDataset.JIDENNDataset">JIDENNDataset</a></span>
</code></dt>
<dd>
<div class="desc"><p>Loads the <code>element_spec</code> from a file. The <code>element_spec</code> is a pickled dictionary of <code>tf.TensorSpec</code> or <code>tf.RaggedTensorSpec</code> objects.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>file</code></strong> :&ensp;<code>str</code></dt>
<dd>The path to the <code>element_spec</code> file.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="jidenn.data.JIDENNDataset.JIDENNDataset" href="#jidenn.data.JIDENNDataset.JIDENNDataset">JIDENNDataset</a></code></dt>
<dd>The JIDENNDataset object with the <code>element_spec</code> set.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_element_spec(self, file: str) -&gt; JIDENNDataset:
    &#34;&#34;&#34;Loads the `element_spec` from a file. The `element_spec` is a pickled dictionary of `tf.TensorSpec` or `tf.RaggedTensorSpec` objects.

    Args:
        file (str): The path to the `element_spec` file.
    Returns:
        JIDENNDataset: The JIDENNDataset object with the `element_spec` set.
    &#34;&#34;&#34;
    with open(file, &#39;rb&#39;) as f:
        element_spec = pickle.load(f)
    return self._set_element_spec(element_spec)</code></pre>
</details>
</dd>
<dt id="jidenn.data.JIDENNDataset.JIDENNDataset.plot_data_distributions"><code class="name flex">
<span>def <span class="ident">plot_data_distributions</span></span>(<span>self, folder:Â str, variables:Â Optional[List[str]]Â =Â None, hue_variable:Â Optional[str]Â =Â None, named_labels:Â Optional[Dict[int,Â str]]Â =Â None, xlabel_mapper:Â Optional[Dict[str,Â str]]Â =Â None) â€‘>Â None</span>
</code></dt>
<dd>
<div class="desc"><p>Plots the data distributions of the dataset. The dataset must be loaded before calling this function.
The function uses <code><a title="jidenn.evaluation.plotter.plot_data_distributions" href="../evaluation/plotter.html#jidenn.evaluation.plotter.plot_data_distributions">plot_data_distributions()</a></code> to plot the data distributions.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>folder</code></strong> :&ensp;<code>str</code></dt>
<dd>The path to the directory where the plots are saved.</dd>
<dt><strong><code>variables</code></strong> :&ensp;<code>Optional[List[str]]</code>, optional</dt>
<dd>List of variables to plot. If <code>None</code>, all variables are plotted. Defaults to <code>None</code>.</dd>
<dt><strong><code>named_labels</code></strong> :&ensp;<code>Dict[int, str]</code>, optional</dt>
<dd>Dictionary mapping truth values to custom labels.
If not provided, the truth values will be used as labels. </dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>ValueError</code></dt>
<dd>If the dataset is not loaded yet.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>None</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plot_data_distributions(self,
                            folder: str,
                            variables: Optional[List[str]] = None,
                            hue_variable: Optional[str] = None,
                            named_labels: Optional[Dict[int, str]] = None,
                            xlabel_mapper: Optional[Dict[str, str]] = None) -&gt; None:
    &#34;&#34;&#34;Plots the data distributions of the dataset. The dataset must be loaded before calling this function.
    The function uses `jidenn.evaluation.plotter.plot_data_distributions` to plot the data distributions.

    Args:
        folder (str): The path to the directory where the plots are saved.
        variables (Optional[List[str]], optional): List of variables to plot. If `None`, all variables are plotted. Defaults to `None`.
        named_labels (Dict[int, str], optional): Dictionary mapping truth values to custom labels.
            If not provided, the truth values will be used as labels. 

    Raises:
        ValueError: If the dataset is not loaded yet.

    Returns:
        None
    &#34;&#34;&#34;
    if self.dataset is None:
        raise ValueError(&#39;Dataset not loaded yet.&#39;)
    df = self.to_pandas(variables)
    plot_data_distributions(df, folder=folder, named_labels=named_labels,
                            xlabel_mapper=xlabel_mapper, hue_variable=hue_variable)</code></pre>
</details>
</dd>
<dt id="jidenn.data.JIDENNDataset.JIDENNDataset.remap_labels"><code class="name flex">
<span>def <span class="ident">remap_labels</span></span>(<span>self, label_mapping:Â Callable[[int],Â int]) â€‘>Â <a title="jidenn.data.JIDENNDataset.JIDENNDataset" href="#jidenn.data.JIDENNDataset.JIDENNDataset">JIDENNDataset</a></span>
</code></dt>
<dd>
<div class="desc"><p>Remaps the labels in the dataset using the <code>label_mapping</code> function.
Should be used after the <code>create_variables</code> method. </p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>label_mapping</code></strong> :&ensp;<code>Callable[[int], int]</code></dt>
<dd>The function that maps the labels.</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>ValueError</code></dt>
<dd>If the dataset is not loaded yet.</dd>
<dt><code>ValueError</code></dt>
<dd>If the <code>target</code> is not set.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="jidenn.data.JIDENNDataset.JIDENNDataset" href="#jidenn.data.JIDENNDataset.JIDENNDataset">JIDENNDataset</a></code></dt>
<dd>The JIDENNDataset object where the <code>label</code> is remapped.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def remap_labels(self, label_mapping: Callable[[int], int]) -&gt; JIDENNDataset:
    &#34;&#34;&#34;Remaps the labels in the dataset using the `label_mapping` function.
    Should be used after the `create_variables` method. 

    Args:
        label_mapping (Callable[[int], int]): The function that maps the labels.

    Raises:
        ValueError: If the dataset is not loaded yet.
        ValueError: If the `target` is not set.

    Returns:
        JIDENNDataset: The JIDENNDataset object where the `label` is remapped.
    &#34;&#34;&#34;
    if self.dataset is None:
        raise ValueError(&#39;Dataset not loaded yet.&#39;)
    if self.target is None:
        raise ValueError(&#39;Target not set yet.&#39;)

    if self.weight is not None:
        @tf.function
        def remap_label(x, y, w):
            return x, label_mapping(y), w
    else:
        @tf.function
        def remap_label(x, y):
            return x, label_mapping(y)

    dataset = self.dataset.map(remap_label)
    return self._set_dataset(dataset)</code></pre>
</details>
</dd>
<dt id="jidenn.data.JIDENNDataset.JIDENNDataset.resample_dataset"><code class="name flex">
<span>def <span class="ident">resample_dataset</span></span>(<span>self, resampling_func:Â Callable[[<a title="jidenn.data.JIDENNDataset.ROOTVariables" href="#jidenn.data.JIDENNDataset.ROOTVariables">ROOTVariables</a>,Â Any],Â int], target_dist:Â List[float])</span>
</code></dt>
<dd>
<div class="desc"><p>Resamples the dataset using the <code>resampling_func</code> function. The function computes the bin index for each sample in the dataset.
The dataset is then resampled to match the <code>target_dist</code> distribution. Be careful that this may <strong>slow down the training process</strong>,
if the target distribution is very different from the original one as the dataset is resampled on the fly and is waiting
for the appropriate sample to be drawn.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>resampling_func</code></strong> :&ensp;<code>Callable[[<a title="jidenn.data.JIDENNDataset.ROOTVariables" href="#jidenn.data.JIDENNDataset.ROOTVariables">ROOTVariables</a>, Any], int]</code></dt>
<dd>Function that bins the data. It must return an integer between 0 and <code>len(target_dist) - 1</code>.</dd>
<dt><strong><code>target_dist</code></strong> :&ensp;<code>List[float]</code></dt>
<dd>The target distribution of the resampled dataset.</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>ValueError</code></dt>
<dd>If the dataset is not loaded yet.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="jidenn.data.JIDENNDataset.JIDENNDataset" href="#jidenn.data.JIDENNDataset.JIDENNDataset">JIDENNDataset</a></code></dt>
<dd>The JIDENNDataset object where the dataset is resampled.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def resample_dataset(self, resampling_func: Callable[[ROOTVariables, Any], int], target_dist: List[float]):
    &#34;&#34;&#34;Resamples the dataset using the `resampling_func` function. The function computes the bin index for each sample in the dataset. 
    The dataset is then resampled to match the `target_dist` distribution. Be careful that this may **slow down the training process**,
    if the target distribution is very different from the original one as the dataset is resampled on the fly and is waiting 
    for the appropriate sample to be drawn.

    Args:
        resampling_func (Callable[[ROOTVariables, Any], int]): Function that bins the data. It must return an integer between 0 and `len(target_dist) - 1`.
        target_dist (List[float]): The target distribution of the resampled dataset.

    Raises:
        ValueError: If the dataset is not loaded yet.

    Returns:
        JIDENNDataset: The JIDENNDataset object where the dataset is resampled.
    &#34;&#34;&#34;
    if self.dataset is None:
        raise ValueError(&#39;Dataset not loaded yet.&#39;)

    @tf.function
    def _data_only(x, data):
        return data
    dataset = self.dataset.rejection_resample(
        resampling_func, target_dist=target_dist).map(_data_only)
    return self._set_dataset(dataset)</code></pre>
</details>
</dd>
<dt id="jidenn.data.JIDENNDataset.JIDENNDataset.save_dataset"><code class="name flex">
<span>def <span class="ident">save_dataset</span></span>(<span>self, file:Â str, num_shards:Â Optional[int]Â =Â None) â€‘>Â None</span>
</code></dt>
<dd>
<div class="desc"><p>Saves the dataset to a file. The dataset is stored in the <code>tf.data.Dataset</code> format.
The <code>element_spec</code> is stored in the <code>element_spec</code> file inside the dataset directory.
Tensorflow saves the <code>element_spec.pb</code> automatically, but manual save is required
for further processing of the dataset.
Ternsorflow file has the <code>.pb</code> extension.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>file</code></strong> :&ensp;<code>str</code></dt>
<dd>The path to the dataset directory.</dd>
<dt><strong><code>num_shards</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>The number of shards to split the dataset into. Defaults to <code>None</code>. The sharding is done uniformly into <code>num_shards</code> files.</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>ValueError</code></dt>
<dd>If the dataset is not loaded yet.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>None</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def save_dataset(self, file: str, num_shards: Optional[int] = None) -&gt; None:
    &#34;&#34;&#34;Saves the dataset to a file. The dataset is stored in the `tf.data.Dataset` format.
    The `element_spec` is stored in the `element_spec` file inside the dataset directory.
    Tensorflow saves the `element_spec.pb` automatically, but manual save is required 
    for further processing of the dataset.  Ternsorflow file has the `.pb` extension.

    Args:
        file (str): The path to the dataset directory.
        num_shards (int, optional): The number of shards to split the dataset into. Defaults to `None`. The sharding is done uniformly into `num_shards` files.

    Raises:
        ValueError: If the dataset is not loaded yet.

    Returns:
        None
    &#34;&#34;&#34;

    if self.dataset is None:
        raise ValueError(&#39;Dataset not loaded yet.&#39;)

    @tf.function
    def random_shards(_) -&gt; tf.Tensor:
        return tf.random.uniform(shape=[], minval=0, maxval=num_shards, dtype=tf.int64)

    self.dataset.save(file, compression=&#39;GZIP&#39;,
                      shard_func=random_shards if num_shards is not None else None)
    with open(os.path.join(file, &#39;element_spec&#39;), &#39;wb&#39;) as f:
        pickle.dump(self.dataset.element_spec, f)</code></pre>
</details>
</dd>
<dt id="jidenn.data.JIDENNDataset.JIDENNDataset.set_dataset"><code class="name flex">
<span>def <span class="ident">set_dataset</span></span>(<span>self, dataset:Â tf.data.Dataset, element_spec:Â Dict[str,Â Union[tf.TensorSpec,Â tf.RaggedTensorSpec]]) â€‘>Â <a title="jidenn.data.JIDENNDataset.JIDENNDataset" href="#jidenn.data.JIDENNDataset.JIDENNDataset">JIDENNDataset</a></span>
</code></dt>
<dd>
<div class="desc"><p>Sets the <code>tf.data.Dataset</code> object and the <code>element_spec</code> of the dataset.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>dataset</code></strong> :&ensp;<code>tf.data.Dataset</code></dt>
<dd>The <code>tf.data.Dataset</code> object consisting of <code><a title="jidenn.data.JIDENNDataset.ROOTVariables" href="#jidenn.data.JIDENNDataset.ROOTVariables">ROOTVariables</a></code>.</dd>
<dt><strong><code>element_spec</code></strong> :&ensp;<code>Dict[str, Union[tf.TensorSpec, tf.RaggedTensorSpec]]</code></dt>
<dd>The <code>element_spec</code> of the dataset.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="jidenn.data.JIDENNDataset.JIDENNDataset" href="#jidenn.data.JIDENNDataset.JIDENNDataset">JIDENNDataset</a></code></dt>
<dd>The JIDENNDataset object with the <code>dataset</code> and <code>element_spec</code> set.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def set_dataset(self, dataset: tf.data.Dataset, element_spec: Dict[str, Union[tf.TensorSpec, tf.RaggedTensorSpec]]) -&gt; JIDENNDataset:
    &#34;&#34;&#34;Sets the `tf.data.Dataset` object and the `element_spec` of the dataset.

    Args:
        dataset (tf.data.Dataset): The `tf.data.Dataset` object consisting of `ROOTVariables`.
        element_spec (Dict[str, Union[tf.TensorSpec, tf.RaggedTensorSpec]]): The `element_spec` of the dataset.

    Returns:
        JIDENNDataset: The JIDENNDataset object with the `dataset` and `element_spec` set.
    &#34;&#34;&#34;
    jidenn_dataset = JIDENNDataset(variables=self.variables,
                                   target=self.target,
                                   weight=self.weight)
    jidenn_dataset._dataset = dataset
    jidenn_dataset._element_spec = element_spec
    return jidenn_dataset</code></pre>
</details>
</dd>
<dt id="jidenn.data.JIDENNDataset.JIDENNDataset.to_pandas"><code class="name flex">
<span>def <span class="ident">to_pandas</span></span>(<span>self, variables:Â Optional[List[str]]Â =Â None) â€‘>Â pandas.core.frame.DataFrame</span>
</code></dt>
<dd>
<div class="desc"><p>Converts the dataset to a pandas DataFrame. The dataset must be loaded before calling this function.
The function uses <code>tensorflow_datasets.as_dataframe</code> to convert the dataset to a pandas DataFrame, so
the <code>tensorflow_datasets</code> package must be installed.</p>
<p>Be careful that this function may take a <strong>long time to run</strong>, depending on the size of the dataset.
Consider taking only a subset of the dataset before converting it to a pandas DataFrame.</p>
<pre><code class="language-python">jidenn_dataset = JIDENNDataset(...) 
...
jidenn_dataset = jidenn_dataset.apply(lambda dataset: dataset.take(1_000))
df = jidenn_dataset.to_pandas()
</code></pre>
<p>If the dataset contains nested tuples consider using <code><a title="jidenn.data.data_info.explode_nested_variables" href="data_info.html#jidenn.data.data_info.explode_nested_variables">explode_nested_variables()</a></code>
on the tuple columns of the convereted dataframe.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>variables</code></strong> :&ensp;<code>Optional[List[str]]</code>, optional</dt>
<dd>List of variables to convert to a pandas DataFrame. If <code>None</code>, all variables are converted. Defaults to <code>None</code>.</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>ImportError</code></dt>
<dd>If <code>tensorflow_datasets</code> is not installed.</dd>
<dt><code>ValueError</code></dt>
<dd>If the dataset is not loaded yet.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>pd.DataFrame</code></dt>
<dd>The <code>tf.data.Dataset</code> converted to a pandas <code>pd.DataFrame</code>.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def to_pandas(self, variables: Optional[List[str]] = None) -&gt; pd.DataFrame:
    &#34;&#34;&#34;Converts the dataset to a pandas DataFrame. The dataset must be loaded before calling this function.
    The function uses `tensorflow_datasets.as_dataframe` to convert the dataset to a pandas DataFrame, so 
    the `tensorflow_datasets` package must be installed.

    Be careful that this function may take a **long time to run**, depending on the size of the dataset.
    Consider taking only a subset of the dataset before converting it to a pandas DataFrame.
    ```python
    jidenn_dataset = JIDENNDataset(...) 
    ...
    jidenn_dataset = jidenn_dataset.apply(lambda dataset: dataset.take(1_000))
    df = jidenn_dataset.to_pandas()
    ```

    If the dataset contains nested tuples consider using `jidenn.data.data_info.explode_nested_variables` 
    on the tuple columns of the convereted dataframe.

    Args:
        variables (Optional[List[str]], optional): List of variables to convert to a pandas DataFrame. If `None`, all variables are converted. Defaults to `None`.

    Raises:
        ImportError: If `tensorflow_datasets` is not installed.
        ValueError: If the dataset is not loaded yet.

    Returns:
        pd.DataFrame: The `tf.data.Dataset` converted to a pandas `pd.DataFrame`.
    &#34;&#34;&#34;

    try:
        import tensorflow_datasets as tfds
    except ImportError:
        raise ImportError(
            &#39;Please install tensorflow_datasets to use this function. Use `pip install tensorflow_datasets`.&#39;)
    if self.dataset is None:
        raise ValueError(&#39;Dataset not loaded yet.&#39;)

    if isinstance(self.element_spec, tuple) and variables is None:
        @tf.function
        def tuple_to_dict(data, label, weight=None):
            if isinstance(data, tuple):
                data = {**data[0], **data[1]}
            data = {**data, &#39;label&#39;: label, &#39;weight&#39;: weight}
            return data

    elif isinstance(self.element_spec, tuple) and variables is not None:
        @tf.function
        def tuple_to_dict(data, label, weight=None):
            if isinstance(data, tuple):
                data = {**data[0], **data[1]}
            data = {**data, &#39;label&#39;: label, &#39;weight&#39;: weight}
            return {k: data[k] for k in variables + [&#39;label&#39;, &#39;weight&#39;]}

    elif isinstance(self.element_spec, dict) and variables is not None:
        @tf.function
        def tuple_to_dict(data):
            return {k: data[k] for k in variables}

    elif isinstance(self.element_spec, dict) and variables is None:
        @tf.function
        def tuple_to_dict(data):
            return data

    else:
        raise ValueError(&#39;The dataset must be a tuple or a dict.&#39;)

    dataset = self.dataset.map(tuple_to_dict)
    df = tfds.as_dataframe(dataset)
    df = df.rename(lambda x: x.replace(&#39;/&#39;, &#39;.&#39;), axis=&#39;columns&#39;)
    return df</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<header>
<a class="homelink" rel="home" title="JIDENN" href="https://jansam.wieno.sk/JIDENN/">
<img src="images/q_g_tagging.jpeg" alt=""> JIDENN
</a>
</header>
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="jidenn.data" href="index.html">jidenn.data</a></code></li>
</ul>
</li>
<li><h3><a href="#header-variables">Global variables</a></h3>
<ul class="">
<li><code><a title="jidenn.data.JIDENNDataset.ROOTVariables" href="#jidenn.data.JIDENNDataset.ROOTVariables">ROOTVariables</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="jidenn.data.JIDENNDataset.dict_to_stacked_array" href="#jidenn.data.JIDENNDataset.dict_to_stacked_array">dict_to_stacked_array</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="jidenn.data.JIDENNDataset.JIDENNDataset" href="#jidenn.data.JIDENNDataset.JIDENNDataset">JIDENNDataset</a></code></h4>
<ul class="">
<li><code><a title="jidenn.data.JIDENNDataset.JIDENNDataset.apply" href="#jidenn.data.JIDENNDataset.JIDENNDataset.apply">apply</a></code></li>
<li><code><a title="jidenn.data.JIDENNDataset.JIDENNDataset.combine" href="#jidenn.data.JIDENNDataset.JIDENNDataset.combine">combine</a></code></li>
<li><code><a title="jidenn.data.JIDENNDataset.JIDENNDataset.create_train_input" href="#jidenn.data.JIDENNDataset.JIDENNDataset.create_train_input">create_train_input</a></code></li>
<li><code><a title="jidenn.data.JIDENNDataset.JIDENNDataset.create_variables" href="#jidenn.data.JIDENNDataset.JIDENNDataset.create_variables">create_variables</a></code></li>
<li><code><a title="jidenn.data.JIDENNDataset.JIDENNDataset.dataset" href="#jidenn.data.JIDENNDataset.JIDENNDataset.dataset">dataset</a></code></li>
<li><code><a title="jidenn.data.JIDENNDataset.JIDENNDataset.element_spec" href="#jidenn.data.JIDENNDataset.JIDENNDataset.element_spec">element_spec</a></code></li>
<li><code><a title="jidenn.data.JIDENNDataset.JIDENNDataset.filter" href="#jidenn.data.JIDENNDataset.JIDENNDataset.filter">filter</a></code></li>
<li><code><a title="jidenn.data.JIDENNDataset.JIDENNDataset.get_prepared_dataset" href="#jidenn.data.JIDENNDataset.JIDENNDataset.get_prepared_dataset">get_prepared_dataset</a></code></li>
<li><code><a title="jidenn.data.JIDENNDataset.JIDENNDataset.load" href="#jidenn.data.JIDENNDataset.JIDENNDataset.load">load</a></code></li>
<li><code><a title="jidenn.data.JIDENNDataset.JIDENNDataset.load_dataset" href="#jidenn.data.JIDENNDataset.JIDENNDataset.load_dataset">load_dataset</a></code></li>
<li><code><a title="jidenn.data.JIDENNDataset.JIDENNDataset.load_element_spec" href="#jidenn.data.JIDENNDataset.JIDENNDataset.load_element_spec">load_element_spec</a></code></li>
<li><code><a title="jidenn.data.JIDENNDataset.JIDENNDataset.plot_data_distributions" href="#jidenn.data.JIDENNDataset.JIDENNDataset.plot_data_distributions">plot_data_distributions</a></code></li>
<li><code><a title="jidenn.data.JIDENNDataset.JIDENNDataset.remap_labels" href="#jidenn.data.JIDENNDataset.JIDENNDataset.remap_labels">remap_labels</a></code></li>
<li><code><a title="jidenn.data.JIDENNDataset.JIDENNDataset.resample_dataset" href="#jidenn.data.JIDENNDataset.JIDENNDataset.resample_dataset">resample_dataset</a></code></li>
<li><code><a title="jidenn.data.JIDENNDataset.JIDENNDataset.save_dataset" href="#jidenn.data.JIDENNDataset.JIDENNDataset.save_dataset">save_dataset</a></code></li>
<li><code><a title="jidenn.data.JIDENNDataset.JIDENNDataset.set_dataset" href="#jidenn.data.JIDENNDataset.JIDENNDataset.set_dataset">set_dataset</a></code></li>
<li><code><a title="jidenn.data.JIDENNDataset.JIDENNDataset.target" href="#jidenn.data.JIDENNDataset.JIDENNDataset.target">target</a></code></li>
<li><code><a title="jidenn.data.JIDENNDataset.JIDENNDataset.to_pandas" href="#jidenn.data.JIDENNDataset.JIDENNDataset.to_pandas">to_pandas</a></code></li>
<li><code><a title="jidenn.data.JIDENNDataset.JIDENNDataset.variables" href="#jidenn.data.JIDENNDataset.JIDENNDataset.variables">variables</a></code></li>
<li><code><a title="jidenn.data.JIDENNDataset.JIDENNDataset.weight" href="#jidenn.data.JIDENNDataset.JIDENNDataset.weight">weight</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>