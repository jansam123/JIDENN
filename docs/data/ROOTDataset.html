<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>jidenn.data.ROOTDataset API documentation</title>
<meta name="description" content="Module for reading ROOT files and converting them to Tensorflow `tf.RaggedTensor` or `tf.Tensor` objects.
The module contains the `ROOTDataset` class …" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS_CHTML" integrity="sha256-kZafAc6mZvK3W3v1pHOcUix30OHQN6pU/NO2oFkqZVw=" crossorigin></script>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
<link rel="canonical" href="http://jansam.wieno.sk/JIDENN/jidenn/data/ROOTDataset.html">
<link rel="icon" href="images/q_g_tagging.jpeg">
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>jidenn.data.ROOTDataset</code></h1>
</header>
<section id="section-intro">
<p>Module for reading ROOT files and converting them to Tensorflow <code>tf.RaggedTensor</code> or <code>tf.Tensor</code> objects.
The module contains the <code><a title="jidenn.data.ROOTDataset.ROOTDataset" href="#jidenn.data.ROOTDataset.ROOTDataset">ROOTDataset</a></code> class which is a wrapper of <code>tf.data.Dataset</code>.
It's main purpose is to read ROOT files and convert them to Tensorflow <code>tf.RaggedTensor</code> or <code>tf.Tensor</code> objects,
and to a <code>tf.data.Dataset</code> object afterwards. It relies on the <code>uproot</code> package.</p>
<p>Two ooptinal backends are available for converting ROOT files to Tensorflow objects: <code>pandas</code> and <code>awkward</code>.</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;
Module for reading ROOT files and converting them to Tensorflow `tf.RaggedTensor` or `tf.Tensor` objects. 
The module contains the `ROOTDataset` class which is a wrapper of `tf.data.Dataset`.
It&#39;s main purpose is to read ROOT files and convert them to Tensorflow `tf.RaggedTensor` or `tf.Tensor` objects,
and to a `tf.data.Dataset` object afterwards. It relies on the `uproot` package.

Two ooptinal backends are available for converting ROOT files to Tensorflow objects: `pandas` and `awkward`.
&#34;&#34;&#34;
from __future__ import annotations
import tensorflow as tf
from typing import Callable, List, Union, Dict, Optional, Literal
import pickle
import os
import uproot
import logging
import pandas as pd
import awkward as ak


ROOTVariables = Dict[str, Union[tf.RaggedTensor, tf.Tensor]]
&#34;&#34;&#34;Type alias for a dictionary of ROOT variables. The keys are the variable  names and the values are the corresponding 
Tensorflow `tf.RaggedTensor` or `tf.Tensor`.

Example:
```python
variables = {
    &#39;jets_pt&#39;: tf.RaggedTensor([[1, 2, 3, 4, 5], [2, 3]], dtype=tf.float32),
    &#39;eventNumber&#39;: tf.Tensor([1, 2], dtype=tf.int32),
    ...
}
```
&#34;&#34;&#34;


def pandas_to_tensor(df: pd.Series) -&gt; Union[tf.RaggedTensor, tf.Tensor]:
    &#34;&#34;&#34;Converts a pandas `pd.Series` to a Tensorflow `tf.RaggedTensor` or `tf.Tensor`. The output is a `tf.RaggedTensor`
    if the Series has a multiple level index, otherwise it is a `tf.Tensor`. The number of levels of the index gives the
    number of dimensions of the output. 

    Args:
        df (pd.Series): pandas pd.Series to be converted. Can have a single or multiple level index (`pd.MultiIndex`).

    Returns:
        tf.RaggedTensor or tf.Tensor: `tf.RaggedTensor` if df has number of index levels  greater than 1, else `tf.Tensor`.
    &#34;&#34;&#34;
    levels = df.index.nlevels
    if levels == 1:
        return tf.constant(df.values)
    elif levels == 2:
        row_lengths = df.groupby(level=[0]).count()
        return tf.RaggedTensor.from_row_lengths(df.values, row_lengths.values, validate=False)
    else:
        max_level_group = list(range(levels - 1))
        nested_row_lengths = [df.groupby(level=max_level_group).count()]
        for i in range(1, levels - 1):
            nested_row_lengths.append(
                nested_row_lengths[-1].groupby(level=max_level_group[:-i]).count())
        return tf.RaggedTensor.from_nested_row_lengths(df.values, nested_row_lengths=nested_row_lengths[::-1], validate=False)


def awkward_to_tensor(array: ak.Array) -&gt; Union[tf.RaggedTensor, tf.Tensor]:
    &#34;&#34;&#34;Converts an awkward `ak.Array` to a Tensorflow `tf.RaggedTensor` or tf.Tensor. The output is a `tf.RaggedTensor` 
    if the array has a dimension greater than 1, otherwise it is a `tf.Tensor`. The number of dimensions of the array 
    gives the number of dimensions of the output.

    Args:
        array (ak.Array): awkward ak.Array to be converted. Can have a single or multiple dimensions.

    Returns:
        tf.RaggedTensor or tf.Tensor: `tf.RaggedTensor` if the array dimension is greater than 1, else `tf.Tensor`.
    &#34;&#34;&#34;
    if array.ndim == 1:
        return tf.constant(array.to_list())
    elif array.ndim == 2:
        row_lengths = ak.num(array, axis=1).to_list()
        return tf.RaggedTensor.from_row_lengths(ak.flatten(array, axis=None).to_list(), row_lengths=row_lengths, validate=False)
    else:
        nested_row_lengths = [ak.flatten(ak.num(array, axis=ax), axis=None).to_list()
                              for ax in range(1, array.ndim)]
        return tf.RaggedTensor.from_nested_row_lengths(ak.flatten(
            array, axis=None).to_list(), nested_row_lengths=nested_row_lengths, validate=False)


def read_ttree(tree: uproot.TTree, backend: Literal[&#39;pd&#39;, &#39;ak&#39;] = &#39;pd&#39;, downcast: bool = True) -&gt; ROOTVariables:
    &#34;&#34;&#34;Reads a ROOT TTree and returns a dictionary of Tensorflow `tf.RaggedTensor` or `tf.Tensor` objects. The keys are 
    the variable names and the values read from the TTree. Converting the TTree is done by a variable at a time. 

    Args:
        tree (uproot.TTree): ROOT TTree to be read.
        backend (str, optional): &#39;pd&#39; or &#39;ak&#39;. Backend to use for reading the TTree, &#39;pd&#39; is faster but consumes more memory. Defaults to &#39;pd&#39;.
        downcast (bool, optional): Downcast the output to `tf.float32`, `tf.int32` or `tf.uint32`. Defaults to True.

    Raises:
        ValueError: If backend is not &#39;pd&#39; or &#39;ak&#39;.

    Returns:
        ROOTVariables: Dictionary of Tensorflow `tf.RaggedTensor` or `tf.Tensor` objects. The keys are the variable names and the values read from the TTree.
    &#34;&#34;&#34;

    if backend != &#39;pd&#39; and backend != &#39;ak&#39;:
        raise ValueError(
            f&#39;Backend {backend} not supported. Choose from pd (pandas) or ak (awkward).&#39;)
    variables = tree.keys()
    output = {}
    for var in variables:
        var_branch = tree[var].array(library=&#34;ak&#34;)
        if ak.num(ak.flatten(var_branch, axis=None), axis=0) == 0:
            continue
        if backend == &#39;ak&#39;:
            tensor = awkward_to_tensor(var_branch)
        elif backend == &#39;pd&#39;:
            var_branch = ak.to_dataframe(var_branch)
            if var_branch.empty:
                continue
            tensor = pandas_to_tensor(var_branch[&#39;values&#39;])

        if downcast:
            if tensor.dtype == tf.float64:
                tensor = tf.cast(tensor, tf.float32)
            elif tensor.dtype == tf.int64:
                tensor = tf.cast(tensor, tf.int32)
            elif tensor.dtype == tf.uint64:
                tensor = tf.cast(tensor, tf.uint32)

        output[var] = tensor
        logging.info(f&#39;{var}: {output[var].shape} {output[var].dtype}&#39;)
    return output


class ROOTDataset:
    &#34;&#34;&#34;Class to read a ROOT file and return a `tf.data.Dataset` object. The dataset contains a dictionary of Tensorflow
    `tf.RaggedTensor` or `tf.Tensor` objects. The keys are the variable names and the values read from the TTree.
    The `.root` files are read using `uproot` and the `tf.data.Dataset` is created using `tf.data.Dataset.from_tensor_slices`. 

    The ROOT file is read by a variable at a time, so the memory consumption may be high for large files. More precisely,
    the proces of creating the `tf.data.Dataset` from a dictionary of `tf.RaggedTensor` or `tf.Tensor` objects 
    **consumes a lot of memory**. This is done as a trade-off for higher conversion speed. 

    Example:
    ```python
    import tensorflow as tf

    root_file = &#39;path/to/file.root&#39;
    save_path = &#39;path/to/save/dataset&#39;
    root_dataset = ROOTDataset.from_root_file(root_file)
    root_dataset.save(save_path)
    ...
    root_dataset = ROOTDataset.load(save_path)
    dataset = root_dataset.dataset
    # Use as a training dataset 
    ```


    The initialization is only a convenience method. The `ROOTDataset.from_root_file` or `ROOTDataset.from_root_files`
    methods should be used for creating a `ROOTDataset` object instead.
    Args:
        dataset (tf.data.Dataset): Tensorflow `tf.data.Dataset` object.
        variables (list[str]): List of variable names.


    &#34;&#34;&#34;

    def __init__(self, dataset: tf.data.Dataset, variables: List[str]):
        self._variables = variables
        self._dataset = dataset

    @property
    def variables(self) -&gt; List[str]:
        &#34;&#34;&#34;List of variable names inferred from the ROOT file.&#34;&#34;&#34;
        return self._variables

    @property
    def dataset(self) -&gt; tf.data.Dataset:
        &#34;&#34;&#34;Tensorflow `tf.data.Dataset` object created from the ROOT file.&#34;&#34;&#34;
        return self._dataset

    @classmethod
    def from_root_file(cls, filename: str,
                       tree_name: str = &#39;NOMINAL&#39;,
                       metadata_hist: Optional[str] = &#39;h_metadata&#39;,
                       backend: Literal[&#39;pd&#39;, &#39;ak&#39;] = &#39;pd&#39;) -&gt; ROOTDataset:
        &#34;&#34;&#34;Reads a ROOT file and returns a `ROOTDataset` object. 

        Args:
            filename (str): Path to the ROOT file.
            tree_name (str, optional): Name of the TTree in the ROOT file. Defaults to &#39;NOMINAL&#39;.
            metadata_hist (str, optional): Name of the histogram containing the metadata. Defaults to &#39;h_metadata&#39;. Could be `None`.
            backend (str, optional): &#39;pd&#39; or &#39;ak&#39;. Backend to use for reading the TTree, &#39;pd&#39; is faster but consumes more memory. Defaults to &#39;pd&#39;.

        Returns:
            ROOTDataset: `ROOTDataset` object.
        &#34;&#34;&#34;
        file = uproot.open(filename, object_cache=None, array_cache=None)
        tree = file[tree_name]
        logging.info(f&#34;Loading ROOT file {filename}&#34;)
        sample = read_ttree(tree, backend=backend)

        if metadata_hist is not None:
            logging.info(&#34;Getting metadata&#34;)
            metadata = file[metadata_hist].values()
            sample[&#39;metadata&#39;] = tf.tile(tf.constant(metadata)[tf.newaxis, :], [
                                         sample[&#39;eventNumber&#39;].shape[0], 1])

        logging.info(f&#39;Done loading file:{filename}&#39;)
        dataset = tf.data.Dataset.from_tensor_slices(sample)
        return cls(dataset, list(sample.keys()))

    @classmethod
    def concat(cls, datasets: List[ROOTDataset]) -&gt; ROOTDataset:
        &#34;&#34;&#34;Concatenates a list of `ROOTDataset` objects. Data samples are sequentially concatenated using `tf.data.Dataset.concatenate`.

        Args:
            datasets (list[ROOTDataset]): List of `ROOTDataset` objects.

        Raises:
            ValueError: If the variables of the datasets do not match.

        Returns:
            ROOTDataset: Combined `ROOTDataset` object.
        &#34;&#34;&#34;
        for dataset in datasets:
            if dataset.variables != datasets[0].variables:
                raise ValueError(&#34;Variables of datasets do not match&#34;)
        final_dataset = datasets[0]._dataset
        for ds in datasets[1:]:
            final_dataset = final_dataset.concatenate(ds._dataset)
        return cls(final_dataset, datasets[0].variables)

    @classmethod
    def from_root_files(cls, filenames: Union[List[str], str]) -&gt; ROOTDataset:
        &#34;&#34;&#34;Reads a list of ROOT files and returns a `ROOTDataset` object. Can also be used to read a single file.

        Args:
            filenames (list[str] or str): List of paths to the ROOT files or a single path to a ROOT file.

        Returns:
            ROOTDataset: `ROOTDataset` object.
        &#34;&#34;&#34;
        if isinstance(filenames, str):
            filenames = [filenames]
        return cls.concat([cls.from_root_file(filename) for filename in filenames])

    @classmethod
    def load(cls, file: str, element_spec_path: Optional[str] = None) -&gt; ROOTDataset:
        &#34;&#34;&#34;Loads a `ROOTDataset` object from a saved directory. The saved object is a `tf.data.Dataset` object
        saved using `tf.data.Dataset.save`. The `element_spec` is loaded separately as a pickle object and is used 
        to create the `tf.data.Dataset` object. Defaults to `element_spec` file inside the saved directory.
        Optionally, the `element_spec_path` can be passed as an argument as full path.

        Example:
        Example of creating a `ROOTDataset` object from saved `tf.data.Dataset` object.
        ```python
        import pickle
        import tensorflow as tf

        dataset = tf.data.Dataset.from_tensor_slices({&#39;a&#39;: [1, 2, 3], &#39;b&#39;: [4, 5, 6]})
        dataset.save(file_path)
        with open(os.path.join(file_path, &#39;element_spec&#39;), &#39;wb&#39;) as f:
            pickle.dump(dataset.element_spec, f)

        root_dataset = ROOTDataset.load(file_path)

        ```

        Args:
            file (str): Path to the saved directory.
            element_spec_path (str, optional): Path to the saved `element_spec` as a pickle file. Defaults to `element_spec` file inside the saved directory.


        Returns:
            ROOTDataset: `ROOTDataset` object.
        &#34;&#34;&#34;

        element_spec_path = os.path.join(
            file, &#39;element_spec&#39;) if element_spec_path is None else element_spec_path
        with open(element_spec_path, &#39;rb&#39;) as f:
            element_spec = pickle.load(f)
        dataset = tf.data.Dataset.load(
            file, compression=&#39;GZIP&#39;, element_spec=element_spec)
        return cls(dataset, list(element_spec.keys()))

    def save(self, save_path: str, element_spec_path: Optional[str] = None, shard_func: Optional[Callable[[ROOTVariables], tf.Tensor]] = None) -&gt; None:
        &#34;&#34;&#34;Saves a `ROOTDataset` object to a directory. The saved object is a `tf.data.Dataset` object 
        and the `element_spec` is saved separately as a pickle object saved inside the saved directory.

        Args:
            save_path (str): Path to the directory where the object is to be saved.
            element_spec_path (str, optional): Path to the saved `element_spec` as a pickle file. Defaults to `element_spec` file inside the saved directory.
            shard_func (Callable, optional): Function to shard the dataset. Used as a `shard_func` argument in `tf.data.Dataset.save`. Defaults to `None`.

        Returns:
            None

        &#34;&#34;&#34;
        element_spec_path = os.path.join(
            save_path, &#39;element_spec&#39;) if element_spec_path is None else element_spec_path
        element_spec = self._dataset.element_spec
        self._dataset.save(save_path, compression=&#39;GZIP&#39;, shard_func=shard_func)
        with open(element_spec_path, &#39;wb&#39;) as f:
            pickle.dump(element_spec, f)

    def map(self, func: Callable[[ROOTVariables], ROOTVariables]) -&gt; ROOTDataset:
        &#34;&#34;&#34;Maps a function to the dataset. The function should take a `ROOTVariables` object as input and return a `ROOTVariables` object as output.

        Args:
            func (Callable): Function to be mapped.
            num_parallel_calls (int, optional): Number of parallel calls to use. Defaults to `None`.

        Returns:
            ROOTDataset: Mapped `ROOTDataset` object.
        &#34;&#34;&#34;
        new_ds = self.dataset.map(func)
        new_ds = new_ds.prefetch(tf.data.AUTOTUNE)
        return ROOTDataset(new_ds, list(new_ds.element_spec.keys()))</code></pre>
</details>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-variables">Global variables</h2>
<dl>
<dt id="jidenn.data.ROOTDataset.ROOTVariables"><code class="name">var <span class="ident">ROOTVariables</span></code></dt>
<dd>
<div class="desc"><p>Type alias for a dictionary of ROOT variables. The keys are the variable
names and the values are the corresponding
Tensorflow <code>tf.RaggedTensor</code> or <code>tf.Tensor</code>.</p>
<p>Example:</p>
<pre><code class="language-python">variables = {
    'jets_pt': tf.RaggedTensor([[1, 2, 3, 4, 5], [2, 3]], dtype=tf.float32),
    'eventNumber': tf.Tensor([1, 2], dtype=tf.int32),
    ...
}
</code></pre></div>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="jidenn.data.ROOTDataset.awkward_to_tensor"><code class="name flex">
<span>def <span class="ident">awkward_to_tensor</span></span>(<span>array: ak.Array) ‑> Union[tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.Tensor]</span>
</code></dt>
<dd>
<div class="desc"><p>Converts an awkward <code>ak.Array</code> to a Tensorflow <code>tf.RaggedTensor</code> or tf.Tensor. The output is a <code>tf.RaggedTensor</code>
if the array has a dimension greater than 1, otherwise it is a <code>tf.Tensor</code>. The number of dimensions of the array
gives the number of dimensions of the output.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>array</code></strong> :&ensp;<code>ak.Array</code></dt>
<dd>awkward ak.Array to be converted. Can have a single or multiple dimensions.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>tf.RaggedTensor</code> or <code>tf.Tensor</code></dt>
<dd><code>tf.RaggedTensor</code> if the array dimension is greater than 1, else <code>tf.Tensor</code>.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def awkward_to_tensor(array: ak.Array) -&gt; Union[tf.RaggedTensor, tf.Tensor]:
    &#34;&#34;&#34;Converts an awkward `ak.Array` to a Tensorflow `tf.RaggedTensor` or tf.Tensor. The output is a `tf.RaggedTensor` 
    if the array has a dimension greater than 1, otherwise it is a `tf.Tensor`. The number of dimensions of the array 
    gives the number of dimensions of the output.

    Args:
        array (ak.Array): awkward ak.Array to be converted. Can have a single or multiple dimensions.

    Returns:
        tf.RaggedTensor or tf.Tensor: `tf.RaggedTensor` if the array dimension is greater than 1, else `tf.Tensor`.
    &#34;&#34;&#34;
    if array.ndim == 1:
        return tf.constant(array.to_list())
    elif array.ndim == 2:
        row_lengths = ak.num(array, axis=1).to_list()
        return tf.RaggedTensor.from_row_lengths(ak.flatten(array, axis=None).to_list(), row_lengths=row_lengths, validate=False)
    else:
        nested_row_lengths = [ak.flatten(ak.num(array, axis=ax), axis=None).to_list()
                              for ax in range(1, array.ndim)]
        return tf.RaggedTensor.from_nested_row_lengths(ak.flatten(
            array, axis=None).to_list(), nested_row_lengths=nested_row_lengths, validate=False)</code></pre>
</details>
</dd>
<dt id="jidenn.data.ROOTDataset.pandas_to_tensor"><code class="name flex">
<span>def <span class="ident">pandas_to_tensor</span></span>(<span>df: pd.Series) ‑> Union[tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.Tensor]</span>
</code></dt>
<dd>
<div class="desc"><p>Converts a pandas <code>pd.Series</code> to a Tensorflow <code>tf.RaggedTensor</code> or <code>tf.Tensor</code>. The output is a <code>tf.RaggedTensor</code>
if the Series has a multiple level index, otherwise it is a <code>tf.Tensor</code>. The number of levels of the index gives the
number of dimensions of the output. </p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>df</code></strong> :&ensp;<code>pd.Series</code></dt>
<dd>pandas pd.Series to be converted. Can have a single or multiple level index (<code>pd.MultiIndex</code>).</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>tf.RaggedTensor</code> or <code>tf.Tensor</code></dt>
<dd><code>tf.RaggedTensor</code> if df has number of index levels
greater than 1, else <code>tf.Tensor</code>.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def pandas_to_tensor(df: pd.Series) -&gt; Union[tf.RaggedTensor, tf.Tensor]:
    &#34;&#34;&#34;Converts a pandas `pd.Series` to a Tensorflow `tf.RaggedTensor` or `tf.Tensor`. The output is a `tf.RaggedTensor`
    if the Series has a multiple level index, otherwise it is a `tf.Tensor`. The number of levels of the index gives the
    number of dimensions of the output. 

    Args:
        df (pd.Series): pandas pd.Series to be converted. Can have a single or multiple level index (`pd.MultiIndex`).

    Returns:
        tf.RaggedTensor or tf.Tensor: `tf.RaggedTensor` if df has number of index levels  greater than 1, else `tf.Tensor`.
    &#34;&#34;&#34;
    levels = df.index.nlevels
    if levels == 1:
        return tf.constant(df.values)
    elif levels == 2:
        row_lengths = df.groupby(level=[0]).count()
        return tf.RaggedTensor.from_row_lengths(df.values, row_lengths.values, validate=False)
    else:
        max_level_group = list(range(levels - 1))
        nested_row_lengths = [df.groupby(level=max_level_group).count()]
        for i in range(1, levels - 1):
            nested_row_lengths.append(
                nested_row_lengths[-1].groupby(level=max_level_group[:-i]).count())
        return tf.RaggedTensor.from_nested_row_lengths(df.values, nested_row_lengths=nested_row_lengths[::-1], validate=False)</code></pre>
</details>
</dd>
<dt id="jidenn.data.ROOTDataset.read_ttree"><code class="name flex">
<span>def <span class="ident">read_ttree</span></span>(<span>tree: uproot.TTree, backend: "Literal['pd', 'ak']" = 'pd', downcast: bool = True) ‑> Dict[str, Union[tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor, tensorflow.python.framework.ops.Tensor]]</span>
</code></dt>
<dd>
<div class="desc"><p>Reads a ROOT TTree and returns a dictionary of Tensorflow <code>tf.RaggedTensor</code> or <code>tf.Tensor</code> objects. The keys are
the variable names and the values read from the TTree. Converting the TTree is done by a variable at a time. </p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>tree</code></strong> :&ensp;<code>uproot.TTree</code></dt>
<dd>ROOT TTree to be read.</dd>
<dt><strong><code>backend</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>'pd' or 'ak'. Backend to use for reading the TTree, 'pd' is faster but consumes more memory. Defaults to 'pd'.</dd>
<dt><strong><code>downcast</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>Downcast the output to <code>tf.float32</code>, <code>tf.int32</code> or <code>tf.uint32</code>. Defaults to True.</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>ValueError</code></dt>
<dd>If backend is not 'pd' or 'ak'.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="jidenn.data.ROOTDataset.ROOTVariables" href="#jidenn.data.ROOTDataset.ROOTVariables">ROOTVariables</a></code></dt>
<dd>Dictionary of Tensorflow <code>tf.RaggedTensor</code> or <code>tf.Tensor</code> objects. The keys are the variable names and the values read from the TTree.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def read_ttree(tree: uproot.TTree, backend: Literal[&#39;pd&#39;, &#39;ak&#39;] = &#39;pd&#39;, downcast: bool = True) -&gt; ROOTVariables:
    &#34;&#34;&#34;Reads a ROOT TTree and returns a dictionary of Tensorflow `tf.RaggedTensor` or `tf.Tensor` objects. The keys are 
    the variable names and the values read from the TTree. Converting the TTree is done by a variable at a time. 

    Args:
        tree (uproot.TTree): ROOT TTree to be read.
        backend (str, optional): &#39;pd&#39; or &#39;ak&#39;. Backend to use for reading the TTree, &#39;pd&#39; is faster but consumes more memory. Defaults to &#39;pd&#39;.
        downcast (bool, optional): Downcast the output to `tf.float32`, `tf.int32` or `tf.uint32`. Defaults to True.

    Raises:
        ValueError: If backend is not &#39;pd&#39; or &#39;ak&#39;.

    Returns:
        ROOTVariables: Dictionary of Tensorflow `tf.RaggedTensor` or `tf.Tensor` objects. The keys are the variable names and the values read from the TTree.
    &#34;&#34;&#34;

    if backend != &#39;pd&#39; and backend != &#39;ak&#39;:
        raise ValueError(
            f&#39;Backend {backend} not supported. Choose from pd (pandas) or ak (awkward).&#39;)
    variables = tree.keys()
    output = {}
    for var in variables:
        var_branch = tree[var].array(library=&#34;ak&#34;)
        if ak.num(ak.flatten(var_branch, axis=None), axis=0) == 0:
            continue
        if backend == &#39;ak&#39;:
            tensor = awkward_to_tensor(var_branch)
        elif backend == &#39;pd&#39;:
            var_branch = ak.to_dataframe(var_branch)
            if var_branch.empty:
                continue
            tensor = pandas_to_tensor(var_branch[&#39;values&#39;])

        if downcast:
            if tensor.dtype == tf.float64:
                tensor = tf.cast(tensor, tf.float32)
            elif tensor.dtype == tf.int64:
                tensor = tf.cast(tensor, tf.int32)
            elif tensor.dtype == tf.uint64:
                tensor = tf.cast(tensor, tf.uint32)

        output[var] = tensor
        logging.info(f&#39;{var}: {output[var].shape} {output[var].dtype}&#39;)
    return output</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="jidenn.data.ROOTDataset.ROOTDataset"><code class="flex name class">
<span>class <span class="ident">ROOTDataset</span></span>
<span>(</span><span>dataset: tf.data.Dataset, variables: List[str])</span>
</code></dt>
<dd>
<div class="desc"><p>Class to read a ROOT file and return a <code>tf.data.Dataset</code> object. The dataset contains a dictionary of Tensorflow
<code>tf.RaggedTensor</code> or <code>tf.Tensor</code> objects. The keys are the variable names and the values read from the TTree.
The <code>.root</code> files are read using <code>uproot</code> and the <code>tf.data.Dataset</code> is created using <code>tf.data.Dataset.from_tensor_slices</code>. </p>
<p>The ROOT file is read by a variable at a time, so the memory consumption may be high for large files. More precisely,
the proces of creating the <code>tf.data.Dataset</code> from a dictionary of <code>tf.RaggedTensor</code> or <code>tf.Tensor</code> objects
<strong>consumes a lot of memory</strong>. This is done as a trade-off for higher conversion speed. </p>
<p>Example:</p>
<pre><code class="language-python">import tensorflow as tf

root_file = 'path/to/file.root'
save_path = 'path/to/save/dataset'
root_dataset = ROOTDataset.from_root_file(root_file)
root_dataset.save(save_path)
...
root_dataset = ROOTDataset.load(save_path)
dataset = root_dataset.dataset
# Use as a training dataset 
</code></pre>
<p>The initialization is only a convenience method. The <code><a title="jidenn.data.ROOTDataset.ROOTDataset.from_root_file" href="#jidenn.data.ROOTDataset.ROOTDataset.from_root_file">ROOTDataset.from_root_file()</a></code> or <code><a title="jidenn.data.ROOTDataset.ROOTDataset.from_root_files" href="#jidenn.data.ROOTDataset.ROOTDataset.from_root_files">ROOTDataset.from_root_files()</a></code>
methods should be used for creating a <code><a title="jidenn.data.ROOTDataset.ROOTDataset" href="#jidenn.data.ROOTDataset.ROOTDataset">ROOTDataset</a></code> object instead.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>dataset</code></strong> :&ensp;<code>tf.data.Dataset</code></dt>
<dd>Tensorflow <code>tf.data.Dataset</code> object.</dd>
<dt><strong><code>variables</code></strong> :&ensp;<code>list[str]</code></dt>
<dd>List of variable names.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class ROOTDataset:
    &#34;&#34;&#34;Class to read a ROOT file and return a `tf.data.Dataset` object. The dataset contains a dictionary of Tensorflow
    `tf.RaggedTensor` or `tf.Tensor` objects. The keys are the variable names and the values read from the TTree.
    The `.root` files are read using `uproot` and the `tf.data.Dataset` is created using `tf.data.Dataset.from_tensor_slices`. 

    The ROOT file is read by a variable at a time, so the memory consumption may be high for large files. More precisely,
    the proces of creating the `tf.data.Dataset` from a dictionary of `tf.RaggedTensor` or `tf.Tensor` objects 
    **consumes a lot of memory**. This is done as a trade-off for higher conversion speed. 

    Example:
    ```python
    import tensorflow as tf

    root_file = &#39;path/to/file.root&#39;
    save_path = &#39;path/to/save/dataset&#39;
    root_dataset = ROOTDataset.from_root_file(root_file)
    root_dataset.save(save_path)
    ...
    root_dataset = ROOTDataset.load(save_path)
    dataset = root_dataset.dataset
    # Use as a training dataset 
    ```


    The initialization is only a convenience method. The `ROOTDataset.from_root_file` or `ROOTDataset.from_root_files`
    methods should be used for creating a `ROOTDataset` object instead.
    Args:
        dataset (tf.data.Dataset): Tensorflow `tf.data.Dataset` object.
        variables (list[str]): List of variable names.


    &#34;&#34;&#34;

    def __init__(self, dataset: tf.data.Dataset, variables: List[str]):
        self._variables = variables
        self._dataset = dataset

    @property
    def variables(self) -&gt; List[str]:
        &#34;&#34;&#34;List of variable names inferred from the ROOT file.&#34;&#34;&#34;
        return self._variables

    @property
    def dataset(self) -&gt; tf.data.Dataset:
        &#34;&#34;&#34;Tensorflow `tf.data.Dataset` object created from the ROOT file.&#34;&#34;&#34;
        return self._dataset

    @classmethod
    def from_root_file(cls, filename: str,
                       tree_name: str = &#39;NOMINAL&#39;,
                       metadata_hist: Optional[str] = &#39;h_metadata&#39;,
                       backend: Literal[&#39;pd&#39;, &#39;ak&#39;] = &#39;pd&#39;) -&gt; ROOTDataset:
        &#34;&#34;&#34;Reads a ROOT file and returns a `ROOTDataset` object. 

        Args:
            filename (str): Path to the ROOT file.
            tree_name (str, optional): Name of the TTree in the ROOT file. Defaults to &#39;NOMINAL&#39;.
            metadata_hist (str, optional): Name of the histogram containing the metadata. Defaults to &#39;h_metadata&#39;. Could be `None`.
            backend (str, optional): &#39;pd&#39; or &#39;ak&#39;. Backend to use for reading the TTree, &#39;pd&#39; is faster but consumes more memory. Defaults to &#39;pd&#39;.

        Returns:
            ROOTDataset: `ROOTDataset` object.
        &#34;&#34;&#34;
        file = uproot.open(filename, object_cache=None, array_cache=None)
        tree = file[tree_name]
        logging.info(f&#34;Loading ROOT file {filename}&#34;)
        sample = read_ttree(tree, backend=backend)

        if metadata_hist is not None:
            logging.info(&#34;Getting metadata&#34;)
            metadata = file[metadata_hist].values()
            sample[&#39;metadata&#39;] = tf.tile(tf.constant(metadata)[tf.newaxis, :], [
                                         sample[&#39;eventNumber&#39;].shape[0], 1])

        logging.info(f&#39;Done loading file:{filename}&#39;)
        dataset = tf.data.Dataset.from_tensor_slices(sample)
        return cls(dataset, list(sample.keys()))

    @classmethod
    def concat(cls, datasets: List[ROOTDataset]) -&gt; ROOTDataset:
        &#34;&#34;&#34;Concatenates a list of `ROOTDataset` objects. Data samples are sequentially concatenated using `tf.data.Dataset.concatenate`.

        Args:
            datasets (list[ROOTDataset]): List of `ROOTDataset` objects.

        Raises:
            ValueError: If the variables of the datasets do not match.

        Returns:
            ROOTDataset: Combined `ROOTDataset` object.
        &#34;&#34;&#34;
        for dataset in datasets:
            if dataset.variables != datasets[0].variables:
                raise ValueError(&#34;Variables of datasets do not match&#34;)
        final_dataset = datasets[0]._dataset
        for ds in datasets[1:]:
            final_dataset = final_dataset.concatenate(ds._dataset)
        return cls(final_dataset, datasets[0].variables)

    @classmethod
    def from_root_files(cls, filenames: Union[List[str], str]) -&gt; ROOTDataset:
        &#34;&#34;&#34;Reads a list of ROOT files and returns a `ROOTDataset` object. Can also be used to read a single file.

        Args:
            filenames (list[str] or str): List of paths to the ROOT files or a single path to a ROOT file.

        Returns:
            ROOTDataset: `ROOTDataset` object.
        &#34;&#34;&#34;
        if isinstance(filenames, str):
            filenames = [filenames]
        return cls.concat([cls.from_root_file(filename) for filename in filenames])

    @classmethod
    def load(cls, file: str, element_spec_path: Optional[str] = None) -&gt; ROOTDataset:
        &#34;&#34;&#34;Loads a `ROOTDataset` object from a saved directory. The saved object is a `tf.data.Dataset` object
        saved using `tf.data.Dataset.save`. The `element_spec` is loaded separately as a pickle object and is used 
        to create the `tf.data.Dataset` object. Defaults to `element_spec` file inside the saved directory.
        Optionally, the `element_spec_path` can be passed as an argument as full path.

        Example:
        Example of creating a `ROOTDataset` object from saved `tf.data.Dataset` object.
        ```python
        import pickle
        import tensorflow as tf

        dataset = tf.data.Dataset.from_tensor_slices({&#39;a&#39;: [1, 2, 3], &#39;b&#39;: [4, 5, 6]})
        dataset.save(file_path)
        with open(os.path.join(file_path, &#39;element_spec&#39;), &#39;wb&#39;) as f:
            pickle.dump(dataset.element_spec, f)

        root_dataset = ROOTDataset.load(file_path)

        ```

        Args:
            file (str): Path to the saved directory.
            element_spec_path (str, optional): Path to the saved `element_spec` as a pickle file. Defaults to `element_spec` file inside the saved directory.


        Returns:
            ROOTDataset: `ROOTDataset` object.
        &#34;&#34;&#34;

        element_spec_path = os.path.join(
            file, &#39;element_spec&#39;) if element_spec_path is None else element_spec_path
        with open(element_spec_path, &#39;rb&#39;) as f:
            element_spec = pickle.load(f)
        dataset = tf.data.Dataset.load(
            file, compression=&#39;GZIP&#39;, element_spec=element_spec)
        return cls(dataset, list(element_spec.keys()))

    def save(self, save_path: str, element_spec_path: Optional[str] = None, shard_func: Optional[Callable[[ROOTVariables], tf.Tensor]] = None) -&gt; None:
        &#34;&#34;&#34;Saves a `ROOTDataset` object to a directory. The saved object is a `tf.data.Dataset` object 
        and the `element_spec` is saved separately as a pickle object saved inside the saved directory.

        Args:
            save_path (str): Path to the directory where the object is to be saved.
            element_spec_path (str, optional): Path to the saved `element_spec` as a pickle file. Defaults to `element_spec` file inside the saved directory.
            shard_func (Callable, optional): Function to shard the dataset. Used as a `shard_func` argument in `tf.data.Dataset.save`. Defaults to `None`.

        Returns:
            None

        &#34;&#34;&#34;
        element_spec_path = os.path.join(
            save_path, &#39;element_spec&#39;) if element_spec_path is None else element_spec_path
        element_spec = self._dataset.element_spec
        self._dataset.save(save_path, compression=&#39;GZIP&#39;, shard_func=shard_func)
        with open(element_spec_path, &#39;wb&#39;) as f:
            pickle.dump(element_spec, f)

    def map(self, func: Callable[[ROOTVariables], ROOTVariables]) -&gt; ROOTDataset:
        &#34;&#34;&#34;Maps a function to the dataset. The function should take a `ROOTVariables` object as input and return a `ROOTVariables` object as output.

        Args:
            func (Callable): Function to be mapped.
            num_parallel_calls (int, optional): Number of parallel calls to use. Defaults to `None`.

        Returns:
            ROOTDataset: Mapped `ROOTDataset` object.
        &#34;&#34;&#34;
        new_ds = self.dataset.map(func)
        new_ds = new_ds.prefetch(tf.data.AUTOTUNE)
        return ROOTDataset(new_ds, list(new_ds.element_spec.keys()))</code></pre>
</details>
<h3>Static methods</h3>
<dl>
<dt id="jidenn.data.ROOTDataset.ROOTDataset.concat"><code class="name flex">
<span>def <span class="ident">concat</span></span>(<span>datasets: List[<a title="jidenn.data.ROOTDataset.ROOTDataset" href="#jidenn.data.ROOTDataset.ROOTDataset">ROOTDataset</a>]) ‑> <a title="jidenn.data.ROOTDataset.ROOTDataset" href="#jidenn.data.ROOTDataset.ROOTDataset">ROOTDataset</a></span>
</code></dt>
<dd>
<div class="desc"><p>Concatenates a list of <code><a title="jidenn.data.ROOTDataset.ROOTDataset" href="#jidenn.data.ROOTDataset.ROOTDataset">ROOTDataset</a></code> objects. Data samples are sequentially concatenated using <code>tf.data.Dataset.concatenate</code>.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>datasets</code></strong> :&ensp;<code>list[<a title="jidenn.data.ROOTDataset.ROOTDataset" href="#jidenn.data.ROOTDataset.ROOTDataset">ROOTDataset</a>]</code></dt>
<dd>List of <code><a title="jidenn.data.ROOTDataset.ROOTDataset" href="#jidenn.data.ROOTDataset.ROOTDataset">ROOTDataset</a></code> objects.</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>ValueError</code></dt>
<dd>If the variables of the datasets do not match.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="jidenn.data.ROOTDataset.ROOTDataset" href="#jidenn.data.ROOTDataset.ROOTDataset">ROOTDataset</a></code></dt>
<dd>Combined <code><a title="jidenn.data.ROOTDataset.ROOTDataset" href="#jidenn.data.ROOTDataset.ROOTDataset">ROOTDataset</a></code> object.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@classmethod
def concat(cls, datasets: List[ROOTDataset]) -&gt; ROOTDataset:
    &#34;&#34;&#34;Concatenates a list of `ROOTDataset` objects. Data samples are sequentially concatenated using `tf.data.Dataset.concatenate`.

    Args:
        datasets (list[ROOTDataset]): List of `ROOTDataset` objects.

    Raises:
        ValueError: If the variables of the datasets do not match.

    Returns:
        ROOTDataset: Combined `ROOTDataset` object.
    &#34;&#34;&#34;
    for dataset in datasets:
        if dataset.variables != datasets[0].variables:
            raise ValueError(&#34;Variables of datasets do not match&#34;)
    final_dataset = datasets[0]._dataset
    for ds in datasets[1:]:
        final_dataset = final_dataset.concatenate(ds._dataset)
    return cls(final_dataset, datasets[0].variables)</code></pre>
</details>
</dd>
<dt id="jidenn.data.ROOTDataset.ROOTDataset.from_root_file"><code class="name flex">
<span>def <span class="ident">from_root_file</span></span>(<span>filename: str, tree_name: str = 'NOMINAL', metadata_hist: Optional[str] = 'h_metadata', backend: "Literal['pd', 'ak']" = 'pd') ‑> <a title="jidenn.data.ROOTDataset.ROOTDataset" href="#jidenn.data.ROOTDataset.ROOTDataset">ROOTDataset</a></span>
</code></dt>
<dd>
<div class="desc"><p>Reads a ROOT file and returns a <code><a title="jidenn.data.ROOTDataset.ROOTDataset" href="#jidenn.data.ROOTDataset.ROOTDataset">ROOTDataset</a></code> object. </p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>filename</code></strong> :&ensp;<code>str</code></dt>
<dd>Path to the ROOT file.</dd>
<dt><strong><code>tree_name</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>Name of the TTree in the ROOT file. Defaults to 'NOMINAL'.</dd>
<dt><strong><code>metadata_hist</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>Name of the histogram containing the metadata. Defaults to 'h_metadata'. Could be <code>None</code>.</dd>
<dt><strong><code>backend</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>'pd' or 'ak'. Backend to use for reading the TTree, 'pd' is faster but consumes more memory. Defaults to 'pd'.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="jidenn.data.ROOTDataset.ROOTDataset" href="#jidenn.data.ROOTDataset.ROOTDataset">ROOTDataset</a></code></dt>
<dd><code><a title="jidenn.data.ROOTDataset.ROOTDataset" href="#jidenn.data.ROOTDataset.ROOTDataset">ROOTDataset</a></code> object.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@classmethod
def from_root_file(cls, filename: str,
                   tree_name: str = &#39;NOMINAL&#39;,
                   metadata_hist: Optional[str] = &#39;h_metadata&#39;,
                   backend: Literal[&#39;pd&#39;, &#39;ak&#39;] = &#39;pd&#39;) -&gt; ROOTDataset:
    &#34;&#34;&#34;Reads a ROOT file and returns a `ROOTDataset` object. 

    Args:
        filename (str): Path to the ROOT file.
        tree_name (str, optional): Name of the TTree in the ROOT file. Defaults to &#39;NOMINAL&#39;.
        metadata_hist (str, optional): Name of the histogram containing the metadata. Defaults to &#39;h_metadata&#39;. Could be `None`.
        backend (str, optional): &#39;pd&#39; or &#39;ak&#39;. Backend to use for reading the TTree, &#39;pd&#39; is faster but consumes more memory. Defaults to &#39;pd&#39;.

    Returns:
        ROOTDataset: `ROOTDataset` object.
    &#34;&#34;&#34;
    file = uproot.open(filename, object_cache=None, array_cache=None)
    tree = file[tree_name]
    logging.info(f&#34;Loading ROOT file {filename}&#34;)
    sample = read_ttree(tree, backend=backend)

    if metadata_hist is not None:
        logging.info(&#34;Getting metadata&#34;)
        metadata = file[metadata_hist].values()
        sample[&#39;metadata&#39;] = tf.tile(tf.constant(metadata)[tf.newaxis, :], [
                                     sample[&#39;eventNumber&#39;].shape[0], 1])

    logging.info(f&#39;Done loading file:{filename}&#39;)
    dataset = tf.data.Dataset.from_tensor_slices(sample)
    return cls(dataset, list(sample.keys()))</code></pre>
</details>
</dd>
<dt id="jidenn.data.ROOTDataset.ROOTDataset.from_root_files"><code class="name flex">
<span>def <span class="ident">from_root_files</span></span>(<span>filenames: Union[List[str], str]) ‑> <a title="jidenn.data.ROOTDataset.ROOTDataset" href="#jidenn.data.ROOTDataset.ROOTDataset">ROOTDataset</a></span>
</code></dt>
<dd>
<div class="desc"><p>Reads a list of ROOT files and returns a <code><a title="jidenn.data.ROOTDataset.ROOTDataset" href="#jidenn.data.ROOTDataset.ROOTDataset">ROOTDataset</a></code> object. Can also be used to read a single file.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>filenames</code></strong> :&ensp;<code>list[str]</code> or <code>str</code></dt>
<dd>List of paths to the ROOT files or a single path to a ROOT file.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="jidenn.data.ROOTDataset.ROOTDataset" href="#jidenn.data.ROOTDataset.ROOTDataset">ROOTDataset</a></code></dt>
<dd><code><a title="jidenn.data.ROOTDataset.ROOTDataset" href="#jidenn.data.ROOTDataset.ROOTDataset">ROOTDataset</a></code> object.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@classmethod
def from_root_files(cls, filenames: Union[List[str], str]) -&gt; ROOTDataset:
    &#34;&#34;&#34;Reads a list of ROOT files and returns a `ROOTDataset` object. Can also be used to read a single file.

    Args:
        filenames (list[str] or str): List of paths to the ROOT files or a single path to a ROOT file.

    Returns:
        ROOTDataset: `ROOTDataset` object.
    &#34;&#34;&#34;
    if isinstance(filenames, str):
        filenames = [filenames]
    return cls.concat([cls.from_root_file(filename) for filename in filenames])</code></pre>
</details>
</dd>
<dt id="jidenn.data.ROOTDataset.ROOTDataset.load"><code class="name flex">
<span>def <span class="ident">load</span></span>(<span>file: str, element_spec_path: Optional[str] = None) ‑> <a title="jidenn.data.ROOTDataset.ROOTDataset" href="#jidenn.data.ROOTDataset.ROOTDataset">ROOTDataset</a></span>
</code></dt>
<dd>
<div class="desc"><p>Loads a <code><a title="jidenn.data.ROOTDataset.ROOTDataset" href="#jidenn.data.ROOTDataset.ROOTDataset">ROOTDataset</a></code> object from a saved directory. The saved object is a <code>tf.data.Dataset</code> object
saved using <code>tf.data.Dataset.save</code>. The <code>element_spec</code> is loaded separately as a pickle object and is used
to create the <code>tf.data.Dataset</code> object. Defaults to <code>element_spec</code> file inside the saved directory.
Optionally, the <code>element_spec_path</code> can be passed as an argument as full path.</p>
<p>Example:
Example of creating a <code><a title="jidenn.data.ROOTDataset.ROOTDataset" href="#jidenn.data.ROOTDataset.ROOTDataset">ROOTDataset</a></code> object from saved <code>tf.data.Dataset</code> object.</p>
<pre><code class="language-python">import pickle
import tensorflow as tf

dataset = tf.data.Dataset.from_tensor_slices({'a': [1, 2, 3], 'b': [4, 5, 6]})
dataset.save(file_path)
with open(os.path.join(file_path, 'element_spec'), 'wb') as f:
    pickle.dump(dataset.element_spec, f)

root_dataset = ROOTDataset.load(file_path)

</code></pre>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>file</code></strong> :&ensp;<code>str</code></dt>
<dd>Path to the saved directory.</dd>
<dt><strong><code>element_spec_path</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>Path to the saved <code>element_spec</code> as a pickle file. Defaults to <code>element_spec</code> file inside the saved directory.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="jidenn.data.ROOTDataset.ROOTDataset" href="#jidenn.data.ROOTDataset.ROOTDataset">ROOTDataset</a></code></dt>
<dd><code><a title="jidenn.data.ROOTDataset.ROOTDataset" href="#jidenn.data.ROOTDataset.ROOTDataset">ROOTDataset</a></code> object.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@classmethod
def load(cls, file: str, element_spec_path: Optional[str] = None) -&gt; ROOTDataset:
    &#34;&#34;&#34;Loads a `ROOTDataset` object from a saved directory. The saved object is a `tf.data.Dataset` object
    saved using `tf.data.Dataset.save`. The `element_spec` is loaded separately as a pickle object and is used 
    to create the `tf.data.Dataset` object. Defaults to `element_spec` file inside the saved directory.
    Optionally, the `element_spec_path` can be passed as an argument as full path.

    Example:
    Example of creating a `ROOTDataset` object from saved `tf.data.Dataset` object.
    ```python
    import pickle
    import tensorflow as tf

    dataset = tf.data.Dataset.from_tensor_slices({&#39;a&#39;: [1, 2, 3], &#39;b&#39;: [4, 5, 6]})
    dataset.save(file_path)
    with open(os.path.join(file_path, &#39;element_spec&#39;), &#39;wb&#39;) as f:
        pickle.dump(dataset.element_spec, f)

    root_dataset = ROOTDataset.load(file_path)

    ```

    Args:
        file (str): Path to the saved directory.
        element_spec_path (str, optional): Path to the saved `element_spec` as a pickle file. Defaults to `element_spec` file inside the saved directory.


    Returns:
        ROOTDataset: `ROOTDataset` object.
    &#34;&#34;&#34;

    element_spec_path = os.path.join(
        file, &#39;element_spec&#39;) if element_spec_path is None else element_spec_path
    with open(element_spec_path, &#39;rb&#39;) as f:
        element_spec = pickle.load(f)
    dataset = tf.data.Dataset.load(
        file, compression=&#39;GZIP&#39;, element_spec=element_spec)
    return cls(dataset, list(element_spec.keys()))</code></pre>
</details>
</dd>
</dl>
<h3>Instance variables</h3>
<dl>
<dt id="jidenn.data.ROOTDataset.ROOTDataset.dataset"><code class="name">var <span class="ident">dataset</span> : tensorflow.python.data.ops.dataset_ops.DatasetV2</code></dt>
<dd>
<div class="desc"><p>Tensorflow <code>tf.data.Dataset</code> object created from the ROOT file.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def dataset(self) -&gt; tf.data.Dataset:
    &#34;&#34;&#34;Tensorflow `tf.data.Dataset` object created from the ROOT file.&#34;&#34;&#34;
    return self._dataset</code></pre>
</details>
</dd>
<dt id="jidenn.data.ROOTDataset.ROOTDataset.variables"><code class="name">var <span class="ident">variables</span> : List[str]</code></dt>
<dd>
<div class="desc"><p>List of variable names inferred from the ROOT file.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def variables(self) -&gt; List[str]:
    &#34;&#34;&#34;List of variable names inferred from the ROOT file.&#34;&#34;&#34;
    return self._variables</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="jidenn.data.ROOTDataset.ROOTDataset.map"><code class="name flex">
<span>def <span class="ident">map</span></span>(<span>self, func: Callable[[<a title="jidenn.data.ROOTDataset.ROOTVariables" href="#jidenn.data.ROOTDataset.ROOTVariables">ROOTVariables</a>], <a title="jidenn.data.ROOTDataset.ROOTVariables" href="#jidenn.data.ROOTDataset.ROOTVariables">ROOTVariables</a>]) ‑> <a title="jidenn.data.ROOTDataset.ROOTDataset" href="#jidenn.data.ROOTDataset.ROOTDataset">ROOTDataset</a></span>
</code></dt>
<dd>
<div class="desc"><p>Maps a function to the dataset. The function should take a <code><a title="jidenn.data.ROOTDataset.ROOTVariables" href="#jidenn.data.ROOTDataset.ROOTVariables">ROOTVariables</a></code> object as input and return a <code><a title="jidenn.data.ROOTDataset.ROOTVariables" href="#jidenn.data.ROOTDataset.ROOTVariables">ROOTVariables</a></code> object as output.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>func</code></strong> :&ensp;<code>Callable</code></dt>
<dd>Function to be mapped.</dd>
<dt><strong><code>num_parallel_calls</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Number of parallel calls to use. Defaults to <code>None</code>.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="jidenn.data.ROOTDataset.ROOTDataset" href="#jidenn.data.ROOTDataset.ROOTDataset">ROOTDataset</a></code></dt>
<dd>Mapped <code><a title="jidenn.data.ROOTDataset.ROOTDataset" href="#jidenn.data.ROOTDataset.ROOTDataset">ROOTDataset</a></code> object.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def map(self, func: Callable[[ROOTVariables], ROOTVariables]) -&gt; ROOTDataset:
    &#34;&#34;&#34;Maps a function to the dataset. The function should take a `ROOTVariables` object as input and return a `ROOTVariables` object as output.

    Args:
        func (Callable): Function to be mapped.
        num_parallel_calls (int, optional): Number of parallel calls to use. Defaults to `None`.

    Returns:
        ROOTDataset: Mapped `ROOTDataset` object.
    &#34;&#34;&#34;
    new_ds = self.dataset.map(func)
    new_ds = new_ds.prefetch(tf.data.AUTOTUNE)
    return ROOTDataset(new_ds, list(new_ds.element_spec.keys()))</code></pre>
</details>
</dd>
<dt id="jidenn.data.ROOTDataset.ROOTDataset.save"><code class="name flex">
<span>def <span class="ident">save</span></span>(<span>self, save_path: str, element_spec_path: Optional[str] = None, shard_func: Optional[Callable[[<a title="jidenn.data.ROOTDataset.ROOTVariables" href="#jidenn.data.ROOTDataset.ROOTVariables">ROOTVariables</a>], tf.Tensor]] = None) ‑> None</span>
</code></dt>
<dd>
<div class="desc"><p>Saves a <code><a title="jidenn.data.ROOTDataset.ROOTDataset" href="#jidenn.data.ROOTDataset.ROOTDataset">ROOTDataset</a></code> object to a directory. The saved object is a <code>tf.data.Dataset</code> object
and the <code>element_spec</code> is saved separately as a pickle object saved inside the saved directory.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>save_path</code></strong> :&ensp;<code>str</code></dt>
<dd>Path to the directory where the object is to be saved.</dd>
<dt><strong><code>element_spec_path</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>Path to the saved <code>element_spec</code> as a pickle file. Defaults to <code>element_spec</code> file inside the saved directory.</dd>
<dt><strong><code>shard_func</code></strong> :&ensp;<code>Callable</code>, optional</dt>
<dd>Function to shard the dataset. Used as a <code>shard_func</code> argument in <code>tf.data.Dataset.save</code>. Defaults to <code>None</code>.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>None</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def save(self, save_path: str, element_spec_path: Optional[str] = None, shard_func: Optional[Callable[[ROOTVariables], tf.Tensor]] = None) -&gt; None:
    &#34;&#34;&#34;Saves a `ROOTDataset` object to a directory. The saved object is a `tf.data.Dataset` object 
    and the `element_spec` is saved separately as a pickle object saved inside the saved directory.

    Args:
        save_path (str): Path to the directory where the object is to be saved.
        element_spec_path (str, optional): Path to the saved `element_spec` as a pickle file. Defaults to `element_spec` file inside the saved directory.
        shard_func (Callable, optional): Function to shard the dataset. Used as a `shard_func` argument in `tf.data.Dataset.save`. Defaults to `None`.

    Returns:
        None

    &#34;&#34;&#34;
    element_spec_path = os.path.join(
        save_path, &#39;element_spec&#39;) if element_spec_path is None else element_spec_path
    element_spec = self._dataset.element_spec
    self._dataset.save(save_path, compression=&#39;GZIP&#39;, shard_func=shard_func)
    with open(element_spec_path, &#39;wb&#39;) as f:
        pickle.dump(element_spec, f)</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<header>
<a class="homelink" rel="home" title="JIDENN" href="https://jansam.wieno.sk/JIDENN/">
<img src="images/q_g_tagging.jpeg" alt=""> JIDENN
</a>
</header>
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="jidenn.data" href="index.html">jidenn.data</a></code></li>
</ul>
</li>
<li><h3><a href="#header-variables">Global variables</a></h3>
<ul class="">
<li><code><a title="jidenn.data.ROOTDataset.ROOTVariables" href="#jidenn.data.ROOTDataset.ROOTVariables">ROOTVariables</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="jidenn.data.ROOTDataset.awkward_to_tensor" href="#jidenn.data.ROOTDataset.awkward_to_tensor">awkward_to_tensor</a></code></li>
<li><code><a title="jidenn.data.ROOTDataset.pandas_to_tensor" href="#jidenn.data.ROOTDataset.pandas_to_tensor">pandas_to_tensor</a></code></li>
<li><code><a title="jidenn.data.ROOTDataset.read_ttree" href="#jidenn.data.ROOTDataset.read_ttree">read_ttree</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="jidenn.data.ROOTDataset.ROOTDataset" href="#jidenn.data.ROOTDataset.ROOTDataset">ROOTDataset</a></code></h4>
<ul class="two-column">
<li><code><a title="jidenn.data.ROOTDataset.ROOTDataset.concat" href="#jidenn.data.ROOTDataset.ROOTDataset.concat">concat</a></code></li>
<li><code><a title="jidenn.data.ROOTDataset.ROOTDataset.dataset" href="#jidenn.data.ROOTDataset.ROOTDataset.dataset">dataset</a></code></li>
<li><code><a title="jidenn.data.ROOTDataset.ROOTDataset.from_root_file" href="#jidenn.data.ROOTDataset.ROOTDataset.from_root_file">from_root_file</a></code></li>
<li><code><a title="jidenn.data.ROOTDataset.ROOTDataset.from_root_files" href="#jidenn.data.ROOTDataset.ROOTDataset.from_root_files">from_root_files</a></code></li>
<li><code><a title="jidenn.data.ROOTDataset.ROOTDataset.load" href="#jidenn.data.ROOTDataset.ROOTDataset.load">load</a></code></li>
<li><code><a title="jidenn.data.ROOTDataset.ROOTDataset.map" href="#jidenn.data.ROOTDataset.ROOTDataset.map">map</a></code></li>
<li><code><a title="jidenn.data.ROOTDataset.ROOTDataset.save" href="#jidenn.data.ROOTDataset.ROOTDataset.save">save</a></code></li>
<li><code><a title="jidenn.data.ROOTDataset.ROOTDataset.variables" href="#jidenn.data.ROOTDataset.ROOTDataset.variables">variables</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>