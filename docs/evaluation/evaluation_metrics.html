<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>jidenn.evaluation.evaluation_metrics API documentation</title>
<meta name="description" content="Module containing custom metrics for evaluating models mainly used in HEP applications." />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS_CHTML" integrity="sha256-kZafAc6mZvK3W3v1pHOcUix30OHQN6pU/NO2oFkqZVw=" crossorigin></script>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
<link rel="canonical" href="http://jansam.wieno.sk/JIDENN/jidenn/evaluation/evaluation_metrics.html">
<link rel="icon" href="images/q_g_tagging.jpeg">
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>jidenn.evaluation.evaluation_metrics</code></h1>
</header>
<section id="section-intro">
<p>Module containing custom metrics for evaluating models mainly used in HEP applications.</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;
Module containing custom metrics for evaluating models mainly used in HEP applications. 
&#34;&#34;&#34;
from typing import List, Dict, Literal, Optional, Union, Tuple
import tensorflow as tf
# import tensorflow_probability as tfp
import numpy as np


class BinaryEfficiency(tf.keras.metrics.Metric):
    r&#34;&#34;&#34;Binary Efficiency metric.
    It is defined as
    $$\varepsilon_i=\frac{T_i}{T_i+F_i}$$
    where $T_i$ is the number of correctly classified data of class $i$ 
    and $F_i$ is the number of incorrectly classified data of class $i$.

    If $i = 1$, then it is the efficiency is called true positive rate (TPR).

    Args:
        label_id (int, optional): The label id for which the efficiency is calculated. Defaults to 1.
        threshold (float, optional): The threshold for the prediction. Defaults to 0.5.
        name (str, optional): The name of the metric. Defaults to &#39;efficiency&#39;.
    &#34;&#34;&#34;

    def __init__(self, label_id: Literal[0, 1] = 1, threshold=0.5, name=&#39;efficiency&#39;):
        super(BinaryEfficiency, self).__init__(name=name)
        self.tp = self.add_weight(name=&#39;tp&#39;, initializer=&#39;zeros&#39;)
        self.total = self.add_weight(name=&#39;total&#39;, initializer=&#39;zeros&#39;)
        self.label_id = label_id
        self.threshold = threshold

    def update_state(self, y_true: Union[tf.Tensor, np.ndarray], y_pred: Union[tf.Tensor, np.ndarray], sample_weight: Union[tf.Tensor, np.ndarray] = None):
        &#34;&#34;&#34;Accumulates the efficiency.

        Args:
            y_true (tf.Tensor): The true labels.
            y_pred (tf.Tensor): The predicted labels.
            sample_weight (tf.Tensor, optional): The sample weights. Defaults to None.
        &#34;&#34;&#34;
        y_pred = tf.cast(y_pred &gt; self.threshold, tf.bool)
        y_true = tf.cast(y_true, tf.bool)
        if self.label_id is not None and self.label_id != 1:
            y_true = tf.logical_not(y_true)
            y_pred = tf.logical_not(y_pred)

        values = tf.logical_and(tf.equal(y_true, True), tf.equal(y_pred, True))
        values = tf.cast(values, self.dtype)
        if sample_weight is not None:
            sample_weight = tf.cast(sample_weight, self.dtype)
            sample_weight = tf.broadcast_weights(sample_weight, values)
            values = tf.multiply(values, sample_weight)

        self.tp.assign_add(tf.reduce_sum(values))
        self.total.assign_add(tf.reduce_sum(tf.cast(y_true, self.dtype)))

    def result(self):
        return self.tp / self.total

    def reset_state(self):
        self.tp.assign(0.)
        self.total.assign(0.)

    def get_config(self):
        config = super(BinaryEfficiency, self).get_config()
        config.update({&#39;threshold&#39;: self.threshold, &#39;label_id&#39;: self.label_id})
        return config


class BinaryRejection(tf.keras.metrics.Metric):
    r&#34;&#34;&#34;Binary Rejection metric.
    It is defined as
    $$\varepsilon_i^{-1}=\frac{T_i+F_i}{T_i}$$
    where $T_i$ is the number of correctly classified data of class $i$ 
    and $F_i$ is the number of incorrectly classified data of class $i$.

    Args:
        label_id (int, optional): The label id for which the efficiency is calculated. Defaults to 1.
        threshold (float, optional): The threshold for the prediction. Defaults to 0.5.
        name (str, optional): The name of the metric. Defaults to &#39;rejection&#39;.
    &#34;&#34;&#34;

    def __init__(self, label_id: Literal[0, 1] = 1, threshold=0.5, name=&#39;rejection&#39;):
        super(BinaryRejection, self).__init__(name=name)
        self.tp = self.add_weight(name=&#39;tp&#39;, initializer=&#39;zeros&#39;)
        self.total = self.add_weight(name=&#39;total&#39;, initializer=&#39;zeros&#39;)
        self.label_id = label_id
        self.threshold = threshold

    def update_state(self, y_true: Union[tf.Tensor, np.ndarray], y_pred: Union[tf.Tensor, np.ndarray], sample_weight: Union[tf.Tensor, np.ndarray] = None):
        &#34;&#34;&#34;Accumulates the efficiency.

        Args:
            y_true (tf.Tensor): The true labels.
            y_pred (tf.Tensor): The predicted labels.
            sample_weight (tf.Tensor, optional): The sample weights. Defaults to None.
        &#34;&#34;&#34;
        y_pred = tf.cast(y_pred &gt; self.threshold, tf.bool)
        y_true = tf.cast(y_true, tf.bool)
        if self.label_id is not None and self.label_id != 1:
            y_true = tf.logical_not(y_true)
            y_pred = tf.logical_not(y_pred)

        values = tf.logical_and(tf.equal(y_true, True), tf.equal(y_pred, True))
        values = tf.cast(values, self.dtype)
        if sample_weight is not None:
            sample_weight = tf.cast(sample_weight, self.dtype)
            sample_weight = tf.broadcast_weights(sample_weight, values)
            values = tf.multiply(values, sample_weight)
        self.tp.assign_add(tf.reduce_sum(values))
        self.total.assign_add(tf.reduce_sum(tf.cast(y_true, self.dtype)))

    def result(self):
        tpr = self.tp / self.total
        return 1.0 / (1 - tpr)

    def reset_state(self):
        self.tp.assign(0.)
        self.total.assign(0.)

    def get_config(self):
        config = super(BinaryRejection, self).get_config()
        config.update({&#39;threshold&#39;: self.threshold, &#39;label_id&#39;: self.label_id})
        return config


class RejectionAtEfficiency(tf.keras.metrics.SpecificityAtSensitivity):
    &#34;&#34;&#34;Rejection at efficiency metric.
    in this case the threshold is chosen such that the efficiency of one class is equal to the given `efficiency`.

    Args:
        efficiency (float, optional): The efficiency. Defaults to 0.5.
        label_id (int, optional): The label id for which the efficiency is calculated. Defaults to 1.
        name (str, optional): The name of the metric. Defaults to &#39;rejection_at_efficiency&#39;.
    &#34;&#34;&#34;

    def __init__(self, efficiency: float = 0.5, label_id: Literal[0, 1] = 1, name=&#39;rejection_at_efficiency&#39;):
        super(RejectionAtEfficiency, self).__init__(
            name=name, sensitivity=efficiency)
        self.label_id = label_id
        self.efficiency = efficiency

    def update_state(self, y_true: Union[tf.Tensor, np.ndarray], y_pred: Union[tf.Tensor, np.ndarray], sample_weight: Union[tf.Tensor, np.ndarray] = None):
        &#34;&#34;&#34;Accumulates the efficiency.

        Args:
            y_true (tf.Tensor): The true labels.
            y_pred (tf.Tensor): The predicted labels.
            sample_weight (tf.Tensor, optional): The sample weights. Defaults to None.
        &#34;&#34;&#34;
        y_true = tf.cast(y_true, tf.bool)
        if self.label_id is not None and self.label_id != 1:
            y_true = tf.logical_not(y_true)
            y_pred = 1 - y_pred
        super(RejectionAtEfficiency, self).update_state(
            y_true, y_pred, sample_weight=sample_weight)

    def get_config(self):
        config = super(RejectionAtEfficiency, self).get_config()
        config.update({&#39;efficiency&#39;: self.efficiency,
                      &#39;label_id&#39;: self.label_id})
        return config

    def result(self):
        return 1 / super(RejectionAtEfficiency, self).result()


class EffectiveTaggingEfficiency(tf.keras.metrics.Metric):

    def __init__(self, bins: List[float] = [0, 0.1, 0.25, 0.5, 0.625, 0.75, 0.875, 1], threshold: float = 0.5, name=&#39;eff_tag_efficiency&#39;, **kwargs):
        super(EffectiveTaggingEfficiency, self).__init__(name=name, **kwargs)
        for value in bins:
            if value &lt; 0 or value &gt; 1:
                raise ValueError(&#39;The bins must be between 0 and 1.&#39;)
        self.bins = bins
        self.threshold = threshold
        self.bin_sums = self.add_weight(
            name=&#39;bin_sums&#39;, initializer=&#39;zeros&#39;, shape=(len(bins) - 1,))
        self.bin_counts = self.add_weight(
            name=&#39;bin_counts&#39;, initializer=&#39;zeros&#39;, shape=(len(bins) - 1,))

    def update_state(self, y_true: Union[tf.Tensor, np.ndarray], score: Union[tf.Tensor, np.ndarray], sample_weight: Union[tf.Tensor, np.ndarray] = None):
        &#34;&#34;&#34;Accumulates the metric.

        Args:
            y_true (Union[tf.Tensor, np.ndarray]): The true labels.
            score (Union[tf.Tensor, np.ndarray]): The output of the model, i.e. number **between 0 and 1**.
        &#34;&#34;&#34;
        score = tf.squeeze(score)
        y_true = tf.squeeze(y_true)
        dilusion_factor = tf.abs(2 * score - 1)
        indicies = tf.searchsorted(self.bins, dilusion_factor)
        pred = tf.cast(score &gt; 0.5, tf.bool)
        wrong_tag = tf.cast(tf.not_equal(
            pred, tf.cast(y_true, tf.bool)), tf.float32)

        bin_counts = tf.cast(tf.math.bincount(
            indicies, minlength=len(self.bins)), tf.float32)
        bin_counts = bin_counts[1:]
        bin_sums = tf.math.bincount(
            indicies, weights=wrong_tag, minlength=len(self.bins))
        bin_sums = bin_sums[1:]
        self.bin_counts.assign_add(bin_counts)
        self.bin_sums.assign_add(bin_sums)

    def get_config(self):
        config = super(EffectiveTaggingEfficiency, self).get_config()
        config.update({&#39;bins&#39;: self.bins, &#39;threshold&#39;: self.threshold})
        return config

    def result(self):
        mask = tf.where(self.bin_counts &gt; 0, True, False)
        bin_counts = tf.boolean_mask(self.bin_counts, mask)
        bin_sums = tf.boolean_mask(self.bin_sums, mask)
        binned_wrong_tag_fraction = bin_sums / bin_counts
        eff = bin_counts / tf.reduce_sum(bin_counts)
        eff_tag_eff = tf.reduce_sum(
            eff * (1 - 2 * binned_wrong_tag_fraction)**2)
        return eff_tag_eff

    def reset_state(self):
        self.bin_sums.assign(tf.zeros_like(self.bin_sums))
        self.bin_counts.assign(tf.zeros_like(self.bin_counts))


class FixedWorkingPointBase(tf.keras.metrics.Metric):
    r&#34;&#34;&#34;
    Base class for metrics that calculate the efficiencies and threshold at a fixed working point, 
    i.e. one fixed efficiency with variables threshold.

    Args:
        working_point (float): The working point, i.e. the efficiency at which the threshold is calculated.
        num_thresholds (int): The number of thresholds to calculate for finding the threshold at the working point.
        name (str): The name of the metric. 
        dtype (tf.dtypes.DType): The data type of the metric.       
    &#34;&#34;&#34;

    def __init__(self, working_point: float = 0.5,
                 num_thresholds: int = 200, name: Optional[str] = None,
                 dtype: Optional[tf.dtypes.DType] = None):
        super().__init__(name=name, dtype=dtype)
        self.working_point = working_point
        self.num_thresholds = num_thresholds

        self.true_positives = self.add_weight(name=&#39;true_positives&#39;, initializer=&#39;zeros&#39;, shape=(num_thresholds,))
        self.total_positives = self.add_weight(name=&#39;total_positives&#39;, initializer=&#39;zeros&#39;, shape=(1,))
        self.false_negatives = self.add_weight(name=&#39;false_negatives&#39;, initializer=&#39;zeros&#39;, shape=(num_thresholds,))
        self.total_negatives = self.add_weight(name=&#39;total_negatives&#39;, initializer=&#39;zeros&#39;, shape=(1,))

        thresholds = [
            (i + 1) * 1.0 / (num_thresholds - 1)
            for i in range(num_thresholds - 2)
        ]
        self.thresholds = [0.0] + thresholds + [1.0]

    def update_state(self, y_true: Union[tf.Tensor, np.ndarray], y_pred: Union[tf.Tensor, np.ndarray], sample_weight: Optional[Union[tf.Tensor, np.ndarray]] = None):
        &#34;&#34;&#34;Accumulates the confusion matrix statistics. The true positives and false negatives are calculated for each threshold.
        The total positives and total negatives are calculated once.

        Args:
            y_true (Union[tf.Tensor, np.ndarray]): True labels.
            y_pred (Union[tf.Tensor, np.ndarray]): Predicted scores, i.e. the output of the model.
            sample_weight (Optional[Union[tf.Tensor, np.ndarray]], optional): Sample weights. Defaults to None.
        &#34;&#34;&#34;
        y_pred = tf.cast(tf.expand_dims(y_pred, axis=1) &gt; self.thresholds, tf.bool)
        y_true = tf.expand_dims(y_true, axis=1)
        positive_equals = tf.logical_and(tf.equal(y_true, True), tf.equal(y_pred, True))
        negative_equals = tf.logical_and(tf.equal(y_true, False), tf.equal(y_pred, False))
        if sample_weight is not None:
            sample_weight = tf.cast(sample_weight, tf.float32)
            sample_weight = tf.expand_dims(sample_weight, axis=1)
            positive_equals = tf.multiply(tf.cast(positive_equals, tf.float32), sample_weight)
            negative_equals = tf.multiply(tf.cast(negative_equals, tf.float32), sample_weight)

        self.true_positives.assign_add(tf.reduce_sum(tf.cast(positive_equals, tf.float32), axis=0))
        self.false_negatives.assign_add(tf.reduce_sum(tf.cast(negative_equals, tf.float32), axis=0))

        positives = tf.cast(tf.equal(y_true, True), tf.float32)
        positives = tf.multiply(positives, sample_weight) if sample_weight is not None else positives
        negatives = tf.cast(tf.equal(y_true, False), tf.float32)
        negatives = tf.multiply(negatives, sample_weight) if sample_weight is not None else negatives
        self.total_positives.assign_add(tf.reduce_sum(positives, axis=0))
        self.total_negatives.assign_add(tf.reduce_sum(negatives, axis=0))

    def result(self) -&gt; Tuple[tf.Tensor, tf.Tensor, tf.Tensor]:
        &#34;&#34;&#34;Calculates the efficiencies and threshold at the working point.
        Both the fixed and variable efficiencies are calculated and returned
        to allow a check of the working point.

        Returns:
            Tuple[tf.Tensor, tf.Tensor, tf.Tensor]: The fixed efficiency, the variable efficiency and the threshold at the working point.

        &#34;&#34;&#34;
        efficiency_positivess = self.true_positives / self.total_positives
        efficiency_negatives = self.false_negatives / self.total_negatives

        result_index = self._find_index_of_threshold(efficiency_positivess, self.working_point)
        positive_at_wp = tf.gather(efficiency_positivess, result_index)
        negative_at_wp = tf.gather(efficiency_negatives, result_index)
        threshold_at_wp = tf.gather(self.thresholds, result_index)

        return positive_at_wp, negative_at_wp, threshold_at_wp

    def _find_index_of_threshold(self, efficiencies: tf.Tensor, working_point: float) -&gt; tf.Tensor:
        &#34;&#34;&#34;Finds the index of the threshold at the working point. &#34;&#34;&#34;
        result_index = tf.math.squared_difference(efficiencies, working_point)
        result_index = tf.argmin(result_index, axis=0)
        return result_index

    def reset_state(self):
        &#34;&#34;&#34;Resets the confusion matrix statistics.&#34;&#34;&#34;
        self.true_positives.assign(tf.zeros_like(self.true_positives))
        self.total_positives.assign(tf.zeros_like(self.total_positives))
        self.false_negatives.assign(tf.zeros_like(self.false_negatives))
        self.total_negatives.assign(tf.zeros_like(self.total_negatives))


class EfficiencyAtFixedWorkingPoint(FixedWorkingPointBase):
    &#34;&#34;&#34;Calculates the efficiency at a fixed working point. The working point is defined by the user.

    Args:
        working_point (float): The working point. Defaults to 0.5.
        fixed_label_id (Literal[0, 1], optional): The label id whose efficiency is fixed. Defaults to 1.
        returned_label_id (Literal[0, 1], optional): The label id whose efficiency is returned. Defaults to 0.
        num_thresholds (int, optional): The number of thresholds to use for the estimation. Defaults to 200.
        name (Optional[str], optional): The name of the metric. Defaults to &#39;efficiency_at_fixed_wp&#39;.
        dtype (Optional[tf.dtypes.DType], optional): The data type of the metric. Defaults to None.
    &#34;&#34;&#34;

    def __init__(self, working_point: float = 0.5, fixed_label_id: Literal[0, 1] = 1, returned_label_id: Literal[0, 1] = 0,
                 num_thresholds: int = 200, name: Optional[str] = &#39;efficiency_at_fixed_wp&#39;, dtype: Optional[tf.dtypes.DType] = None):

        super().__init__(working_point=working_point, num_thresholds=num_thresholds, name=name, dtype=dtype)
        self.fixed_label_id = fixed_label_id
        self.returned_label_id = returned_label_id

    def result(self) -&gt; tf.Tensor:
        &#34;&#34;&#34;Calculates the efficiency at the working point.

        Raises:
            ValueError: If the fixed_label_id is not 0 or 1.

        Returns:
            tf.Tensor: The efficiency at the working point.
        &#34;&#34;&#34;
        efficiency_positivess = self.true_positives / self.total_positives
        efficiency_negatives = self.false_negatives / self.total_negatives

        if self.fixed_label_id == 1:
            fixed_efficiency = efficiency_positivess
        elif self.fixed_label_id == 0:
            fixed_efficiency = efficiency_negatives
        else:
            raise ValueError(f&#39;fixed_label_id must be 0 or 1, but is {self.fixed_label_id}&#39;)

        closest_index = self._find_index_of_threshold(fixed_efficiency, self.working_point)

        if self.returned_label_id == 1:
            efficiency_at_wp = tf.gather(efficiency_positivess, closest_index)
        elif self.returned_label_id == 0:
            efficiency_at_wp = tf.gather(efficiency_negatives, closest_index)

        return efficiency_at_wp


class RejectionAtFixedWorkingPoint(EfficiencyAtFixedWorkingPoint):
    &#34;&#34;&#34;Calculates the rejection at a fixed working point. The working point is defined by the user.

    Args:
        working_point (float): The working point. Defaults to 0.5.
        fixed_label_id (Literal[0, 1], optional): The label id whose efficiency is fixed. Defaults to 1.
        returned_label_id (Literal[0, 1], optional): The label id whose efficiency is returned. Defaults to 0.
        num_thresholds (int, optional): The number of thresholds to use for the estimation. Defaults to 200.
        name (Optional[str], optional): The name of the metric. Defaults to &#39;efficiency_at_fixed_wp&#39;.
        dtype (Optional[tf.dtypes.DType], optional): The data type of the metric. Defaults to None.
    &#34;&#34;&#34;

    def __init__(self, working_point: float = 0.5, fixed_label_id: Literal[0, 1] = 1, returned_label_id: Literal[0, 1] = 0,
                 num_thresholds: int = 200, name: Optional[str] = &#39;rejection_at_fixed_wp&#39;, dtype: Optional[tf.dtypes.DType] = None):
        super().__init__(working_point=working_point, fixed_label_id=fixed_label_id, returned_label_id=returned_label_id,
                         num_thresholds=num_thresholds, name=name, dtype=dtype)

    def result(self) -&gt; tf.Tensor:
        &#34;&#34;&#34;Calculates the rejection at the working point.

        Returns:
            tf.Tensor: The rejection at the working point.
        &#34;&#34;&#34;

        return 1.0 / (1 - super().result())


class ThresholdAtFixedWorkingPoint(FixedWorkingPointBase):
    &#34;&#34;&#34;Calculates the threshold at a fixed working point. The working point is defined by the user.

    Args:
        working_point (float): The working point. Defaults to 0.5.
        fixed_label_id (Literal[0, 1], optional): The label id whose efficiency is fixed. Defaults to 1.
        num_thresholds (int, optional): The number of thresholds to use for the estimation. Defaults to 200.
        name (Optional[str], optional): The name of the metric. Defaults to &#39;threshold_at_fixed_wp&#39;.
        dtype (Optional[tf.dtypes.DType], optional): The data type of the metric. Defaults to None.
    &#34;&#34;&#34;

    def __init__(self, working_point: float = 0.5, num_thresholds: int = 200, fixed_label_id: Literal[0, 1] = 1, name: Optional[str] = &#39;threshold_at_fixed_efficiency&#39;, dtype: Optional[tf.dtypes.DType] = None):
        super().__init__(working_point=working_point, num_thresholds=num_thresholds, name=name, dtype=dtype)
        self.fixed_label_id = fixed_label_id

    def result(self) -&gt; tf.Tensor:
        &#34;&#34;&#34;Calculates the threshold at the working point.

        Raises:
            ValueError: If the fixed_label_id is not 0 or 1.

        Returns:
            tf.Tensor: The threshold at the working point.
        &#34;&#34;&#34;

        if self.fixed_label_id == 1:
            efficiencies = self.true_positives / self.total_positives
        elif self.fixed_label_id == 0:
            efficiencies = self.false_negatives / self.total_negatives
        else:
            raise ValueError(f&#39;fixed_label_id must be 0 or 1, but is {self.fixed_label_id}&#39;)

        closest_index = self._find_index_of_threshold(efficiencies, self.working_point)

        return tf.gather(self.thresholds, closest_index)


def get_metrics(threshold: float = 0.5) -&gt; List[tf.keras.metrics.Metric]:
    &#34;&#34;&#34;Returns a list of metrics.

    Args:
        threshold (float, optional): The threshold for the prediction. Defaults to 0.5.

    Returns:
        List[tf.keras.metrics.Metric]: The list of selected metrics.
    &#34;&#34;&#34;
    metrics = [
        tf.keras.metrics.BinaryCrossentropy(name=&#39;loss&#39;),
        tf.keras.metrics.BinaryAccuracy(
            name=&#39;binary_accuracy&#39;, threshold=threshold),
        BinaryEfficiency(name=&#39;gluon_efficiency&#39;,
                         label_id=0, threshold=threshold),
        BinaryEfficiency(name=&#39;quark_efficiency&#39;,
                         label_id=1, threshold=threshold),
        BinaryRejection(name=&#39;gluon_rejection&#39;,
                        label_id=0, threshold=threshold),
        BinaryRejection(name=&#39;quark_rejection&#39;,
                        label_id=1, threshold=threshold),
        EfficiencyAtFixedWorkingPoint(name=&#39;gluon_efficiency_at_quark_50wp&#39;,
                                      fixed_label_id=1, working_point=0.5, returned_label_id=0),
        EfficiencyAtFixedWorkingPoint(name=&#39;quark_efficiency_at_quark_50wp&#39;,
                                      fixed_label_id=1, working_point=0.5, returned_label_id=1),
        RejectionAtFixedWorkingPoint(name=&#39;gluon_rejection_at_quark_50wp&#39;,
                                     fixed_label_id=1, working_point=0.5, returned_label_id=0),
        ThresholdAtFixedWorkingPoint(name=&#39;threshold_at_fixed_quark_50wp&#39;,
                                     fixed_label_id=1, working_point=0.5),
        EfficiencyAtFixedWorkingPoint(name=&#39;gluon_efficiency_at_quark_80wp&#39;,
                                      fixed_label_id=1, working_point=0.8, returned_label_id=0),
        EfficiencyAtFixedWorkingPoint(name=&#39;quark_efficiency_at_quark_80wp&#39;,
                                      fixed_label_id=1, working_point=0.8, returned_label_id=1),
        RejectionAtFixedWorkingPoint(name=&#39;gluon_rejection_at_quark_80wp&#39;,
                                     fixed_label_id=1, working_point=0.8, returned_label_id=0),
        ThresholdAtFixedWorkingPoint(name=&#39;threshold_at_fixed_quark_80wp&#39;,
                                     fixed_label_id=1, working_point=0.8),
        EffectiveTaggingEfficiency(
            name=&#39;effective_tagging_efficiency&#39;, threshold=threshold),
        tf.keras.metrics.AUC(name=&#39;auc&#39;)]
    return metrics


def calculate_metrics(y_true: np.ndarray, score: np.ndarray, threshold: float = 0.5, weights: Optional[np.ndarray] = None) -&gt; Dict[str, float]:
    &#34;&#34;&#34;Calculates the metrics.
    Args:
        y_true (np.ndarray): The true labels.
        score (np.ndarray): The output scores of the model.
        threshold (float, optional): The threshold for the prediction. Defaults to 0.5.
        weights (np.ndarray, optional): The sample weights. Defaults to None.
    Returns:
        Dict[str, float]: The dictionary of metric names and values.
    &#34;&#34;&#34;
    metrics = get_metrics(threshold)
    results = {}
    for metric in metrics:
        metric.reset_state()
        metric.update_state(y_true, score, sample_weight=weights)
        result = metric.result().numpy()
        results[metric.name] = result
    return results</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="jidenn.evaluation.evaluation_metrics.calculate_metrics"><code class="name flex">
<span>def <span class="ident">calculate_metrics</span></span>(<span>y_true: numpy.ndarray, score: numpy.ndarray, threshold: float = 0.5, weights: Optional[numpy.ndarray] = None) ‑> Dict[str, float]</span>
</code></dt>
<dd>
<div class="desc"><p>Calculates the metrics.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>y_true</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>The true labels.</dd>
<dt><strong><code>score</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>The output scores of the model.</dd>
<dt><strong><code>threshold</code></strong> :&ensp;<code>float</code>, optional</dt>
<dd>The threshold for the prediction. Defaults to 0.5.</dd>
<dt><strong><code>weights</code></strong> :&ensp;<code>np.ndarray</code>, optional</dt>
<dd>The sample weights. Defaults to None.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>Dict[str, float]</code></dt>
<dd>The dictionary of metric names and values.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def calculate_metrics(y_true: np.ndarray, score: np.ndarray, threshold: float = 0.5, weights: Optional[np.ndarray] = None) -&gt; Dict[str, float]:
    &#34;&#34;&#34;Calculates the metrics.
    Args:
        y_true (np.ndarray): The true labels.
        score (np.ndarray): The output scores of the model.
        threshold (float, optional): The threshold for the prediction. Defaults to 0.5.
        weights (np.ndarray, optional): The sample weights. Defaults to None.
    Returns:
        Dict[str, float]: The dictionary of metric names and values.
    &#34;&#34;&#34;
    metrics = get_metrics(threshold)
    results = {}
    for metric in metrics:
        metric.reset_state()
        metric.update_state(y_true, score, sample_weight=weights)
        result = metric.result().numpy()
        results[metric.name] = result
    return results</code></pre>
</details>
</dd>
<dt id="jidenn.evaluation.evaluation_metrics.get_metrics"><code class="name flex">
<span>def <span class="ident">get_metrics</span></span>(<span>threshold: float = 0.5) ‑> List[keras.metrics.base_metric.Metric]</span>
</code></dt>
<dd>
<div class="desc"><p>Returns a list of metrics.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>threshold</code></strong> :&ensp;<code>float</code>, optional</dt>
<dd>The threshold for the prediction. Defaults to 0.5.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>List[tf.keras.metrics.Metric]</code></dt>
<dd>The list of selected metrics.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_metrics(threshold: float = 0.5) -&gt; List[tf.keras.metrics.Metric]:
    &#34;&#34;&#34;Returns a list of metrics.

    Args:
        threshold (float, optional): The threshold for the prediction. Defaults to 0.5.

    Returns:
        List[tf.keras.metrics.Metric]: The list of selected metrics.
    &#34;&#34;&#34;
    metrics = [
        tf.keras.metrics.BinaryCrossentropy(name=&#39;loss&#39;),
        tf.keras.metrics.BinaryAccuracy(
            name=&#39;binary_accuracy&#39;, threshold=threshold),
        BinaryEfficiency(name=&#39;gluon_efficiency&#39;,
                         label_id=0, threshold=threshold),
        BinaryEfficiency(name=&#39;quark_efficiency&#39;,
                         label_id=1, threshold=threshold),
        BinaryRejection(name=&#39;gluon_rejection&#39;,
                        label_id=0, threshold=threshold),
        BinaryRejection(name=&#39;quark_rejection&#39;,
                        label_id=1, threshold=threshold),
        EfficiencyAtFixedWorkingPoint(name=&#39;gluon_efficiency_at_quark_50wp&#39;,
                                      fixed_label_id=1, working_point=0.5, returned_label_id=0),
        EfficiencyAtFixedWorkingPoint(name=&#39;quark_efficiency_at_quark_50wp&#39;,
                                      fixed_label_id=1, working_point=0.5, returned_label_id=1),
        RejectionAtFixedWorkingPoint(name=&#39;gluon_rejection_at_quark_50wp&#39;,
                                     fixed_label_id=1, working_point=0.5, returned_label_id=0),
        ThresholdAtFixedWorkingPoint(name=&#39;threshold_at_fixed_quark_50wp&#39;,
                                     fixed_label_id=1, working_point=0.5),
        EfficiencyAtFixedWorkingPoint(name=&#39;gluon_efficiency_at_quark_80wp&#39;,
                                      fixed_label_id=1, working_point=0.8, returned_label_id=0),
        EfficiencyAtFixedWorkingPoint(name=&#39;quark_efficiency_at_quark_80wp&#39;,
                                      fixed_label_id=1, working_point=0.8, returned_label_id=1),
        RejectionAtFixedWorkingPoint(name=&#39;gluon_rejection_at_quark_80wp&#39;,
                                     fixed_label_id=1, working_point=0.8, returned_label_id=0),
        ThresholdAtFixedWorkingPoint(name=&#39;threshold_at_fixed_quark_80wp&#39;,
                                     fixed_label_id=1, working_point=0.8),
        EffectiveTaggingEfficiency(
            name=&#39;effective_tagging_efficiency&#39;, threshold=threshold),
        tf.keras.metrics.AUC(name=&#39;auc&#39;)]
    return metrics</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="jidenn.evaluation.evaluation_metrics.BinaryEfficiency"><code class="flex name class">
<span>class <span class="ident">BinaryEfficiency</span></span>
<span>(</span><span>label_id: Literal[0, 1] = 1, threshold=0.5, name='efficiency')</span>
</code></dt>
<dd>
<div class="desc"><p>Binary Efficiency metric.
It is defined as
<span><span class="MathJax_Preview">\varepsilon_i=\frac{T_i}{T_i+F_i}</span><script type="math/tex; mode=display">\varepsilon_i=\frac{T_i}{T_i+F_i}</script></span>
where $T_i$ is the number of correctly classified data of class $i$
and $F_i$ is the number of incorrectly classified data of class $i$.</p>
<p>If $i = 1$, then it is the efficiency is called true positive rate (TPR).</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>label_id</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>The label id for which the efficiency is calculated. Defaults to 1.</dd>
<dt><strong><code>threshold</code></strong> :&ensp;<code>float</code>, optional</dt>
<dd>The threshold for the prediction. Defaults to 0.5.</dd>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>The name of the metric. Defaults to 'efficiency'.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class BinaryEfficiency(tf.keras.metrics.Metric):
    r&#34;&#34;&#34;Binary Efficiency metric.
    It is defined as
    $$\varepsilon_i=\frac{T_i}{T_i+F_i}$$
    where $T_i$ is the number of correctly classified data of class $i$ 
    and $F_i$ is the number of incorrectly classified data of class $i$.

    If $i = 1$, then it is the efficiency is called true positive rate (TPR).

    Args:
        label_id (int, optional): The label id for which the efficiency is calculated. Defaults to 1.
        threshold (float, optional): The threshold for the prediction. Defaults to 0.5.
        name (str, optional): The name of the metric. Defaults to &#39;efficiency&#39;.
    &#34;&#34;&#34;

    def __init__(self, label_id: Literal[0, 1] = 1, threshold=0.5, name=&#39;efficiency&#39;):
        super(BinaryEfficiency, self).__init__(name=name)
        self.tp = self.add_weight(name=&#39;tp&#39;, initializer=&#39;zeros&#39;)
        self.total = self.add_weight(name=&#39;total&#39;, initializer=&#39;zeros&#39;)
        self.label_id = label_id
        self.threshold = threshold

    def update_state(self, y_true: Union[tf.Tensor, np.ndarray], y_pred: Union[tf.Tensor, np.ndarray], sample_weight: Union[tf.Tensor, np.ndarray] = None):
        &#34;&#34;&#34;Accumulates the efficiency.

        Args:
            y_true (tf.Tensor): The true labels.
            y_pred (tf.Tensor): The predicted labels.
            sample_weight (tf.Tensor, optional): The sample weights. Defaults to None.
        &#34;&#34;&#34;
        y_pred = tf.cast(y_pred &gt; self.threshold, tf.bool)
        y_true = tf.cast(y_true, tf.bool)
        if self.label_id is not None and self.label_id != 1:
            y_true = tf.logical_not(y_true)
            y_pred = tf.logical_not(y_pred)

        values = tf.logical_and(tf.equal(y_true, True), tf.equal(y_pred, True))
        values = tf.cast(values, self.dtype)
        if sample_weight is not None:
            sample_weight = tf.cast(sample_weight, self.dtype)
            sample_weight = tf.broadcast_weights(sample_weight, values)
            values = tf.multiply(values, sample_weight)

        self.tp.assign_add(tf.reduce_sum(values))
        self.total.assign_add(tf.reduce_sum(tf.cast(y_true, self.dtype)))

    def result(self):
        return self.tp / self.total

    def reset_state(self):
        self.tp.assign(0.)
        self.total.assign(0.)

    def get_config(self):
        config = super(BinaryEfficiency, self).get_config()
        config.update({&#39;threshold&#39;: self.threshold, &#39;label_id&#39;: self.label_id})
        return config</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>keras.metrics.base_metric.Metric</li>
<li>keras.engine.base_layer.Layer</li>
<li>tensorflow.python.module.module.Module</li>
<li>tensorflow.python.trackable.autotrackable.AutoTrackable</li>
<li>tensorflow.python.trackable.base.Trackable</li>
<li>keras.utils.version_utils.LayerVersionSelector</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="jidenn.evaluation.evaluation_metrics.BinaryEfficiency.get_config"><code class="name flex">
<span>def <span class="ident">get_config</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns the serializable config of the metric.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_config(self):
    config = super(BinaryEfficiency, self).get_config()
    config.update({&#39;threshold&#39;: self.threshold, &#39;label_id&#39;: self.label_id})
    return config</code></pre>
</details>
</dd>
<dt id="jidenn.evaluation.evaluation_metrics.BinaryEfficiency.reset_state"><code class="name flex">
<span>def <span class="ident">reset_state</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Resets all of the metric state variables.</p>
<p>This function is called between epochs/steps,
when a metric is evaluated during training.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def reset_state(self):
    self.tp.assign(0.)
    self.total.assign(0.)</code></pre>
</details>
</dd>
<dt id="jidenn.evaluation.evaluation_metrics.BinaryEfficiency.result"><code class="name flex">
<span>def <span class="ident">result</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Computes and returns the scalar metric value tensor or a dict of
scalars.</p>
<p>Result computation is an idempotent operation that simply calculates the
metric value using the state variables.</p>
<h2 id="returns">Returns</h2>
<p>A scalar tensor, or a dictionary of scalar tensors.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def result(self):
    return self.tp / self.total</code></pre>
</details>
</dd>
<dt id="jidenn.evaluation.evaluation_metrics.BinaryEfficiency.update_state"><code class="name flex">
<span>def <span class="ident">update_state</span></span>(<span>self, y_true: Union[tensorflow.python.framework.ops.Tensor, numpy.ndarray], y_pred: Union[tensorflow.python.framework.ops.Tensor, numpy.ndarray], sample_weight: Union[tensorflow.python.framework.ops.Tensor, numpy.ndarray] = None)</span>
</code></dt>
<dd>
<div class="desc"><p>Accumulates the efficiency.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>y_true</code></strong> :&ensp;<code>tf.Tensor</code></dt>
<dd>The true labels.</dd>
<dt><strong><code>y_pred</code></strong> :&ensp;<code>tf.Tensor</code></dt>
<dd>The predicted labels.</dd>
<dt><strong><code>sample_weight</code></strong> :&ensp;<code>tf.Tensor</code>, optional</dt>
<dd>The sample weights. Defaults to None.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def update_state(self, y_true: Union[tf.Tensor, np.ndarray], y_pred: Union[tf.Tensor, np.ndarray], sample_weight: Union[tf.Tensor, np.ndarray] = None):
    &#34;&#34;&#34;Accumulates the efficiency.

    Args:
        y_true (tf.Tensor): The true labels.
        y_pred (tf.Tensor): The predicted labels.
        sample_weight (tf.Tensor, optional): The sample weights. Defaults to None.
    &#34;&#34;&#34;
    y_pred = tf.cast(y_pred &gt; self.threshold, tf.bool)
    y_true = tf.cast(y_true, tf.bool)
    if self.label_id is not None and self.label_id != 1:
        y_true = tf.logical_not(y_true)
        y_pred = tf.logical_not(y_pred)

    values = tf.logical_and(tf.equal(y_true, True), tf.equal(y_pred, True))
    values = tf.cast(values, self.dtype)
    if sample_weight is not None:
        sample_weight = tf.cast(sample_weight, self.dtype)
        sample_weight = tf.broadcast_weights(sample_weight, values)
        values = tf.multiply(values, sample_weight)

    self.tp.assign_add(tf.reduce_sum(values))
    self.total.assign_add(tf.reduce_sum(tf.cast(y_true, self.dtype)))</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="jidenn.evaluation.evaluation_metrics.BinaryRejection"><code class="flex name class">
<span>class <span class="ident">BinaryRejection</span></span>
<span>(</span><span>label_id: Literal[0, 1] = 1, threshold=0.5, name='rejection')</span>
</code></dt>
<dd>
<div class="desc"><p>Binary Rejection metric.
It is defined as
<span><span class="MathJax_Preview">\varepsilon_i^{-1}=\frac{T_i+F_i}{T_i}</span><script type="math/tex; mode=display">\varepsilon_i^{-1}=\frac{T_i+F_i}{T_i}</script></span>
where $T_i$ is the number of correctly classified data of class $i$
and $F_i$ is the number of incorrectly classified data of class $i$.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>label_id</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>The label id for which the efficiency is calculated. Defaults to 1.</dd>
<dt><strong><code>threshold</code></strong> :&ensp;<code>float</code>, optional</dt>
<dd>The threshold for the prediction. Defaults to 0.5.</dd>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>The name of the metric. Defaults to 'rejection'.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class BinaryRejection(tf.keras.metrics.Metric):
    r&#34;&#34;&#34;Binary Rejection metric.
    It is defined as
    $$\varepsilon_i^{-1}=\frac{T_i+F_i}{T_i}$$
    where $T_i$ is the number of correctly classified data of class $i$ 
    and $F_i$ is the number of incorrectly classified data of class $i$.

    Args:
        label_id (int, optional): The label id for which the efficiency is calculated. Defaults to 1.
        threshold (float, optional): The threshold for the prediction. Defaults to 0.5.
        name (str, optional): The name of the metric. Defaults to &#39;rejection&#39;.
    &#34;&#34;&#34;

    def __init__(self, label_id: Literal[0, 1] = 1, threshold=0.5, name=&#39;rejection&#39;):
        super(BinaryRejection, self).__init__(name=name)
        self.tp = self.add_weight(name=&#39;tp&#39;, initializer=&#39;zeros&#39;)
        self.total = self.add_weight(name=&#39;total&#39;, initializer=&#39;zeros&#39;)
        self.label_id = label_id
        self.threshold = threshold

    def update_state(self, y_true: Union[tf.Tensor, np.ndarray], y_pred: Union[tf.Tensor, np.ndarray], sample_weight: Union[tf.Tensor, np.ndarray] = None):
        &#34;&#34;&#34;Accumulates the efficiency.

        Args:
            y_true (tf.Tensor): The true labels.
            y_pred (tf.Tensor): The predicted labels.
            sample_weight (tf.Tensor, optional): The sample weights. Defaults to None.
        &#34;&#34;&#34;
        y_pred = tf.cast(y_pred &gt; self.threshold, tf.bool)
        y_true = tf.cast(y_true, tf.bool)
        if self.label_id is not None and self.label_id != 1:
            y_true = tf.logical_not(y_true)
            y_pred = tf.logical_not(y_pred)

        values = tf.logical_and(tf.equal(y_true, True), tf.equal(y_pred, True))
        values = tf.cast(values, self.dtype)
        if sample_weight is not None:
            sample_weight = tf.cast(sample_weight, self.dtype)
            sample_weight = tf.broadcast_weights(sample_weight, values)
            values = tf.multiply(values, sample_weight)
        self.tp.assign_add(tf.reduce_sum(values))
        self.total.assign_add(tf.reduce_sum(tf.cast(y_true, self.dtype)))

    def result(self):
        tpr = self.tp / self.total
        return 1.0 / (1 - tpr)

    def reset_state(self):
        self.tp.assign(0.)
        self.total.assign(0.)

    def get_config(self):
        config = super(BinaryRejection, self).get_config()
        config.update({&#39;threshold&#39;: self.threshold, &#39;label_id&#39;: self.label_id})
        return config</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>keras.metrics.base_metric.Metric</li>
<li>keras.engine.base_layer.Layer</li>
<li>tensorflow.python.module.module.Module</li>
<li>tensorflow.python.trackable.autotrackable.AutoTrackable</li>
<li>tensorflow.python.trackable.base.Trackable</li>
<li>keras.utils.version_utils.LayerVersionSelector</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="jidenn.evaluation.evaluation_metrics.BinaryRejection.get_config"><code class="name flex">
<span>def <span class="ident">get_config</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns the serializable config of the metric.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_config(self):
    config = super(BinaryRejection, self).get_config()
    config.update({&#39;threshold&#39;: self.threshold, &#39;label_id&#39;: self.label_id})
    return config</code></pre>
</details>
</dd>
<dt id="jidenn.evaluation.evaluation_metrics.BinaryRejection.reset_state"><code class="name flex">
<span>def <span class="ident">reset_state</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Resets all of the metric state variables.</p>
<p>This function is called between epochs/steps,
when a metric is evaluated during training.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def reset_state(self):
    self.tp.assign(0.)
    self.total.assign(0.)</code></pre>
</details>
</dd>
<dt id="jidenn.evaluation.evaluation_metrics.BinaryRejection.result"><code class="name flex">
<span>def <span class="ident">result</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Computes and returns the scalar metric value tensor or a dict of
scalars.</p>
<p>Result computation is an idempotent operation that simply calculates the
metric value using the state variables.</p>
<h2 id="returns">Returns</h2>
<p>A scalar tensor, or a dictionary of scalar tensors.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def result(self):
    tpr = self.tp / self.total
    return 1.0 / (1 - tpr)</code></pre>
</details>
</dd>
<dt id="jidenn.evaluation.evaluation_metrics.BinaryRejection.update_state"><code class="name flex">
<span>def <span class="ident">update_state</span></span>(<span>self, y_true: Union[tensorflow.python.framework.ops.Tensor, numpy.ndarray], y_pred: Union[tensorflow.python.framework.ops.Tensor, numpy.ndarray], sample_weight: Union[tensorflow.python.framework.ops.Tensor, numpy.ndarray] = None)</span>
</code></dt>
<dd>
<div class="desc"><p>Accumulates the efficiency.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>y_true</code></strong> :&ensp;<code>tf.Tensor</code></dt>
<dd>The true labels.</dd>
<dt><strong><code>y_pred</code></strong> :&ensp;<code>tf.Tensor</code></dt>
<dd>The predicted labels.</dd>
<dt><strong><code>sample_weight</code></strong> :&ensp;<code>tf.Tensor</code>, optional</dt>
<dd>The sample weights. Defaults to None.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def update_state(self, y_true: Union[tf.Tensor, np.ndarray], y_pred: Union[tf.Tensor, np.ndarray], sample_weight: Union[tf.Tensor, np.ndarray] = None):
    &#34;&#34;&#34;Accumulates the efficiency.

    Args:
        y_true (tf.Tensor): The true labels.
        y_pred (tf.Tensor): The predicted labels.
        sample_weight (tf.Tensor, optional): The sample weights. Defaults to None.
    &#34;&#34;&#34;
    y_pred = tf.cast(y_pred &gt; self.threshold, tf.bool)
    y_true = tf.cast(y_true, tf.bool)
    if self.label_id is not None and self.label_id != 1:
        y_true = tf.logical_not(y_true)
        y_pred = tf.logical_not(y_pred)

    values = tf.logical_and(tf.equal(y_true, True), tf.equal(y_pred, True))
    values = tf.cast(values, self.dtype)
    if sample_weight is not None:
        sample_weight = tf.cast(sample_weight, self.dtype)
        sample_weight = tf.broadcast_weights(sample_weight, values)
        values = tf.multiply(values, sample_weight)
    self.tp.assign_add(tf.reduce_sum(values))
    self.total.assign_add(tf.reduce_sum(tf.cast(y_true, self.dtype)))</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="jidenn.evaluation.evaluation_metrics.EffectiveTaggingEfficiency"><code class="flex name class">
<span>class <span class="ident">EffectiveTaggingEfficiency</span></span>
<span>(</span><span>bins: List[float] = [0, 0.1, 0.25, 0.5, 0.625, 0.75, 0.875, 1], threshold: float = 0.5, name='eff_tag_efficiency', **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Encapsulates metric logic and state.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>name</code></strong></dt>
<dd>(Optional) string name of the metric instance.</dd>
<dt><strong><code>dtype</code></strong></dt>
<dd>(Optional) data type of the metric result.</dd>
<dt><strong><code>**kwargs</code></strong></dt>
<dd>Additional layer keywords arguments.</dd>
</dl>
<p>Standalone usage:</p>
<pre><code class="language-python">m = SomeMetric(...)
for input in ...:
  m.update_state(input)
print('Final result: ', m.result().numpy())
</code></pre>
<p>Usage with <code>compile()</code> API:</p>
<pre><code class="language-python">model = tf.keras.Sequential()
model.add(tf.keras.layers.Dense(64, activation='relu'))
model.add(tf.keras.layers.Dense(64, activation='relu'))
model.add(tf.keras.layers.Dense(10, activation='softmax'))

model.compile(optimizer=tf.keras.optimizers.RMSprop(0.01),
              loss=tf.keras.losses.CategoricalCrossentropy(),
              metrics=[tf.keras.metrics.CategoricalAccuracy()])

data = np.random.random((1000, 32))
labels = np.random.random((1000, 10))

dataset = tf.data.Dataset.from_tensor_slices((data, labels))
dataset = dataset.batch(32)

model.fit(dataset, epochs=10)
</code></pre>
<p>To be implemented by subclasses:
* <code>__init__()</code>: All state variables should be created in this method by
calling <code>self.add_weight()</code> like: <code>self.var = self.add_weight(...)</code>
* <code>update_state()</code>: Has all updates to the state variables like:
self.var.assign_add(&hellip;).
* <code>result()</code>: Computes and returns a scalar value or a dict of scalar values
for the metric from the state variables.</p>
<p>Example subclass implementation:</p>
<pre><code class="language-python">class BinaryTruePositives(tf.keras.metrics.Metric):

  def __init__(self, name='binary_true_positives', **kwargs):
    super(BinaryTruePositives, self).__init__(name=name, **kwargs)
    self.true_positives = self.add_weight(name='tp', initializer='zeros')

  def update_state(self, y_true, y_pred, sample_weight=None):
    y_true = tf.cast(y_true, tf.bool)
    y_pred = tf.cast(y_pred, tf.bool)

    values = tf.logical_and(tf.equal(y_true, True), tf.equal(y_pred, True))
    values = tf.cast(values, self.dtype)
    if sample_weight is not None:
      sample_weight = tf.cast(sample_weight, self.dtype)
      sample_weight = tf.broadcast_to(sample_weight, values.shape)
      values = tf.multiply(values, sample_weight)
    self.true_positives.assign_add(tf.reduce_sum(values))

  def result(self):
    return self.true_positives
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class EffectiveTaggingEfficiency(tf.keras.metrics.Metric):

    def __init__(self, bins: List[float] = [0, 0.1, 0.25, 0.5, 0.625, 0.75, 0.875, 1], threshold: float = 0.5, name=&#39;eff_tag_efficiency&#39;, **kwargs):
        super(EffectiveTaggingEfficiency, self).__init__(name=name, **kwargs)
        for value in bins:
            if value &lt; 0 or value &gt; 1:
                raise ValueError(&#39;The bins must be between 0 and 1.&#39;)
        self.bins = bins
        self.threshold = threshold
        self.bin_sums = self.add_weight(
            name=&#39;bin_sums&#39;, initializer=&#39;zeros&#39;, shape=(len(bins) - 1,))
        self.bin_counts = self.add_weight(
            name=&#39;bin_counts&#39;, initializer=&#39;zeros&#39;, shape=(len(bins) - 1,))

    def update_state(self, y_true: Union[tf.Tensor, np.ndarray], score: Union[tf.Tensor, np.ndarray], sample_weight: Union[tf.Tensor, np.ndarray] = None):
        &#34;&#34;&#34;Accumulates the metric.

        Args:
            y_true (Union[tf.Tensor, np.ndarray]): The true labels.
            score (Union[tf.Tensor, np.ndarray]): The output of the model, i.e. number **between 0 and 1**.
        &#34;&#34;&#34;
        score = tf.squeeze(score)
        y_true = tf.squeeze(y_true)
        dilusion_factor = tf.abs(2 * score - 1)
        indicies = tf.searchsorted(self.bins, dilusion_factor)
        pred = tf.cast(score &gt; 0.5, tf.bool)
        wrong_tag = tf.cast(tf.not_equal(
            pred, tf.cast(y_true, tf.bool)), tf.float32)

        bin_counts = tf.cast(tf.math.bincount(
            indicies, minlength=len(self.bins)), tf.float32)
        bin_counts = bin_counts[1:]
        bin_sums = tf.math.bincount(
            indicies, weights=wrong_tag, minlength=len(self.bins))
        bin_sums = bin_sums[1:]
        self.bin_counts.assign_add(bin_counts)
        self.bin_sums.assign_add(bin_sums)

    def get_config(self):
        config = super(EffectiveTaggingEfficiency, self).get_config()
        config.update({&#39;bins&#39;: self.bins, &#39;threshold&#39;: self.threshold})
        return config

    def result(self):
        mask = tf.where(self.bin_counts &gt; 0, True, False)
        bin_counts = tf.boolean_mask(self.bin_counts, mask)
        bin_sums = tf.boolean_mask(self.bin_sums, mask)
        binned_wrong_tag_fraction = bin_sums / bin_counts
        eff = bin_counts / tf.reduce_sum(bin_counts)
        eff_tag_eff = tf.reduce_sum(
            eff * (1 - 2 * binned_wrong_tag_fraction)**2)
        return eff_tag_eff

    def reset_state(self):
        self.bin_sums.assign(tf.zeros_like(self.bin_sums))
        self.bin_counts.assign(tf.zeros_like(self.bin_counts))</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>keras.metrics.base_metric.Metric</li>
<li>keras.engine.base_layer.Layer</li>
<li>tensorflow.python.module.module.Module</li>
<li>tensorflow.python.trackable.autotrackable.AutoTrackable</li>
<li>tensorflow.python.trackable.base.Trackable</li>
<li>keras.utils.version_utils.LayerVersionSelector</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="jidenn.evaluation.evaluation_metrics.EffectiveTaggingEfficiency.get_config"><code class="name flex">
<span>def <span class="ident">get_config</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns the serializable config of the metric.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_config(self):
    config = super(EffectiveTaggingEfficiency, self).get_config()
    config.update({&#39;bins&#39;: self.bins, &#39;threshold&#39;: self.threshold})
    return config</code></pre>
</details>
</dd>
<dt id="jidenn.evaluation.evaluation_metrics.EffectiveTaggingEfficiency.reset_state"><code class="name flex">
<span>def <span class="ident">reset_state</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Resets all of the metric state variables.</p>
<p>This function is called between epochs/steps,
when a metric is evaluated during training.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def reset_state(self):
    self.bin_sums.assign(tf.zeros_like(self.bin_sums))
    self.bin_counts.assign(tf.zeros_like(self.bin_counts))</code></pre>
</details>
</dd>
<dt id="jidenn.evaluation.evaluation_metrics.EffectiveTaggingEfficiency.result"><code class="name flex">
<span>def <span class="ident">result</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Computes and returns the scalar metric value tensor or a dict of
scalars.</p>
<p>Result computation is an idempotent operation that simply calculates the
metric value using the state variables.</p>
<h2 id="returns">Returns</h2>
<p>A scalar tensor, or a dictionary of scalar tensors.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def result(self):
    mask = tf.where(self.bin_counts &gt; 0, True, False)
    bin_counts = tf.boolean_mask(self.bin_counts, mask)
    bin_sums = tf.boolean_mask(self.bin_sums, mask)
    binned_wrong_tag_fraction = bin_sums / bin_counts
    eff = bin_counts / tf.reduce_sum(bin_counts)
    eff_tag_eff = tf.reduce_sum(
        eff * (1 - 2 * binned_wrong_tag_fraction)**2)
    return eff_tag_eff</code></pre>
</details>
</dd>
<dt id="jidenn.evaluation.evaluation_metrics.EffectiveTaggingEfficiency.update_state"><code class="name flex">
<span>def <span class="ident">update_state</span></span>(<span>self, y_true: Union[tensorflow.python.framework.ops.Tensor, numpy.ndarray], score: Union[tensorflow.python.framework.ops.Tensor, numpy.ndarray], sample_weight: Union[tensorflow.python.framework.ops.Tensor, numpy.ndarray] = None)</span>
</code></dt>
<dd>
<div class="desc"><p>Accumulates the metric.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>y_true</code></strong> :&ensp;<code>Union[tf.Tensor, np.ndarray]</code></dt>
<dd>The true labels.</dd>
<dt><strong><code>score</code></strong> :&ensp;<code>Union[tf.Tensor, np.ndarray]</code></dt>
<dd>The output of the model, i.e. number <strong>between 0 and 1</strong>.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def update_state(self, y_true: Union[tf.Tensor, np.ndarray], score: Union[tf.Tensor, np.ndarray], sample_weight: Union[tf.Tensor, np.ndarray] = None):
    &#34;&#34;&#34;Accumulates the metric.

    Args:
        y_true (Union[tf.Tensor, np.ndarray]): The true labels.
        score (Union[tf.Tensor, np.ndarray]): The output of the model, i.e. number **between 0 and 1**.
    &#34;&#34;&#34;
    score = tf.squeeze(score)
    y_true = tf.squeeze(y_true)
    dilusion_factor = tf.abs(2 * score - 1)
    indicies = tf.searchsorted(self.bins, dilusion_factor)
    pred = tf.cast(score &gt; 0.5, tf.bool)
    wrong_tag = tf.cast(tf.not_equal(
        pred, tf.cast(y_true, tf.bool)), tf.float32)

    bin_counts = tf.cast(tf.math.bincount(
        indicies, minlength=len(self.bins)), tf.float32)
    bin_counts = bin_counts[1:]
    bin_sums = tf.math.bincount(
        indicies, weights=wrong_tag, minlength=len(self.bins))
    bin_sums = bin_sums[1:]
    self.bin_counts.assign_add(bin_counts)
    self.bin_sums.assign_add(bin_sums)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="jidenn.evaluation.evaluation_metrics.EfficiencyAtFixedWorkingPoint"><code class="flex name class">
<span>class <span class="ident">EfficiencyAtFixedWorkingPoint</span></span>
<span>(</span><span>working_point: float = 0.5, fixed_label_id: Literal[0, 1] = 1, returned_label_id: Literal[0, 1] = 0, num_thresholds: int = 200, name: Optional[str] = 'efficiency_at_fixed_wp', dtype: Optional[tensorflow.python.framework.dtypes.DType] = None)</span>
</code></dt>
<dd>
<div class="desc"><p>Calculates the efficiency at a fixed working point. The working point is defined by the user.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>working_point</code></strong> :&ensp;<code>float</code></dt>
<dd>The working point. Defaults to 0.5.</dd>
<dt><strong><code>fixed_label_id</code></strong> :&ensp;<code>Literal[0, 1]</code>, optional</dt>
<dd>The label id whose efficiency is fixed. Defaults to 1.</dd>
<dt><strong><code>returned_label_id</code></strong> :&ensp;<code>Literal[0, 1]</code>, optional</dt>
<dd>The label id whose efficiency is returned. Defaults to 0.</dd>
<dt><strong><code>num_thresholds</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>The number of thresholds to use for the estimation. Defaults to 200.</dd>
<dt><strong><code>name</code></strong> :&ensp;<code>Optional[str]</code>, optional</dt>
<dd>The name of the metric. Defaults to 'efficiency_at_fixed_wp'.</dd>
<dt><strong><code>dtype</code></strong> :&ensp;<code>Optional[tf.dtypes.DType]</code>, optional</dt>
<dd>The data type of the metric. Defaults to None.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class EfficiencyAtFixedWorkingPoint(FixedWorkingPointBase):
    &#34;&#34;&#34;Calculates the efficiency at a fixed working point. The working point is defined by the user.

    Args:
        working_point (float): The working point. Defaults to 0.5.
        fixed_label_id (Literal[0, 1], optional): The label id whose efficiency is fixed. Defaults to 1.
        returned_label_id (Literal[0, 1], optional): The label id whose efficiency is returned. Defaults to 0.
        num_thresholds (int, optional): The number of thresholds to use for the estimation. Defaults to 200.
        name (Optional[str], optional): The name of the metric. Defaults to &#39;efficiency_at_fixed_wp&#39;.
        dtype (Optional[tf.dtypes.DType], optional): The data type of the metric. Defaults to None.
    &#34;&#34;&#34;

    def __init__(self, working_point: float = 0.5, fixed_label_id: Literal[0, 1] = 1, returned_label_id: Literal[0, 1] = 0,
                 num_thresholds: int = 200, name: Optional[str] = &#39;efficiency_at_fixed_wp&#39;, dtype: Optional[tf.dtypes.DType] = None):

        super().__init__(working_point=working_point, num_thresholds=num_thresholds, name=name, dtype=dtype)
        self.fixed_label_id = fixed_label_id
        self.returned_label_id = returned_label_id

    def result(self) -&gt; tf.Tensor:
        &#34;&#34;&#34;Calculates the efficiency at the working point.

        Raises:
            ValueError: If the fixed_label_id is not 0 or 1.

        Returns:
            tf.Tensor: The efficiency at the working point.
        &#34;&#34;&#34;
        efficiency_positivess = self.true_positives / self.total_positives
        efficiency_negatives = self.false_negatives / self.total_negatives

        if self.fixed_label_id == 1:
            fixed_efficiency = efficiency_positivess
        elif self.fixed_label_id == 0:
            fixed_efficiency = efficiency_negatives
        else:
            raise ValueError(f&#39;fixed_label_id must be 0 or 1, but is {self.fixed_label_id}&#39;)

        closest_index = self._find_index_of_threshold(fixed_efficiency, self.working_point)

        if self.returned_label_id == 1:
            efficiency_at_wp = tf.gather(efficiency_positivess, closest_index)
        elif self.returned_label_id == 0:
            efficiency_at_wp = tf.gather(efficiency_negatives, closest_index)

        return efficiency_at_wp</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="jidenn.evaluation.evaluation_metrics.FixedWorkingPointBase" href="#jidenn.evaluation.evaluation_metrics.FixedWorkingPointBase">FixedWorkingPointBase</a></li>
<li>keras.metrics.base_metric.Metric</li>
<li>keras.engine.base_layer.Layer</li>
<li>tensorflow.python.module.module.Module</li>
<li>tensorflow.python.trackable.autotrackable.AutoTrackable</li>
<li>tensorflow.python.trackable.base.Trackable</li>
<li>keras.utils.version_utils.LayerVersionSelector</li>
</ul>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="jidenn.evaluation.evaluation_metrics.RejectionAtFixedWorkingPoint" href="#jidenn.evaluation.evaluation_metrics.RejectionAtFixedWorkingPoint">RejectionAtFixedWorkingPoint</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="jidenn.evaluation.evaluation_metrics.EfficiencyAtFixedWorkingPoint.reset_state"><code class="name flex">
<span>def <span class="ident">reset_state</span></span>(<span>self)</span>
</code></dt>
<dd>
<p class="inheritance">
<em>Inherited from:</em>
<code><a title="jidenn.evaluation.evaluation_metrics.FixedWorkingPointBase" href="#jidenn.evaluation.evaluation_metrics.FixedWorkingPointBase">FixedWorkingPointBase</a></code>.<code><a title="jidenn.evaluation.evaluation_metrics.FixedWorkingPointBase.reset_state" href="#jidenn.evaluation.evaluation_metrics.FixedWorkingPointBase.reset_state">reset_state</a></code>
</p>
<div class="desc inherited"><p>Resets the confusion matrix statistics.</p></div>
</dd>
<dt id="jidenn.evaluation.evaluation_metrics.EfficiencyAtFixedWorkingPoint.result"><code class="name flex">
<span>def <span class="ident">result</span></span>(<span>self) ‑> tensorflow.python.framework.ops.Tensor</span>
</code></dt>
<dd>
<div class="desc"><p>Calculates the efficiency at the working point.</p>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>ValueError</code></dt>
<dd>If the fixed_label_id is not 0 or 1.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>tf.Tensor</code></dt>
<dd>The efficiency at the working point.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def result(self) -&gt; tf.Tensor:
    &#34;&#34;&#34;Calculates the efficiency at the working point.

    Raises:
        ValueError: If the fixed_label_id is not 0 or 1.

    Returns:
        tf.Tensor: The efficiency at the working point.
    &#34;&#34;&#34;
    efficiency_positivess = self.true_positives / self.total_positives
    efficiency_negatives = self.false_negatives / self.total_negatives

    if self.fixed_label_id == 1:
        fixed_efficiency = efficiency_positivess
    elif self.fixed_label_id == 0:
        fixed_efficiency = efficiency_negatives
    else:
        raise ValueError(f&#39;fixed_label_id must be 0 or 1, but is {self.fixed_label_id}&#39;)

    closest_index = self._find_index_of_threshold(fixed_efficiency, self.working_point)

    if self.returned_label_id == 1:
        efficiency_at_wp = tf.gather(efficiency_positivess, closest_index)
    elif self.returned_label_id == 0:
        efficiency_at_wp = tf.gather(efficiency_negatives, closest_index)

    return efficiency_at_wp</code></pre>
</details>
</dd>
<dt id="jidenn.evaluation.evaluation_metrics.EfficiencyAtFixedWorkingPoint.update_state"><code class="name flex">
<span>def <span class="ident">update_state</span></span>(<span>self, y_true: Union[tensorflow.python.framework.ops.Tensor, numpy.ndarray], y_pred: Union[tensorflow.python.framework.ops.Tensor, numpy.ndarray], sample_weight: Union[tensorflow.python.framework.ops.Tensor, numpy.ndarray, ForwardRef(None)] = None)</span>
</code></dt>
<dd>
<p class="inheritance">
<em>Inherited from:</em>
<code><a title="jidenn.evaluation.evaluation_metrics.FixedWorkingPointBase" href="#jidenn.evaluation.evaluation_metrics.FixedWorkingPointBase">FixedWorkingPointBase</a></code>.<code><a title="jidenn.evaluation.evaluation_metrics.FixedWorkingPointBase.update_state" href="#jidenn.evaluation.evaluation_metrics.FixedWorkingPointBase.update_state">update_state</a></code>
</p>
<div class="desc inherited"><p>Accumulates the confusion matrix statistics. The true positives and false negatives are calculated for each threshold.
The total positives and total …</p></div>
</dd>
</dl>
</dd>
<dt id="jidenn.evaluation.evaluation_metrics.FixedWorkingPointBase"><code class="flex name class">
<span>class <span class="ident">FixedWorkingPointBase</span></span>
<span>(</span><span>working_point: float = 0.5, num_thresholds: int = 200, name: Optional[str] = None, dtype: Optional[tensorflow.python.framework.dtypes.DType] = None)</span>
</code></dt>
<dd>
<div class="desc"><p>Base class for metrics that calculate the efficiencies and threshold at a fixed working point,
i.e. one fixed efficiency with variables threshold.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>working_point</code></strong> :&ensp;<code>float</code></dt>
<dd>The working point, i.e. the efficiency at which the threshold is calculated.</dd>
<dt><strong><code>num_thresholds</code></strong> :&ensp;<code>int</code></dt>
<dd>The number of thresholds to calculate for finding the threshold at the working point.</dd>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code></dt>
<dd>The name of the metric. </dd>
<dt><strong><code>dtype</code></strong> :&ensp;<code>tf.dtypes.DType</code></dt>
<dd>The data type of the metric.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class FixedWorkingPointBase(tf.keras.metrics.Metric):
    r&#34;&#34;&#34;
    Base class for metrics that calculate the efficiencies and threshold at a fixed working point, 
    i.e. one fixed efficiency with variables threshold.

    Args:
        working_point (float): The working point, i.e. the efficiency at which the threshold is calculated.
        num_thresholds (int): The number of thresholds to calculate for finding the threshold at the working point.
        name (str): The name of the metric. 
        dtype (tf.dtypes.DType): The data type of the metric.       
    &#34;&#34;&#34;

    def __init__(self, working_point: float = 0.5,
                 num_thresholds: int = 200, name: Optional[str] = None,
                 dtype: Optional[tf.dtypes.DType] = None):
        super().__init__(name=name, dtype=dtype)
        self.working_point = working_point
        self.num_thresholds = num_thresholds

        self.true_positives = self.add_weight(name=&#39;true_positives&#39;, initializer=&#39;zeros&#39;, shape=(num_thresholds,))
        self.total_positives = self.add_weight(name=&#39;total_positives&#39;, initializer=&#39;zeros&#39;, shape=(1,))
        self.false_negatives = self.add_weight(name=&#39;false_negatives&#39;, initializer=&#39;zeros&#39;, shape=(num_thresholds,))
        self.total_negatives = self.add_weight(name=&#39;total_negatives&#39;, initializer=&#39;zeros&#39;, shape=(1,))

        thresholds = [
            (i + 1) * 1.0 / (num_thresholds - 1)
            for i in range(num_thresholds - 2)
        ]
        self.thresholds = [0.0] + thresholds + [1.0]

    def update_state(self, y_true: Union[tf.Tensor, np.ndarray], y_pred: Union[tf.Tensor, np.ndarray], sample_weight: Optional[Union[tf.Tensor, np.ndarray]] = None):
        &#34;&#34;&#34;Accumulates the confusion matrix statistics. The true positives and false negatives are calculated for each threshold.
        The total positives and total negatives are calculated once.

        Args:
            y_true (Union[tf.Tensor, np.ndarray]): True labels.
            y_pred (Union[tf.Tensor, np.ndarray]): Predicted scores, i.e. the output of the model.
            sample_weight (Optional[Union[tf.Tensor, np.ndarray]], optional): Sample weights. Defaults to None.
        &#34;&#34;&#34;
        y_pred = tf.cast(tf.expand_dims(y_pred, axis=1) &gt; self.thresholds, tf.bool)
        y_true = tf.expand_dims(y_true, axis=1)
        positive_equals = tf.logical_and(tf.equal(y_true, True), tf.equal(y_pred, True))
        negative_equals = tf.logical_and(tf.equal(y_true, False), tf.equal(y_pred, False))
        if sample_weight is not None:
            sample_weight = tf.cast(sample_weight, tf.float32)
            sample_weight = tf.expand_dims(sample_weight, axis=1)
            positive_equals = tf.multiply(tf.cast(positive_equals, tf.float32), sample_weight)
            negative_equals = tf.multiply(tf.cast(negative_equals, tf.float32), sample_weight)

        self.true_positives.assign_add(tf.reduce_sum(tf.cast(positive_equals, tf.float32), axis=0))
        self.false_negatives.assign_add(tf.reduce_sum(tf.cast(negative_equals, tf.float32), axis=0))

        positives = tf.cast(tf.equal(y_true, True), tf.float32)
        positives = tf.multiply(positives, sample_weight) if sample_weight is not None else positives
        negatives = tf.cast(tf.equal(y_true, False), tf.float32)
        negatives = tf.multiply(negatives, sample_weight) if sample_weight is not None else negatives
        self.total_positives.assign_add(tf.reduce_sum(positives, axis=0))
        self.total_negatives.assign_add(tf.reduce_sum(negatives, axis=0))

    def result(self) -&gt; Tuple[tf.Tensor, tf.Tensor, tf.Tensor]:
        &#34;&#34;&#34;Calculates the efficiencies and threshold at the working point.
        Both the fixed and variable efficiencies are calculated and returned
        to allow a check of the working point.

        Returns:
            Tuple[tf.Tensor, tf.Tensor, tf.Tensor]: The fixed efficiency, the variable efficiency and the threshold at the working point.

        &#34;&#34;&#34;
        efficiency_positivess = self.true_positives / self.total_positives
        efficiency_negatives = self.false_negatives / self.total_negatives

        result_index = self._find_index_of_threshold(efficiency_positivess, self.working_point)
        positive_at_wp = tf.gather(efficiency_positivess, result_index)
        negative_at_wp = tf.gather(efficiency_negatives, result_index)
        threshold_at_wp = tf.gather(self.thresholds, result_index)

        return positive_at_wp, negative_at_wp, threshold_at_wp

    def _find_index_of_threshold(self, efficiencies: tf.Tensor, working_point: float) -&gt; tf.Tensor:
        &#34;&#34;&#34;Finds the index of the threshold at the working point. &#34;&#34;&#34;
        result_index = tf.math.squared_difference(efficiencies, working_point)
        result_index = tf.argmin(result_index, axis=0)
        return result_index

    def reset_state(self):
        &#34;&#34;&#34;Resets the confusion matrix statistics.&#34;&#34;&#34;
        self.true_positives.assign(tf.zeros_like(self.true_positives))
        self.total_positives.assign(tf.zeros_like(self.total_positives))
        self.false_negatives.assign(tf.zeros_like(self.false_negatives))
        self.total_negatives.assign(tf.zeros_like(self.total_negatives))</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>keras.metrics.base_metric.Metric</li>
<li>keras.engine.base_layer.Layer</li>
<li>tensorflow.python.module.module.Module</li>
<li>tensorflow.python.trackable.autotrackable.AutoTrackable</li>
<li>tensorflow.python.trackable.base.Trackable</li>
<li>keras.utils.version_utils.LayerVersionSelector</li>
</ul>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="jidenn.evaluation.evaluation_metrics.EfficiencyAtFixedWorkingPoint" href="#jidenn.evaluation.evaluation_metrics.EfficiencyAtFixedWorkingPoint">EfficiencyAtFixedWorkingPoint</a></li>
<li><a title="jidenn.evaluation.evaluation_metrics.ThresholdAtFixedWorkingPoint" href="#jidenn.evaluation.evaluation_metrics.ThresholdAtFixedWorkingPoint">ThresholdAtFixedWorkingPoint</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="jidenn.evaluation.evaluation_metrics.FixedWorkingPointBase.reset_state"><code class="name flex">
<span>def <span class="ident">reset_state</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Resets the confusion matrix statistics.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def reset_state(self):
    &#34;&#34;&#34;Resets the confusion matrix statistics.&#34;&#34;&#34;
    self.true_positives.assign(tf.zeros_like(self.true_positives))
    self.total_positives.assign(tf.zeros_like(self.total_positives))
    self.false_negatives.assign(tf.zeros_like(self.false_negatives))
    self.total_negatives.assign(tf.zeros_like(self.total_negatives))</code></pre>
</details>
</dd>
<dt id="jidenn.evaluation.evaluation_metrics.FixedWorkingPointBase.result"><code class="name flex">
<span>def <span class="ident">result</span></span>(<span>self) ‑> Tuple[tensorflow.python.framework.ops.Tensor, tensorflow.python.framework.ops.Tensor, tensorflow.python.framework.ops.Tensor]</span>
</code></dt>
<dd>
<div class="desc"><p>Calculates the efficiencies and threshold at the working point.
Both the fixed and variable efficiencies are calculated and returned
to allow a check of the working point.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>Tuple[tf.Tensor, tf.Tensor, tf.Tensor]</code></dt>
<dd>The fixed efficiency, the variable efficiency and the threshold at the working point.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def result(self) -&gt; Tuple[tf.Tensor, tf.Tensor, tf.Tensor]:
    &#34;&#34;&#34;Calculates the efficiencies and threshold at the working point.
    Both the fixed and variable efficiencies are calculated and returned
    to allow a check of the working point.

    Returns:
        Tuple[tf.Tensor, tf.Tensor, tf.Tensor]: The fixed efficiency, the variable efficiency and the threshold at the working point.

    &#34;&#34;&#34;
    efficiency_positivess = self.true_positives / self.total_positives
    efficiency_negatives = self.false_negatives / self.total_negatives

    result_index = self._find_index_of_threshold(efficiency_positivess, self.working_point)
    positive_at_wp = tf.gather(efficiency_positivess, result_index)
    negative_at_wp = tf.gather(efficiency_negatives, result_index)
    threshold_at_wp = tf.gather(self.thresholds, result_index)

    return positive_at_wp, negative_at_wp, threshold_at_wp</code></pre>
</details>
</dd>
<dt id="jidenn.evaluation.evaluation_metrics.FixedWorkingPointBase.update_state"><code class="name flex">
<span>def <span class="ident">update_state</span></span>(<span>self, y_true: Union[tensorflow.python.framework.ops.Tensor, numpy.ndarray], y_pred: Union[tensorflow.python.framework.ops.Tensor, numpy.ndarray], sample_weight: Union[tensorflow.python.framework.ops.Tensor, numpy.ndarray, ForwardRef(None)] = None)</span>
</code></dt>
<dd>
<div class="desc"><p>Accumulates the confusion matrix statistics. The true positives and false negatives are calculated for each threshold.
The total positives and total negatives are calculated once.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>y_true</code></strong> :&ensp;<code>Union[tf.Tensor, np.ndarray]</code></dt>
<dd>True labels.</dd>
<dt><strong><code>y_pred</code></strong> :&ensp;<code>Union[tf.Tensor, np.ndarray]</code></dt>
<dd>Predicted scores, i.e. the output of the model.</dd>
<dt><strong><code>sample_weight</code></strong> :&ensp;<code>Optional[Union[tf.Tensor, np.ndarray]]</code>, optional</dt>
<dd>Sample weights. Defaults to None.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def update_state(self, y_true: Union[tf.Tensor, np.ndarray], y_pred: Union[tf.Tensor, np.ndarray], sample_weight: Optional[Union[tf.Tensor, np.ndarray]] = None):
    &#34;&#34;&#34;Accumulates the confusion matrix statistics. The true positives and false negatives are calculated for each threshold.
    The total positives and total negatives are calculated once.

    Args:
        y_true (Union[tf.Tensor, np.ndarray]): True labels.
        y_pred (Union[tf.Tensor, np.ndarray]): Predicted scores, i.e. the output of the model.
        sample_weight (Optional[Union[tf.Tensor, np.ndarray]], optional): Sample weights. Defaults to None.
    &#34;&#34;&#34;
    y_pred = tf.cast(tf.expand_dims(y_pred, axis=1) &gt; self.thresholds, tf.bool)
    y_true = tf.expand_dims(y_true, axis=1)
    positive_equals = tf.logical_and(tf.equal(y_true, True), tf.equal(y_pred, True))
    negative_equals = tf.logical_and(tf.equal(y_true, False), tf.equal(y_pred, False))
    if sample_weight is not None:
        sample_weight = tf.cast(sample_weight, tf.float32)
        sample_weight = tf.expand_dims(sample_weight, axis=1)
        positive_equals = tf.multiply(tf.cast(positive_equals, tf.float32), sample_weight)
        negative_equals = tf.multiply(tf.cast(negative_equals, tf.float32), sample_weight)

    self.true_positives.assign_add(tf.reduce_sum(tf.cast(positive_equals, tf.float32), axis=0))
    self.false_negatives.assign_add(tf.reduce_sum(tf.cast(negative_equals, tf.float32), axis=0))

    positives = tf.cast(tf.equal(y_true, True), tf.float32)
    positives = tf.multiply(positives, sample_weight) if sample_weight is not None else positives
    negatives = tf.cast(tf.equal(y_true, False), tf.float32)
    negatives = tf.multiply(negatives, sample_weight) if sample_weight is not None else negatives
    self.total_positives.assign_add(tf.reduce_sum(positives, axis=0))
    self.total_negatives.assign_add(tf.reduce_sum(negatives, axis=0))</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="jidenn.evaluation.evaluation_metrics.RejectionAtEfficiency"><code class="flex name class">
<span>class <span class="ident">RejectionAtEfficiency</span></span>
<span>(</span><span>efficiency: float = 0.5, label_id: Literal[0, 1] = 1, name='rejection_at_efficiency')</span>
</code></dt>
<dd>
<div class="desc"><p>Rejection at efficiency metric.
in this case the threshold is chosen such that the efficiency of one class is equal to the given <code>efficiency</code>.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>efficiency</code></strong> :&ensp;<code>float</code>, optional</dt>
<dd>The efficiency. Defaults to 0.5.</dd>
<dt><strong><code>label_id</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>The label id for which the efficiency is calculated. Defaults to 1.</dd>
<dt><strong><code>name</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>The name of the metric. Defaults to 'rejection_at_efficiency'.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class RejectionAtEfficiency(tf.keras.metrics.SpecificityAtSensitivity):
    &#34;&#34;&#34;Rejection at efficiency metric.
    in this case the threshold is chosen such that the efficiency of one class is equal to the given `efficiency`.

    Args:
        efficiency (float, optional): The efficiency. Defaults to 0.5.
        label_id (int, optional): The label id for which the efficiency is calculated. Defaults to 1.
        name (str, optional): The name of the metric. Defaults to &#39;rejection_at_efficiency&#39;.
    &#34;&#34;&#34;

    def __init__(self, efficiency: float = 0.5, label_id: Literal[0, 1] = 1, name=&#39;rejection_at_efficiency&#39;):
        super(RejectionAtEfficiency, self).__init__(
            name=name, sensitivity=efficiency)
        self.label_id = label_id
        self.efficiency = efficiency

    def update_state(self, y_true: Union[tf.Tensor, np.ndarray], y_pred: Union[tf.Tensor, np.ndarray], sample_weight: Union[tf.Tensor, np.ndarray] = None):
        &#34;&#34;&#34;Accumulates the efficiency.

        Args:
            y_true (tf.Tensor): The true labels.
            y_pred (tf.Tensor): The predicted labels.
            sample_weight (tf.Tensor, optional): The sample weights. Defaults to None.
        &#34;&#34;&#34;
        y_true = tf.cast(y_true, tf.bool)
        if self.label_id is not None and self.label_id != 1:
            y_true = tf.logical_not(y_true)
            y_pred = 1 - y_pred
        super(RejectionAtEfficiency, self).update_state(
            y_true, y_pred, sample_weight=sample_weight)

    def get_config(self):
        config = super(RejectionAtEfficiency, self).get_config()
        config.update({&#39;efficiency&#39;: self.efficiency,
                      &#39;label_id&#39;: self.label_id})
        return config

    def result(self):
        return 1 / super(RejectionAtEfficiency, self).result()</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>keras.metrics.metrics.SpecificityAtSensitivity</li>
<li>keras.metrics.metrics.SensitivitySpecificityBase</li>
<li>keras.metrics.base_metric.Metric</li>
<li>keras.engine.base_layer.Layer</li>
<li>tensorflow.python.module.module.Module</li>
<li>tensorflow.python.trackable.autotrackable.AutoTrackable</li>
<li>tensorflow.python.trackable.base.Trackable</li>
<li>keras.utils.version_utils.LayerVersionSelector</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="jidenn.evaluation.evaluation_metrics.RejectionAtEfficiency.get_config"><code class="name flex">
<span>def <span class="ident">get_config</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns the serializable config of the metric.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_config(self):
    config = super(RejectionAtEfficiency, self).get_config()
    config.update({&#39;efficiency&#39;: self.efficiency,
                  &#39;label_id&#39;: self.label_id})
    return config</code></pre>
</details>
</dd>
<dt id="jidenn.evaluation.evaluation_metrics.RejectionAtEfficiency.result"><code class="name flex">
<span>def <span class="ident">result</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Computes and returns the scalar metric value tensor or a dict of
scalars.</p>
<p>Result computation is an idempotent operation that simply calculates the
metric value using the state variables.</p>
<h2 id="returns">Returns</h2>
<p>A scalar tensor, or a dictionary of scalar tensors.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def result(self):
    return 1 / super(RejectionAtEfficiency, self).result()</code></pre>
</details>
</dd>
<dt id="jidenn.evaluation.evaluation_metrics.RejectionAtEfficiency.update_state"><code class="name flex">
<span>def <span class="ident">update_state</span></span>(<span>self, y_true: Union[tensorflow.python.framework.ops.Tensor, numpy.ndarray], y_pred: Union[tensorflow.python.framework.ops.Tensor, numpy.ndarray], sample_weight: Union[tensorflow.python.framework.ops.Tensor, numpy.ndarray] = None)</span>
</code></dt>
<dd>
<div class="desc"><p>Accumulates the efficiency.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>y_true</code></strong> :&ensp;<code>tf.Tensor</code></dt>
<dd>The true labels.</dd>
<dt><strong><code>y_pred</code></strong> :&ensp;<code>tf.Tensor</code></dt>
<dd>The predicted labels.</dd>
<dt><strong><code>sample_weight</code></strong> :&ensp;<code>tf.Tensor</code>, optional</dt>
<dd>The sample weights. Defaults to None.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def update_state(self, y_true: Union[tf.Tensor, np.ndarray], y_pred: Union[tf.Tensor, np.ndarray], sample_weight: Union[tf.Tensor, np.ndarray] = None):
    &#34;&#34;&#34;Accumulates the efficiency.

    Args:
        y_true (tf.Tensor): The true labels.
        y_pred (tf.Tensor): The predicted labels.
        sample_weight (tf.Tensor, optional): The sample weights. Defaults to None.
    &#34;&#34;&#34;
    y_true = tf.cast(y_true, tf.bool)
    if self.label_id is not None and self.label_id != 1:
        y_true = tf.logical_not(y_true)
        y_pred = 1 - y_pred
    super(RejectionAtEfficiency, self).update_state(
        y_true, y_pred, sample_weight=sample_weight)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="jidenn.evaluation.evaluation_metrics.RejectionAtFixedWorkingPoint"><code class="flex name class">
<span>class <span class="ident">RejectionAtFixedWorkingPoint</span></span>
<span>(</span><span>working_point: float = 0.5, fixed_label_id: Literal[0, 1] = 1, returned_label_id: Literal[0, 1] = 0, num_thresholds: int = 200, name: Optional[str] = 'rejection_at_fixed_wp', dtype: Optional[tensorflow.python.framework.dtypes.DType] = None)</span>
</code></dt>
<dd>
<div class="desc"><p>Calculates the rejection at a fixed working point. The working point is defined by the user.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>working_point</code></strong> :&ensp;<code>float</code></dt>
<dd>The working point. Defaults to 0.5.</dd>
<dt><strong><code>fixed_label_id</code></strong> :&ensp;<code>Literal[0, 1]</code>, optional</dt>
<dd>The label id whose efficiency is fixed. Defaults to 1.</dd>
<dt><strong><code>returned_label_id</code></strong> :&ensp;<code>Literal[0, 1]</code>, optional</dt>
<dd>The label id whose efficiency is returned. Defaults to 0.</dd>
<dt><strong><code>num_thresholds</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>The number of thresholds to use for the estimation. Defaults to 200.</dd>
<dt><strong><code>name</code></strong> :&ensp;<code>Optional[str]</code>, optional</dt>
<dd>The name of the metric. Defaults to 'efficiency_at_fixed_wp'.</dd>
<dt><strong><code>dtype</code></strong> :&ensp;<code>Optional[tf.dtypes.DType]</code>, optional</dt>
<dd>The data type of the metric. Defaults to None.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class RejectionAtFixedWorkingPoint(EfficiencyAtFixedWorkingPoint):
    &#34;&#34;&#34;Calculates the rejection at a fixed working point. The working point is defined by the user.

    Args:
        working_point (float): The working point. Defaults to 0.5.
        fixed_label_id (Literal[0, 1], optional): The label id whose efficiency is fixed. Defaults to 1.
        returned_label_id (Literal[0, 1], optional): The label id whose efficiency is returned. Defaults to 0.
        num_thresholds (int, optional): The number of thresholds to use for the estimation. Defaults to 200.
        name (Optional[str], optional): The name of the metric. Defaults to &#39;efficiency_at_fixed_wp&#39;.
        dtype (Optional[tf.dtypes.DType], optional): The data type of the metric. Defaults to None.
    &#34;&#34;&#34;

    def __init__(self, working_point: float = 0.5, fixed_label_id: Literal[0, 1] = 1, returned_label_id: Literal[0, 1] = 0,
                 num_thresholds: int = 200, name: Optional[str] = &#39;rejection_at_fixed_wp&#39;, dtype: Optional[tf.dtypes.DType] = None):
        super().__init__(working_point=working_point, fixed_label_id=fixed_label_id, returned_label_id=returned_label_id,
                         num_thresholds=num_thresholds, name=name, dtype=dtype)

    def result(self) -&gt; tf.Tensor:
        &#34;&#34;&#34;Calculates the rejection at the working point.

        Returns:
            tf.Tensor: The rejection at the working point.
        &#34;&#34;&#34;

        return 1.0 / (1 - super().result())</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="jidenn.evaluation.evaluation_metrics.EfficiencyAtFixedWorkingPoint" href="#jidenn.evaluation.evaluation_metrics.EfficiencyAtFixedWorkingPoint">EfficiencyAtFixedWorkingPoint</a></li>
<li><a title="jidenn.evaluation.evaluation_metrics.FixedWorkingPointBase" href="#jidenn.evaluation.evaluation_metrics.FixedWorkingPointBase">FixedWorkingPointBase</a></li>
<li>keras.metrics.base_metric.Metric</li>
<li>keras.engine.base_layer.Layer</li>
<li>tensorflow.python.module.module.Module</li>
<li>tensorflow.python.trackable.autotrackable.AutoTrackable</li>
<li>tensorflow.python.trackable.base.Trackable</li>
<li>keras.utils.version_utils.LayerVersionSelector</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="jidenn.evaluation.evaluation_metrics.RejectionAtFixedWorkingPoint.reset_state"><code class="name flex">
<span>def <span class="ident">reset_state</span></span>(<span>self)</span>
</code></dt>
<dd>
<p class="inheritance">
<em>Inherited from:</em>
<code><a title="jidenn.evaluation.evaluation_metrics.EfficiencyAtFixedWorkingPoint" href="#jidenn.evaluation.evaluation_metrics.EfficiencyAtFixedWorkingPoint">EfficiencyAtFixedWorkingPoint</a></code>.<code><a title="jidenn.evaluation.evaluation_metrics.EfficiencyAtFixedWorkingPoint.reset_state" href="#jidenn.evaluation.evaluation_metrics.EfficiencyAtFixedWorkingPoint.reset_state">reset_state</a></code>
</p>
<div class="desc inherited"><p>Resets the confusion matrix statistics.</p></div>
</dd>
<dt id="jidenn.evaluation.evaluation_metrics.RejectionAtFixedWorkingPoint.result"><code class="name flex">
<span>def <span class="ident">result</span></span>(<span>self) ‑> tensorflow.python.framework.ops.Tensor</span>
</code></dt>
<dd>
<div class="desc"><p>Calculates the rejection at the working point.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>tf.Tensor</code></dt>
<dd>The rejection at the working point.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def result(self) -&gt; tf.Tensor:
    &#34;&#34;&#34;Calculates the rejection at the working point.

    Returns:
        tf.Tensor: The rejection at the working point.
    &#34;&#34;&#34;

    return 1.0 / (1 - super().result())</code></pre>
</details>
</dd>
<dt id="jidenn.evaluation.evaluation_metrics.RejectionAtFixedWorkingPoint.update_state"><code class="name flex">
<span>def <span class="ident">update_state</span></span>(<span>self, y_true: Union[tensorflow.python.framework.ops.Tensor, numpy.ndarray], y_pred: Union[tensorflow.python.framework.ops.Tensor, numpy.ndarray], sample_weight: Union[tensorflow.python.framework.ops.Tensor, numpy.ndarray, ForwardRef(None)] = None)</span>
</code></dt>
<dd>
<p class="inheritance">
<em>Inherited from:</em>
<code><a title="jidenn.evaluation.evaluation_metrics.EfficiencyAtFixedWorkingPoint" href="#jidenn.evaluation.evaluation_metrics.EfficiencyAtFixedWorkingPoint">EfficiencyAtFixedWorkingPoint</a></code>.<code><a title="jidenn.evaluation.evaluation_metrics.EfficiencyAtFixedWorkingPoint.update_state" href="#jidenn.evaluation.evaluation_metrics.EfficiencyAtFixedWorkingPoint.update_state">update_state</a></code>
</p>
<div class="desc inherited"><p>Accumulates the confusion matrix statistics. The true positives and false negatives are calculated for each threshold.
The total positives and total …</p></div>
</dd>
</dl>
</dd>
<dt id="jidenn.evaluation.evaluation_metrics.ThresholdAtFixedWorkingPoint"><code class="flex name class">
<span>class <span class="ident">ThresholdAtFixedWorkingPoint</span></span>
<span>(</span><span>working_point: float = 0.5, num_thresholds: int = 200, fixed_label_id: Literal[0, 1] = 1, name: Optional[str] = 'threshold_at_fixed_efficiency', dtype: Optional[tensorflow.python.framework.dtypes.DType] = None)</span>
</code></dt>
<dd>
<div class="desc"><p>Calculates the threshold at a fixed working point. The working point is defined by the user.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>working_point</code></strong> :&ensp;<code>float</code></dt>
<dd>The working point. Defaults to 0.5.</dd>
<dt><strong><code>fixed_label_id</code></strong> :&ensp;<code>Literal[0, 1]</code>, optional</dt>
<dd>The label id whose efficiency is fixed. Defaults to 1.</dd>
<dt><strong><code>num_thresholds</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>The number of thresholds to use for the estimation. Defaults to 200.</dd>
<dt><strong><code>name</code></strong> :&ensp;<code>Optional[str]</code>, optional</dt>
<dd>The name of the metric. Defaults to 'threshold_at_fixed_wp'.</dd>
<dt><strong><code>dtype</code></strong> :&ensp;<code>Optional[tf.dtypes.DType]</code>, optional</dt>
<dd>The data type of the metric. Defaults to None.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class ThresholdAtFixedWorkingPoint(FixedWorkingPointBase):
    &#34;&#34;&#34;Calculates the threshold at a fixed working point. The working point is defined by the user.

    Args:
        working_point (float): The working point. Defaults to 0.5.
        fixed_label_id (Literal[0, 1], optional): The label id whose efficiency is fixed. Defaults to 1.
        num_thresholds (int, optional): The number of thresholds to use for the estimation. Defaults to 200.
        name (Optional[str], optional): The name of the metric. Defaults to &#39;threshold_at_fixed_wp&#39;.
        dtype (Optional[tf.dtypes.DType], optional): The data type of the metric. Defaults to None.
    &#34;&#34;&#34;

    def __init__(self, working_point: float = 0.5, num_thresholds: int = 200, fixed_label_id: Literal[0, 1] = 1, name: Optional[str] = &#39;threshold_at_fixed_efficiency&#39;, dtype: Optional[tf.dtypes.DType] = None):
        super().__init__(working_point=working_point, num_thresholds=num_thresholds, name=name, dtype=dtype)
        self.fixed_label_id = fixed_label_id

    def result(self) -&gt; tf.Tensor:
        &#34;&#34;&#34;Calculates the threshold at the working point.

        Raises:
            ValueError: If the fixed_label_id is not 0 or 1.

        Returns:
            tf.Tensor: The threshold at the working point.
        &#34;&#34;&#34;

        if self.fixed_label_id == 1:
            efficiencies = self.true_positives / self.total_positives
        elif self.fixed_label_id == 0:
            efficiencies = self.false_negatives / self.total_negatives
        else:
            raise ValueError(f&#39;fixed_label_id must be 0 or 1, but is {self.fixed_label_id}&#39;)

        closest_index = self._find_index_of_threshold(efficiencies, self.working_point)

        return tf.gather(self.thresholds, closest_index)</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="jidenn.evaluation.evaluation_metrics.FixedWorkingPointBase" href="#jidenn.evaluation.evaluation_metrics.FixedWorkingPointBase">FixedWorkingPointBase</a></li>
<li>keras.metrics.base_metric.Metric</li>
<li>keras.engine.base_layer.Layer</li>
<li>tensorflow.python.module.module.Module</li>
<li>tensorflow.python.trackable.autotrackable.AutoTrackable</li>
<li>tensorflow.python.trackable.base.Trackable</li>
<li>keras.utils.version_utils.LayerVersionSelector</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="jidenn.evaluation.evaluation_metrics.ThresholdAtFixedWorkingPoint.reset_state"><code class="name flex">
<span>def <span class="ident">reset_state</span></span>(<span>self)</span>
</code></dt>
<dd>
<p class="inheritance">
<em>Inherited from:</em>
<code><a title="jidenn.evaluation.evaluation_metrics.FixedWorkingPointBase" href="#jidenn.evaluation.evaluation_metrics.FixedWorkingPointBase">FixedWorkingPointBase</a></code>.<code><a title="jidenn.evaluation.evaluation_metrics.FixedWorkingPointBase.reset_state" href="#jidenn.evaluation.evaluation_metrics.FixedWorkingPointBase.reset_state">reset_state</a></code>
</p>
<div class="desc inherited"><p>Resets the confusion matrix statistics.</p></div>
</dd>
<dt id="jidenn.evaluation.evaluation_metrics.ThresholdAtFixedWorkingPoint.result"><code class="name flex">
<span>def <span class="ident">result</span></span>(<span>self) ‑> tensorflow.python.framework.ops.Tensor</span>
</code></dt>
<dd>
<div class="desc"><p>Calculates the threshold at the working point.</p>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>ValueError</code></dt>
<dd>If the fixed_label_id is not 0 or 1.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>tf.Tensor</code></dt>
<dd>The threshold at the working point.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def result(self) -&gt; tf.Tensor:
    &#34;&#34;&#34;Calculates the threshold at the working point.

    Raises:
        ValueError: If the fixed_label_id is not 0 or 1.

    Returns:
        tf.Tensor: The threshold at the working point.
    &#34;&#34;&#34;

    if self.fixed_label_id == 1:
        efficiencies = self.true_positives / self.total_positives
    elif self.fixed_label_id == 0:
        efficiencies = self.false_negatives / self.total_negatives
    else:
        raise ValueError(f&#39;fixed_label_id must be 0 or 1, but is {self.fixed_label_id}&#39;)

    closest_index = self._find_index_of_threshold(efficiencies, self.working_point)

    return tf.gather(self.thresholds, closest_index)</code></pre>
</details>
</dd>
<dt id="jidenn.evaluation.evaluation_metrics.ThresholdAtFixedWorkingPoint.update_state"><code class="name flex">
<span>def <span class="ident">update_state</span></span>(<span>self, y_true: Union[tensorflow.python.framework.ops.Tensor, numpy.ndarray], y_pred: Union[tensorflow.python.framework.ops.Tensor, numpy.ndarray], sample_weight: Union[tensorflow.python.framework.ops.Tensor, numpy.ndarray, ForwardRef(None)] = None)</span>
</code></dt>
<dd>
<p class="inheritance">
<em>Inherited from:</em>
<code><a title="jidenn.evaluation.evaluation_metrics.FixedWorkingPointBase" href="#jidenn.evaluation.evaluation_metrics.FixedWorkingPointBase">FixedWorkingPointBase</a></code>.<code><a title="jidenn.evaluation.evaluation_metrics.FixedWorkingPointBase.update_state" href="#jidenn.evaluation.evaluation_metrics.FixedWorkingPointBase.update_state">update_state</a></code>
</p>
<div class="desc inherited"><p>Accumulates the confusion matrix statistics. The true positives and false negatives are calculated for each threshold.
The total positives and total …</p></div>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<header>
<a class="homelink" rel="home" title="JIDENN" href="https://jansam.wieno.sk/JIDENN/">
<img src="images/q_g_tagging.jpeg" alt=""> JIDENN
</a>
</header>
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="jidenn.evaluation" href="index.html">jidenn.evaluation</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="jidenn.evaluation.evaluation_metrics.calculate_metrics" href="#jidenn.evaluation.evaluation_metrics.calculate_metrics">calculate_metrics</a></code></li>
<li><code><a title="jidenn.evaluation.evaluation_metrics.get_metrics" href="#jidenn.evaluation.evaluation_metrics.get_metrics">get_metrics</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="jidenn.evaluation.evaluation_metrics.BinaryEfficiency" href="#jidenn.evaluation.evaluation_metrics.BinaryEfficiency">BinaryEfficiency</a></code></h4>
<ul class="">
<li><code><a title="jidenn.evaluation.evaluation_metrics.BinaryEfficiency.get_config" href="#jidenn.evaluation.evaluation_metrics.BinaryEfficiency.get_config">get_config</a></code></li>
<li><code><a title="jidenn.evaluation.evaluation_metrics.BinaryEfficiency.reset_state" href="#jidenn.evaluation.evaluation_metrics.BinaryEfficiency.reset_state">reset_state</a></code></li>
<li><code><a title="jidenn.evaluation.evaluation_metrics.BinaryEfficiency.result" href="#jidenn.evaluation.evaluation_metrics.BinaryEfficiency.result">result</a></code></li>
<li><code><a title="jidenn.evaluation.evaluation_metrics.BinaryEfficiency.update_state" href="#jidenn.evaluation.evaluation_metrics.BinaryEfficiency.update_state">update_state</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="jidenn.evaluation.evaluation_metrics.BinaryRejection" href="#jidenn.evaluation.evaluation_metrics.BinaryRejection">BinaryRejection</a></code></h4>
<ul class="">
<li><code><a title="jidenn.evaluation.evaluation_metrics.BinaryRejection.get_config" href="#jidenn.evaluation.evaluation_metrics.BinaryRejection.get_config">get_config</a></code></li>
<li><code><a title="jidenn.evaluation.evaluation_metrics.BinaryRejection.reset_state" href="#jidenn.evaluation.evaluation_metrics.BinaryRejection.reset_state">reset_state</a></code></li>
<li><code><a title="jidenn.evaluation.evaluation_metrics.BinaryRejection.result" href="#jidenn.evaluation.evaluation_metrics.BinaryRejection.result">result</a></code></li>
<li><code><a title="jidenn.evaluation.evaluation_metrics.BinaryRejection.update_state" href="#jidenn.evaluation.evaluation_metrics.BinaryRejection.update_state">update_state</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="jidenn.evaluation.evaluation_metrics.EffectiveTaggingEfficiency" href="#jidenn.evaluation.evaluation_metrics.EffectiveTaggingEfficiency">EffectiveTaggingEfficiency</a></code></h4>
<ul class="">
<li><code><a title="jidenn.evaluation.evaluation_metrics.EffectiveTaggingEfficiency.get_config" href="#jidenn.evaluation.evaluation_metrics.EffectiveTaggingEfficiency.get_config">get_config</a></code></li>
<li><code><a title="jidenn.evaluation.evaluation_metrics.EffectiveTaggingEfficiency.reset_state" href="#jidenn.evaluation.evaluation_metrics.EffectiveTaggingEfficiency.reset_state">reset_state</a></code></li>
<li><code><a title="jidenn.evaluation.evaluation_metrics.EffectiveTaggingEfficiency.result" href="#jidenn.evaluation.evaluation_metrics.EffectiveTaggingEfficiency.result">result</a></code></li>
<li><code><a title="jidenn.evaluation.evaluation_metrics.EffectiveTaggingEfficiency.update_state" href="#jidenn.evaluation.evaluation_metrics.EffectiveTaggingEfficiency.update_state">update_state</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="jidenn.evaluation.evaluation_metrics.EfficiencyAtFixedWorkingPoint" href="#jidenn.evaluation.evaluation_metrics.EfficiencyAtFixedWorkingPoint">EfficiencyAtFixedWorkingPoint</a></code></h4>
<ul class="">
<li><code><a title="jidenn.evaluation.evaluation_metrics.EfficiencyAtFixedWorkingPoint.reset_state" href="#jidenn.evaluation.evaluation_metrics.EfficiencyAtFixedWorkingPoint.reset_state">reset_state</a></code></li>
<li><code><a title="jidenn.evaluation.evaluation_metrics.EfficiencyAtFixedWorkingPoint.result" href="#jidenn.evaluation.evaluation_metrics.EfficiencyAtFixedWorkingPoint.result">result</a></code></li>
<li><code><a title="jidenn.evaluation.evaluation_metrics.EfficiencyAtFixedWorkingPoint.update_state" href="#jidenn.evaluation.evaluation_metrics.EfficiencyAtFixedWorkingPoint.update_state">update_state</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="jidenn.evaluation.evaluation_metrics.FixedWorkingPointBase" href="#jidenn.evaluation.evaluation_metrics.FixedWorkingPointBase">FixedWorkingPointBase</a></code></h4>
<ul class="">
<li><code><a title="jidenn.evaluation.evaluation_metrics.FixedWorkingPointBase.reset_state" href="#jidenn.evaluation.evaluation_metrics.FixedWorkingPointBase.reset_state">reset_state</a></code></li>
<li><code><a title="jidenn.evaluation.evaluation_metrics.FixedWorkingPointBase.result" href="#jidenn.evaluation.evaluation_metrics.FixedWorkingPointBase.result">result</a></code></li>
<li><code><a title="jidenn.evaluation.evaluation_metrics.FixedWorkingPointBase.update_state" href="#jidenn.evaluation.evaluation_metrics.FixedWorkingPointBase.update_state">update_state</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="jidenn.evaluation.evaluation_metrics.RejectionAtEfficiency" href="#jidenn.evaluation.evaluation_metrics.RejectionAtEfficiency">RejectionAtEfficiency</a></code></h4>
<ul class="">
<li><code><a title="jidenn.evaluation.evaluation_metrics.RejectionAtEfficiency.get_config" href="#jidenn.evaluation.evaluation_metrics.RejectionAtEfficiency.get_config">get_config</a></code></li>
<li><code><a title="jidenn.evaluation.evaluation_metrics.RejectionAtEfficiency.result" href="#jidenn.evaluation.evaluation_metrics.RejectionAtEfficiency.result">result</a></code></li>
<li><code><a title="jidenn.evaluation.evaluation_metrics.RejectionAtEfficiency.update_state" href="#jidenn.evaluation.evaluation_metrics.RejectionAtEfficiency.update_state">update_state</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="jidenn.evaluation.evaluation_metrics.RejectionAtFixedWorkingPoint" href="#jidenn.evaluation.evaluation_metrics.RejectionAtFixedWorkingPoint">RejectionAtFixedWorkingPoint</a></code></h4>
<ul class="">
<li><code><a title="jidenn.evaluation.evaluation_metrics.RejectionAtFixedWorkingPoint.reset_state" href="#jidenn.evaluation.evaluation_metrics.RejectionAtFixedWorkingPoint.reset_state">reset_state</a></code></li>
<li><code><a title="jidenn.evaluation.evaluation_metrics.RejectionAtFixedWorkingPoint.result" href="#jidenn.evaluation.evaluation_metrics.RejectionAtFixedWorkingPoint.result">result</a></code></li>
<li><code><a title="jidenn.evaluation.evaluation_metrics.RejectionAtFixedWorkingPoint.update_state" href="#jidenn.evaluation.evaluation_metrics.RejectionAtFixedWorkingPoint.update_state">update_state</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="jidenn.evaluation.evaluation_metrics.ThresholdAtFixedWorkingPoint" href="#jidenn.evaluation.evaluation_metrics.ThresholdAtFixedWorkingPoint">ThresholdAtFixedWorkingPoint</a></code></h4>
<ul class="">
<li><code><a title="jidenn.evaluation.evaluation_metrics.ThresholdAtFixedWorkingPoint.reset_state" href="#jidenn.evaluation.evaluation_metrics.ThresholdAtFixedWorkingPoint.reset_state">reset_state</a></code></li>
<li><code><a title="jidenn.evaluation.evaluation_metrics.ThresholdAtFixedWorkingPoint.result" href="#jidenn.evaluation.evaluation_metrics.ThresholdAtFixedWorkingPoint.result">result</a></code></li>
<li><code><a title="jidenn.evaluation.evaluation_metrics.ThresholdAtFixedWorkingPoint.update_state" href="#jidenn.evaluation.evaluation_metrics.ThresholdAtFixedWorkingPoint.update_state">update_state</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>